<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 82]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.LG](#cs.LG) [Total: 53]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 该研究提出了一种名为ALP的少样本自适应语言提示方法，利用多模态大语言模型（如GPT-4o和Gemini 1.5 Pro）检测钓鱼网页，显著提升了检测准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击是严重的网络安全威胁，需要自适应检测技术。传统方法难以应对复杂的钓鱼内容，因此探索基于大语言模型的多模态检测方法。

Method: ALP是一种结构化语义推理方法，通过分析语言模式、紧迫性提示和操纵性措辞，结合文本、视觉和URL分析，构建统一模型。

Result: 实验表明，ALP显著提升了钓鱼检测准确率，F1-score达到0.93，优于传统方法。

Conclusion: ALP结合多模态大语言模型为钓鱼检测提供了更鲁棒、可解释和自适应的解决方案。

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [2] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: PersonaGen是一个基于大型语言模型（LLM）的多阶段人格条件框架，用于生成情感丰富的文本，以解决情感识别领域高质量数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 情感表达具有主观性，受个体特质、社会文化背景和情境因素影响，导致大规模、通用数据集难以收集。

Method: 通过结合人口统计属性、社会文化背景和详细情境上下文，构建分层的虚拟人格，指导情感表达生成。

Result: PersonaGen在生成多样、连贯且具有区分性的情感表达方面显著优于基线方法。

Conclusion: PersonaGen可作为增强或替代真实情感数据集的强大工具。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [3] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT是一种结构感知的微调方法，通过注入图拓扑信息提升LLMs在结构化输入（如AMR）上的文本生成性能，显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理AMR等结构化输入时，常忽略关键结构信息或依赖不兼容的架构，限制了LLMs的性能。

Method: SAFT利用磁拉普拉斯变换计算方向敏感的位置编码，并将其投影到LLM的嵌入空间，无需改变架构。

Result: 在AMR 3.0上，SAFT比基线提高了3.5 BLEU，且性能提升随图复杂度增加。

Conclusion: SAFT为结构化数据与语言模型的结合提供了一种通用且有效的途径。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [4] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 提出了一种基于图的新方法，利用NLP技术将新闻文章转换为图结构，并通过MDL-GBAD算法检测假新闻。


<details>
  <summary>Details</summary>
Motivation: 假新闻在数字世界中快速传播，亟需有效解决方案。

Method: 使用NLP将新闻转换为图结构，应用MDL-GBAD算法挖掘异常模式。

Result: 方法能够识别数据集中的规范模式并发现异常模式。

Conclusion: 图方法在处理复杂上下文数据时优于传统技术。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [5] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: PARAM-1是一个专注于印度语言多样性的2.9B参数语言模型，通过双语（印地语和英语）训练，强调公平表示、适应印度形态的标记化和文化对齐评估。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）以英语为中心，忽视了印度等语言多样地区的需求。PARAM-1旨在通过设计解决这一问题。

Method: 采用2.9B参数的解码器架构，训练双语数据集（印地语和英语），强调公平表示（25%语料分配）、适应印度形态的标记化和文化对齐评估。

Result: PARAM-1既是一个通用模型，也是印度中心应用的强大基线。

Conclusion: PARAM-1通过预训练层面的多样性设计，为公平的基础模型提供了蓝图。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [6] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 通过将主题建模流程重构为基于意见单元（包含相关文本摘录和情感评分的独立陈述），提升了从客户评论中提取见解的能力。


<details>
  <summary>Details</summary>
Motivation: 改进传统主题建模方法，以更准确地捕捉客户评论中的主题和情感，从而更好地理解客户关注点对业务指标的影响。

Method: 利用大型语言模型提取意见单元，并在此基础上进行主题建模，同时结合情感评分和业务指标（如星级评分）进行分析。

Result: 系统生成了连贯且可解释的主题，同时捕捉了每个主题的情感，并能有效预测星级评分。

Conclusion: 该方法在主题建模和情感分析方面表现优异，能够为业务决策提供有价值的见解。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [7] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: Babel框架通过单语语料库提升神经机器翻译的风格保真度，无需平行语料库或修改现有系统架构。


<details>
  <summary>Details</summary>
Motivation: 解决神经机器翻译中风格保真度不足的问题，尤其是在缺乏平行语料库的情况下。

Method: Babel包含风格检测器和扩散式风格应用器，前者识别风格差异，后者修正不一致性。

Result: 在五个领域实验中，Babel风格检测精度达88.21%，风格保留提升150%，语义相似度0.92。

Conclusion: Babel有效提升翻译风格保真度，同时保持语义完整性和流畅性。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [8] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 研究利用稀疏自编码器（SAE）特征控制多语言大模型（LLM）生成目标语言，通过修改单个SAE特征实现高达90%的语言转换成功率。


<details>
  <summary>Details</summary>
Motivation: 解决在多语言大模型中零样本设置下无法明确控制生成目标语言的挑战。

Method: 利用预训练的SAE特征，识别与目标语言相关的特征，通过修改这些特征实现语言控制。

Result: 在Gemma-2B和Gemma-9B模型上，修改单个SAE特征可实现90%的语言转换成功率，同时保持语义一致性。

Conclusion: 稀疏特征控制是一种轻量且可解释的多语言生成控制机制。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [9] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: ALIGNed-LLM通过将知识图谱嵌入语言模型，显著减少幻觉问题并提升事实性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在NLP任务中表现优异，但幻觉问题严重，知识图谱的引入可提供结构化、可靠的外部信息。

Method: 利用预训练的知识图谱嵌入模型（如TransE）和可训练投影层，对齐实体与文本嵌入，增强语言模型的事实性。

Result: 在多个问答基准数据集和实际金融用例中，模型表现显著提升。

Conclusion: ALIGNed-LLM是一种简单有效的方法，能显著减少语言模型的幻觉问题并提高事实性。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [10] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 论文提出了一种名为PSA的新型攻击方法，利用权威论文内容构造对抗性提示，成功攻击多种LLM，揭示了模型对不同类型论文的脆弱性差异。


<details>
  <summary>Details</summary>
Motivation: 研究发现LLM倾向于信任权威来源（如学术论文），可能带来新的安全漏洞，因此探索了基于论文内容的攻击方法。

Method: 提出PSA方法，通过合成攻击或防御导向的论文内容构造对抗性提示模板，并在预定义子章节中嵌入有害查询作为对抗性载荷。

Result: 实验显示PSA对Claude3.5-Sonnet和Deepseek-R1的攻击成功率分别达97%和98%，并揭示了模型对不同论文类型的脆弱性差异。

Conclusion: PSA揭示了LLM的新漏洞，为对抗性方法和安全对齐提供了未来研究方向。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [11] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 论文评估了三种广泛使用的价值探测策略的鲁棒性和表达能力，发现输入扰动下所有方法均表现不稳定，且模型的价值与行为偏好相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLM）价值取向评估的挑战，包括探测方法的系统性比较不足，以及探测值是否能反映真实行为偏好。

Method: 通过变化提示和选项，评估三种价值探测策略的鲁棒性，并设计两项任务研究价值对人口统计背景的响应及与行为偏好的相关性。

Result: 输入扰动下所有方法均表现不稳定；人口统计背景对自由文本生成影响小；模型价值与行为偏好相关性弱。

Conclusion: 需更谨慎地评估LLM价值探测方法，并意识到其局限性。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [12] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 论文提出了一种数学方法，将词汇项表示为函数空间中的函数（如小波），并构造了任意句法对象的忠实表示。通过使用第二Renyi熵构建的非结合半环结构，实现了与magma结构兼容的句法表示。该方法通过操作ad模型电路，将输入波形转换为编码句法结构的输出，并通过Hopf代数马尔可夫链实现Merge操作。


<details>
  <summary>Details</summary>
Motivation: 探索句法核心计算结构的神经计算实现可能性，并验证Merge操作与算术后继函数的相似性。

Method: 利用函数空间中的函数表示词汇项，构建非结合半环结构，通过操作ad模型电路实现句法表示，并用Hopf代数马尔可夫链实现Merge操作。

Result: 证明了句法核心计算结构的神经计算实现的理论可能性，并通过正弦波的跨频率相位同步展示了Merge的具体实现。

Conclusion: 研究为句法计算的神经实现提供了理论支持，并揭示了Merge与算术后继函数的深层次联系。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [13] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 提出了一种新的计算框架，用于构建捕捉松散组织对话（准模式对话）的对话图，并引入了一种新的图简化技术（Filter & Reconnect），显著提升了语义指标和结构清晰度。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的系统在多场景中与用户交互，分析对话动态的重要性日益增加。

Method: 提出了Filter & Reconnect方法，一种图简化技术，减少噪声同时保持语义连贯性和结构完整性。

Result: 使用大语言模型结合该技术，语义指标S提升了2.06倍，同时实现了树状结构和0 δ-双曲性，优化了对话建模的清晰度。

Conclusion: 该工作为大规模对话数据集分析提供了计算方法，可应用于监控聊天机器人、对话管理工具和用户行为分析等自动化系统。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [14] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 研究通过整合暂停特征和语义连贯性指标，评估了自动语音识别（ASR）在预测精神分裂症谱系障碍中形式思维障碍（FTD）严重程度的效果，发现暂停特征单独即可有效预测FTD，而整合特征进一步提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统临床评分量表资源密集且难以扩展，研究旨在探索ASR技术如何通过量化语言和时间特征，为FTD评估提供可扩展的替代方案。

Method: 研究结合暂停特征和语义连贯性指标，使用支持向量回归（SVR）预测临床FTD评分，并在三个数据集（AVH、TOPSY、PsyCL）中验证模型性能。

Result: 暂停特征单独预测FTD效果显著，整合暂停和语义特征后性能进一步提升（最高相关性0.649，AUC 83.71%），且结果在不同数据集中一致。

Conclusion: 结合时间和语义分析框架为评估紊乱言语提供了新方向，推动了精神病自动化语音分析的发展。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [15] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 论文介绍了Balalaika数据集，用于解决俄语语音合成的独特挑战，并展示了其在语音合成和增强任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 俄语语音合成面临元音弱化、辅音清音化、变调模式、同形异义词歧义和不自然语调等独特挑战。

Method: 构建了包含2000多小时高质量俄语语音的Balalaika数据集，附带全面的文本标注（包括标点和重音标记），并详细描述了数据集的构建流程和标注方法。

Result: 实验表明，基于Balalaika训练的模型在语音合成和增强任务中显著优于现有数据集训练的模型。

Conclusion: Balalaika数据集为俄语语音合成提供了高质量资源，解决了现有挑战，并在实验中表现出优越性能。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [16] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 研究通过多层面语言学特征分析人类与机器生成文本的差异，发现人类文本句法更简单、语义更多样，且风格多样性更高。


<details>
  <summary>Details</summary>
Motivation: 探索人类与机器生成文本在语言学特征上的差异，以更深入理解两者的区别。

Method: 选择8个领域的人类与机器生成文本，计算语言学特征（如依存长度、情感性），并应用统计分析。

Result: 人类文本句法更简单、语义更多样；机器生成文本风格趋同，新模型输出更一致。

Conclusion: 机器生成文本在风格上逐渐趋同，而人类文本更具多样性。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [17] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-X是一系列开源大语言模型，通过7B参数规模提升多语言翻译能力，性能媲美闭源模型。


<details>
  <summary>Details</summary>
Motivation: 解决多语言翻译中复杂的语言模式和生硬翻译问题。

Method: 预训练基础模型，通过Chain-of-Thought推理和强化学习微调指导模型。

Result: 在28种语言中表现与Gemini-2.5和GPT-4o相当，显著优于其他开源模型。

Conclusion: Seed-X为翻译研究和应用提供了高效的开源解决方案。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [18] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: CU-ICU是一种针对ICU数据集的无监督指令微调方法，通过稀疏微调和选择性参数更新，显著提升了预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在医疗领域（如ICU）的领域适应性和标记数据不足的问题。

Method: 基于T5架构，结合少样本提示和选择性参数更新的稀疏微调方法。

Result: 在ICU任务中（如败血症早期检测、死亡率预测和临床笔记生成），CU-ICU比标准微调方法提高了15%的准确性和20%的解释性，同时仅更新1%的参数。

Conclusion: CU-ICU是一种高效、可扩展的解决方案，适用于ICU环境中的临床决策支持。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [19] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: KiC框架通过语义对齐评估，在降低API成本的同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有级联方法无法可靠评估自由文本输出的问题。

Method: 使用关键词启发式级联（KiC）框架，评估弱模型输出的语义对齐。

Result: KiC在三个基准测试中达到GPT-4的97.53%准确率，成本降低28.81%。

Conclusion: KiC是一种高效且经济的自由文本生成解决方案。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [20] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe是一个针对多轮对话中大型语言模型的自适应双阶段推理加速框架，通过动态稀疏化和渐进键值压缩提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长对话历史时面临计算和内存挑战，且依赖固定启发式方法，无法适应动态对话模式。

Method: LoopServe在预填充阶段动态选择注意力矩阵重要部分，解码阶段渐进压缩键值缓存。

Result: 实验表明，LoopServe在多种长上下文对话任务中显著加速推理并优于现有基线。

Conclusion: LoopServe通过自适应优化，有效解决了多轮对话中的效率问题。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [21] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: 论文评估了LLM在群组推荐系统（GRS）中的表现，发现其推荐与ADD聚合类似，但解释常涉及评分平均。额外标准的使用和解释不一致性影响了透明性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM作为GRS的决策和解释生成器的效果，并与传统社会选择聚合策略对比。

Method: 比较LLM生成的推荐和解释与ADD聚合策略的结果，分析群组结构和额外标准的影响。

Result: LLM推荐类似ADD聚合，但解释涉及评分平均；群组结构无影响；额外标准和不一致解释影响透明性。

Conclusion: LLM在GRS中的应用需改进解释一致性，标准聚合方法在大规模项目集上可能效率不足。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [22] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 研究通过机器学习预测法国上诉法院的儿童监护权判决，探讨法官个体决策模式对结果的影响，支持法律现实主义观点。


<details>
  <summary>Details</summary>
Motivation: 挑战法官是中立变量的假设，验证法律现实主义与形式主义的争论。

Method: 使用18,937份判决数据，结合LLM和ML模型（RF、XGB、SVC），比较法官专用模型与通用模型的预测效果。

Result: 法官专用模型预测准确率更高（F1达92.85%），验证法官个体模式对判决的影响。

Conclusion: 司法身份对法律结果有可测量的影响，支持法律现实主义。数据与代码将公开。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [23] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 论文探讨了如何通过参数高效微调技术（如LoRA和软提示调优）减少大型语言模型（LLMs）对LGBTQIA+群体的偏见，并展示了LoRA在降低偏见分数上的显著效果。


<details>
  <summary>Details</summary>
Motivation: LLMs在训练数据中常带有性别和性取向偏见，导致输出边缘化LGBTQIA+用户，因此减少此类偏见至关重要。

Method: 评估了两种参数高效微调技术（LoRA和软提示调优）作为轻量级替代方案，使用WinoQueer基准量化偏见，并在QueerNews语料库上进行微调。

Result: LoRA（<0.1%额外参数）将偏见分数降低多达50分，中立性从接近0%提升至36%；软提示调优效果有限。

Conclusion: LoRA能以极低计算成本显著提升公平性，建议推广社区参与的参数高效微调技术、扩大LGBTQIA+语料库，并持续进行模型审计。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [24] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 论文研究了视觉语言模型（VLM）中提示设计对生成不当内容的影响，发现多模态环境下模型区分能力下降，并提出了一种提高越狱成功率的框架。


<details>
  <summary>Details</summary>
Motivation: 探究提示敏感性如何被利用以生成不当内容，特别是在视觉语言模型中。

Method: 分析了三个关键因素（详细视觉信息、对抗样本、正面开头短语）对越狱的影响，并提出了一种基于内部层跳连接的框架。

Result: 每个因素均可独立触发越狱，少量上下文示例即可诱导不当输出；提出的框架显著提高了越狱成功率。

Conclusion: 视觉语言模型在多模态环境下易受攻击，即使是看似无害的内容（如表情包）也可能引发有害输出。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [25] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 论文提出了一种改进的GSDMM+算法，用于短文本聚类，解决了稀疏性和高维性问题，并通过实验验证了其高效性和有效性。


<details>
  <summary>Details</summary>
Motivation: 短文本聚类在社交媒体时代愈发重要，但现有方法面临稀疏性、高维性和计算复杂度高的挑战。

Method: 提出基于Dirichlet Multinomial Mixture模型的GSDMM+算法，通过减少初始化噪声、自适应调整词权重和策略性合并簇来优化性能。

Result: 实验表明，GSDMM+在效率和效果上优于经典和最新方法。

Conclusion: GSDMM+是一种高效的短文本聚类方法，代码已开源。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [26] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 论文提出两种生成问答对（QA）的方法，分别基于大语言模型（LLM）和知识图谱（KG），用于从科学文章中提取关键概念和贡献。KG方法通过构建和优化知识图谱，更有效地捕捉文章的主要思想。


<details>
  <summary>Details</summary>
Motivation: 学者在阅读或引用文章时需要快速理解其主要内容，因此需要一种高效的方法提取关键概念。

Method: 1. LLM方法：选择重要段落，生成问题并排序，再生成答案。2. KG方法：构建知识图谱，通过实体关系提取和显著性三元组选择生成QA。

Result: 评估表明，KG方法能更有效地提取文章主要思想，且优化实体关系提取模型对高质量三元组提取至关重要。

Conclusion: KG方法在提取科学文章关键概念方面表现优异，优化实体关系提取模型是成功的关键。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [27] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 研究探讨了中文心理咨询中语言表达与抑郁和焦虑心理状态的关系，发现负面情绪词与心理状态严重程度显著正相关，但第一人称单数代词使用频率与心理状态无关。


<details>
  <summary>Details</summary>
Motivation: 探索中文心理咨询中语言特征与心理状态的关系，填补文化差异下的研究空白。

Method: 基于735个在线心理咨询会话语料库，使用LIWC软件量化语言模式，并通过混合效应模型分析。

Result: 负面情绪词频率与抑郁和焦虑严重程度显著正相关；第一人称单数代词使用频率与心理状态无关。

Conclusion: 文化背景和对话动态对心理健康交流中的语言使用有重要影响，为中文人群的心理治疗提供了新见解。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [28] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 论文提出了一种概率框架，用于定义侦探小说中的公平性（fair play），并设计了相关指标。研究发现，LLM生成的故事虽然不可预测，但未能平衡惊喜与公平性，导致质量较差。


<details>
  <summary>Details</summary>
Motivation: 探讨侦探小说中如何平衡读者预期与意外发展（即公平性），并量化这一概念。

Method: 提出概率框架，定义公平性及设计相关指标，分析LLM生成的故事。

Result: LLM生成的故事缺乏惊喜与公平性的平衡，质量较差。

Conclusion: 平衡故事的连贯性与惊喜是高质量侦探小说的关键，LLM目前未能做到。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [29] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 论文介绍了一种名为InTraVisTo的工具，用于可视化Transformer模型内部的计算过程，帮助研究者理解LLM的内部推理模式。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs的推理能力显著提升，但其不可预测性和行为与预期的不一致使得生产应用具有挑战性。

Method: 开发了InTraVisTo工具，通过解码每层模型的token嵌入和Sankey图可视化信息流，追踪Transformer模型的内部计算过程。

Result: InTraVisTo提供了对Transformer模型内部状态和信息流的可视化，揭示了LLMs的内部推理模式。

Conclusion: InTraVisTo有助于研究者更深入地理解LLMs的内部计算过程和推理行为。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [30] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 论文研究了网络安全NER领域的标签标准化问题，通过粗粒度标签统一和跨数据集评估，发现模型在统一数据集上泛化能力差，并提出多头和基于图的迁移模型作为替代方案。


<details>
  <summary>Details</summary>
Motivation: 网络安全NER领域缺乏标准化标签，导致数据集难以整合，研究旨在提高数据资源的可用性。

Method: 采用粗粒度标签统一方法，使用BiLSTM模型进行跨数据集评估，并提出多头和基于图的迁移模型。

Result: 统一数据集训练的模型泛化能力差，多头模型略有改进，基于图的迁移模型性能未显著提升。

Conclusion: 标签统一存在局限性，需进一步研究改进模型架构以提升跨数据集性能。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [31] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 论文探讨了如何通过合成数据、拼接单语音频和利用真实代码切换数据提升加泰罗尼亚语-西班牙语代码切换的自动语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 代码切换（CS）在自动语音识别（ASR）中因训练数据稀缺和语言相似性而面临挑战，尤其在多语言社会中普遍存在。

Method: 研究采用三种策略：生成合成CS数据、拼接单语音频、利用真实CS数据加语言标记，并基于Whisper模型进行微调。

Result: 结合少量合成CS数据和主导语言标记的模型表现最佳。

Conclusion: 合成数据与语言标记结合的方法有效提升了CS-ASR性能，模型已开源。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [32] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 论文探讨了利用大型语言模型（LLMs）从情境判断测试（SJTs）中提取相关特征的新方法，以解决传统人工评分在规模化应用中的问题。


<details>
  <summary>Details</summary>
Motivation: 学术项目日益重视个人与专业技能的重要性，但传统SJTs依赖人工评分，难以规模化。需要开发可靠且自动化的评分系统。

Method: 采用大型语言模型（LLMs）从SJTs的开放回答中提取与构念相关的特征，并以Casper SJT为例验证方法有效性。

Result: 研究证明了LLMs在提取SJTs特征方面的有效性，为自动化评分系统的发展奠定了基础。

Conclusion: 该方法为未来个人与专业技能的自动化评分提供了新的研究方向。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [33] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本文提出了一种基于Transformer模型的文本政治倾向和政治性自动分类方法，通过整合多个数据集并创建新数据集，解决了现有方法在分布外文本上表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在政治倾向和政治性分类任务中存在分布外文本表现不佳的问题，需要更通用的解决方案。

Method: 整合12个政治倾向分类数据集，并扩展18个现有数据集以创建新的政治性分类数据集，采用留一法和留出法进行模型评估和训练。

Result: 通过广泛的基准测试，评估了现有模型的性能，并训练了具有更强泛化能力的新模型。

Conclusion: 提出的方法通过数据集整合和新模型训练，显著提升了政治文本分类任务的泛化能力。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [34] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 研究表明，当前和近期的AI说服力主要来自后训练和提示方法，而非个性化或模型规模；这些方法虽提升说服力，但降低了事实准确性。


<details>
  <summary>Details</summary>
Motivation: 评估AI对政治议题的说服力及其事实准确性，以回应公众对AI影响人类信念的担忧。

Method: 通过三个大规模实验（N=76,977），测试19个LLM（包括专为说服设计的模型）在707个政治议题上的表现，并分析466,769条生成内容的事实准确性。

Result: 后训练和提示方法显著提升AI说服力（分别达51%和27%），但降低了事实准确性；个性化或模型规模的影响较小。

Conclusion: AI的说服力主要依赖于后训练和提示方法，但这些方法可能以牺牲事实准确性为代价，需谨慎使用。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [35] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: Marcel是一个轻量级开源对话代理，旨在帮助准学生解答入学相关问题，减轻大学工作人员负担。


<details>
  <summary>Details</summary>
Motivation: 通过提供快速个性化回答，减少大学工作人员的工作量。

Method: 采用检索增强生成技术，结合FAQ检索器，优化检索质量。

Result: 系统架构详细，技术评估显示组件性能良好，实际部署效果显著。

Conclusion: Marcel适用于资源有限的学术环境，能有效支持入学咨询。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [36] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 研究发现微调放大了LLMs的首因效应，通过语义相似性重排选项显著提升MCQA性能。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在MCQA任务中的首因效应及其影响。

Method: 通过语义相似性重排选项，利用首因效应提升性能。

Result: 重排选项显著提高了MCQA的准确性。

Conclusion: 偏见既是挑战也是机会，为偏见识别的模型设计提供启示。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [37] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 论文提出了一种基于知识图谱（KG）的任务生成方法，通过组合领域基础概念训练语言模型，实现领域特定推理能力的提升，并在医学领域验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型在跨领域泛化中表现良好，但缺乏深度领域专业知识，需通过组合基础概念来提升推理能力。

Method: 利用知识图谱构建任务生成管道，合成基于KG基础概念的任务，并微调语言模型（如QwQ-32B）以获取领域专业知识。

Result: QwQ-Med-3模型在医学领域显著优于现有推理模型，并在ICD-Bench评估中表现出色。

Conclusion: 通过组合领域基础概念的方法，可以实现领域特定超级智能，为通用人工智能（AGI）的发展提供新思路。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [38] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 本文提出了一种通用的阿拉伯语语音和文本处理方法，并基于FastConformer架构训练了两个新模型：一个针对现代标准阿拉伯语（MSA），另一个是首个统一的MSA和古典阿拉伯语（CA）公共模型。MSA模型在相关数据集上达到SOTA性能，统一模型在CA带音标任务中表现优异，同时保持MSA的强性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语自动语音识别（ASR）系统开发面临挑战，尤其是语言变体的多样性。现有研究多集中于MSA，对其他变体关注不足。

Method: 提出通用方法处理阿拉伯语语音和文本，基于FastConformer架构训练两个模型：MSA专用模型和MSA/CA统一模型。

Result: MSA模型在相关数据集上达到SOTA性能；统一模型在CA带音标任务中表现优异，同时保持MSA的强性能。

Conclusion: 该方法有效解决了阿拉伯语ASR的独特挑战，模型开源以促进可复现性。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [39] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM框架利用LLM作为时空预测器和轨迹推理器，通过分层时间标记化减少序列长度，显著提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在捕捉时空依赖性和计算效率上的不足。

Method: 将轨迹分段为每日标记，利用分层注意力和预计算提示嵌入增强LLM的推理能力。

Result: 在三个数据集上实现2.4%准确率提升、周末5.0%提升和24.6%训练时间减少。

Conclusion: RHYTHM在效率和性能上优于现有方法，适用于大规模时空预测任务。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [40] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 提出CPC-CMS框架用于文档级情感分析，结合专家知识计算权重，选择最佳分类模型。


<details>
  <summary>Details</summary>
Motivation: 解决文档级情感分析中模型选择问题，结合多评价标准优化决策。

Method: 基于专家知识计算权重，构建加权决策矩阵，评估多种基线模型。

Result: ALBERT在排除时间因素时表现最佳，但考虑时间消耗时无单一模型始终最优。

Conclusion: CPC-CMS可推广至其他分类应用领域。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [41] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 评估了多种成本效益高的大型语言模型（LLMs）在生物医学任务中的表现，发现不同模型在不同任务中表现最佳，开源模型在某些任务中甚至优于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 研究不同LLMs在生物医学任务中的表现差异，为特定应用选择最优模型提供依据。

Method: 评估了闭源和开源LLMs在文本分类、生成、问答及多模态图像处理等任务中的表现。

Result: 无单一模型在所有任务中表现最佳，开源模型在某些任务中表现优于闭源模型，且具有更快推理和更强隐私保护优势。

Conclusion: 研究结果为生物医学应用中模型选择提供了实用指导，强调了开源模型的潜力。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [42] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 论文提出了一种基于信息论的协作理性言语行为（CRSA）框架，用于多轮对话场景，优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有理性言语行为（RSA）框架难以扩展到多轮协作场景，需要一种新方法。

Method: 引入CRSA，基于信息论扩展RSA，优化增益函数，考虑对话中双方的私有信息。

Result: 在指称游戏和医患对话实验中，CRSA表现更一致、可解释且协作性更强。

Conclusion: CRSA为更具实用性和社会意识的语言代理提供了新方向。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [43] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: DENSE系统通过模拟医生参考过往病历的方式，生成临床连贯且时间敏感的进展记录，填补了电子健康记录中进展记录的缺失。


<details>
  <summary>Details</summary>
Motivation: 进展记录在电子健康记录中具有重要意义，但在大规模数据集中严重不足（如MIMIC-III中仅8.56%的访问包含进展记录），导致患者纵向叙事不完整。

Method: DENSE结合细粒度分类和时间对齐机制，利用临床信息检索策略从当前和过往访问中提取相关内容，通过大型语言模型生成连贯的进展记录。

Result: 生成的记录在时间对齐比例上达到1.089，优于原始记录，支持下游任务如总结、预测建模和临床决策。

Conclusion: DENSE为现实医疗环境中基于LLM的记录合成提供了可扩展的解决方案，增强了叙事的连贯性。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [44] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: PLABA track评估了语言模型在将生物医学文献改写为通俗语言方面的表现，发现模型在事实准确性和完整性上接近人类水平，但在简洁性和自动评估工具方面仍需改进。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的专业性使其难以被患者和护理人员理解，语言模型可能解决这一问题，但需严格评估以避免潜在风险。

Method: 通过PLABA track的两个任务（全文改写和术语替换）评估模型表现，结合专业参考和专家手动评估。

Result: 模型在事实准确性和完整性上表现优异，但简洁性不足；自动评估工具与人工评估相关性低。

Conclusion: 语言模型在生物医学文献通俗化方面有潜力，但需改进简洁性和自动评估工具。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 本文综述了无人机航拍场景中的开放词汇目标检测（OVOD），探讨了其核心原理、方法分类、数据集及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统无人机目标检测方法局限于预定义类别，而OVOD通过跨模态文本-图像对齐（如CLIP）实现了对未见物体的检测，提升了无人机的智能性和自主性。

Method: 通过系统分类法对现有OVOD方法进行归纳，并全面梳理相关数据集，分析关键挑战和开放问题。

Result: 提出了无人机航拍场景中OVOD的清晰路线图，为研究者提供了有价值的参考。

Conclusion: OVOD在无人机航拍场景中具有广阔的应用前景，未来研究应关注其核心挑战和创新方向。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [46] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: EDNIG是一种基于U-Net的新型深度学习框架，通过引入亮度图和多尺度特征提取模块，结合GAN优化，显著提升了低光图像增强的效果。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强中未曝光区域处理不足的问题，提升模型在多样化光照条件下的表现。

Method: 结合U-Net架构，引入亮度图（BCP）和多尺度特征提取（SPP），使用Swish激活函数，并在GAN框架下优化。

Result: 在定量指标和视觉质量上优于现有方法，同时模型复杂度较低。

Conclusion: EDNIG在低光图像增强任务中表现出色，适合实际应用。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [47] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: 研究发现，尽管视觉语言模型（VLMs）在复杂视觉任务上表现优异，但在非局部视觉推理任务中表现不佳，甚至接近随机准确率。


<details>
  <summary>Details</summary>
Motivation: 评估VLMs在非局部视觉推理任务中的能力，揭示其在核心视觉推理上的不足。

Method: 设计了三种非局部视觉任务（比较感知、扫视搜索和平滑视觉搜索），测试主流模型的表现。

Result: 旗舰模型（如Gemini 2.5 Pro、Claude Vision 3.7等）在这些任务中表现不佳，甚至低于人类水平。

Conclusion: 当前VLMs在视觉推理能力上仍有显著缺陷，需进一步改进。

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [48] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 研究探讨了视觉语言模型（VLM）的空间推理能力，发现结构化多阶段提示（SceneGraph CoT）显著提升性能，而强化学习（GRPO）比监督微调（SFT）表现更好且更稳健。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过提示策略和强化学习提升VLM的空间推理能力及其泛化性。

Method: 使用Chain-of-Thought（CoT）提示和Group Relative Policy Optimization（GRPO）进行微调，并在SAT数据集和CVBench上评估。

Result: SceneGraph CoT显著提高空间推理准确性；GRPO在Pass@1评估中表现优于SFT，且在分布外（OOD）条件下更稳健。

Conclusion: 结构化提示和强化学习能有效提升VLM的空间推理能力和泛化表现。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [49] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 利用2D视觉语言模型实现无标注的开放词汇3D物体检测，通过几何方法生成3D边界框，并在多种输入条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有3D检测数据集类别有限且标注成本高，而2D视觉语言模型具有丰富的语义理解和开放词汇能力，可用于3D检测。

Method: 使用2D视觉语言模型生成文本条件提议，结合SAM分割和相机几何投影到3D，通过DBSCAN聚类和旋转卡尺生成3D边界框。

Result: 在LiDAR和RGB-D输入下均表现优异，无需训练且支持开放词汇。

Conclusion: 展示了2D基础模型在可扩展3D感知中的潜力，代码开源。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [50] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种多模态多任务网络及训练算法，支持12种模态数据输入，通过共享Transformer架构和跨模态注意力机制实现统一嵌入空间，并在25个数据集上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态和多任务场景下的数据融合与任务协同问题，提升模型在多样化数据上的表现。

Method: 采用模态专用分词器、共享Transformer架构和跨注意力机制，结合模态特定任务头和迭代模态切换预训练策略。

Result: 在12种模态的25个数据集上实现了最先进的性能。

Conclusion: 所提出的架构、预训练策略和多任务训练方法在多模态场景中表现出色。

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [51] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 提出了一种结合光学动作捕捉和Transformer模型的端到端深度学习框架，用于医疗康复，解决数据噪声和缺失问题，并实时检测异常动作。


<details>
  <summary>Details</summary>
Motivation: 解决医疗康复中因遮挡和环境因素导致的数据噪声和缺失问题，同时实时监测患者异常动作以确保安全。

Method: 利用Transformer模型进行时间序列建模，对动作捕捉数据进行去噪和补全。

Result: 在卒中和骨科康复数据集上表现出优异的数据重建和异常检测性能。

Conclusion: 该框架为远程康复提供了可扩展、经济高效的解决方案，减少了对现场监督的需求。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [52] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种结合Vision Transformers和Graph Neural Networks的创新框架，用于提高乳腺癌检测的准确性，并在CBIS-DDSM数据集上取得了84.2%的准确率。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因之一，早期检测对提高生存率至关重要。

Method: 通过整合Vision Transformers（ViT）和Graph Neural Networks（GNN），利用ViT捕捉全局图像特征和GNN建模结构关系的能力。

Result: 在CBIS-DDSM数据集上实现了84.2%的准确率，优于传统方法。

Conclusion: 该框架不仅提高了检测准确性，还通过可解释的注意力热图帮助临床医生理解模型的决策过程。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [53] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: 论文提出了一种名为IConMark的新型语义水印方法，用于区分AI生成图像与真实图像，具有抗对抗攻击和人类可读的特点。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和合成媒体的快速发展，区分AI生成图像与真实图像对防止虚假信息和确保数字真实性至关重要。传统水印技术易受对抗攻击，效果有限。

Method: IConMark通过在AI生成图像中嵌入可解释的语义属性，而非传统的噪声或扰动，实现人类可读且抗对抗攻击的水印。还提出了结合StegaStamp和TrustMark的混合方法（IConMark+SS和IConMark+TM）。

Result: IConMark及其变体在检测准确性和图像质量保持上优于基线方法，AUROC得分分别提高了10.8%、14.5%和15.9%。

Conclusion: IConMark为可解释水印技术提供了有效解决方案，结合现有方法可进一步增强鲁棒性。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [54] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: Butter是一个新颖的目标检测框架，通过频率自适应特征一致性增强和渐进式层次特征融合网络，提升了多尺度特征表示能力，显著提高了检测精度并降低了模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有架构（如YOLO和DETR）在多尺度特征一致性和计算效率之间存在平衡问题，导致动态环境中目标检测的精度不足。

Method: Butter引入FAFCE组件和PHFFNet模块，分别通过自适应频率滤波和渐进特征融合优化多尺度特征一致性和语义层次学习。

Result: 在BDD100K、KITTI和Cityscapes数据集上的实验表明，Butter在检测精度和模型复杂度方面表现优异。

Conclusion: Butter通过层次特征优化，实现了实时自动驾驶场景中精度、可部署性和计算效率的平衡。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [55] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: ModaRoute是一个基于LLM的智能路由系统，动态选择多模态视频检索的最优模态，减少计算开销41%，同时保持60.9%的召回率。


<details>
  <summary>Details</summary>
Motivation: 密集文本描述虽然能达到75.9%的召回率，但需要昂贵的离线处理且会遗漏34%的视觉信息（如场景文本）。

Method: 使用GPT-4.1分析查询意图并预测信息需求，动态路由查询到ASR、OCR和视觉索引，平均每查询使用1.78种模态。

Result: 在180万视频剪辑上评估，智能路由减少了计算开销41%，召回率为60.9%。

Conclusion: 智能路由为多模态检索系统提供了实用解决方案，降低了基础设施成本，同时保持了实际部署的竞争力。

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [56] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 该论文综述了工业缺陷检测领域的最新进展，重点分析了从封闭集到开放集检测方法的转变，并总结了当前挑战与未来趋势。


<details>
  <summary>Details</summary>
Motivation: 传统工业缺陷检测方法难以满足现代制造业对精度、自动化和可扩展性的需求，而计算机视觉和深度学习的进步为缺陷检测提供了新思路。

Method: 论文通过深入分析2D和3D模态下的封闭集与开放集缺陷检测方法，梳理其发展历程，并强调开放集技术的优势。

Result: 研究发现开放集检测方法减少了对大量缺陷标注的依赖，并能识别新型异常，成为当前研究热点。

Conclusion: 论文总结了工业缺陷检测领域的现状与挑战，为未来研究提供了全面的视角。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [57] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 论文探讨了在卫星图像机器学习（SatML）任务中，融合其他地理数据层如何提升模型性能，特别是在数据有限和跨区域测试时效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有SatML模型主要依赖光学卫星图像，忽略了其他地理数据层的潜在价值。研究旨在探索多模态输入对模型性能的影响。

Method: 通过为SatML基准任务生成增强数据集，将其他地理数据层（如高程模型、传感器数据）与光学图像结合，测试分类、回归和分割任务。

Result: 融合多模态输入显著提升模型性能，尤其在数据有限和跨区域测试时。硬编码融合策略优于学习策略。

Conclusion: 多模态输入可提升SatML的数据效率和泛化能力，硬编码融合策略值得未来研究关注。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [58] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 提出了一种基于生成输出分布距离的最小化概念擦除方法，通过端到端优化和神经元掩码技术，在不影响模型性能的情况下实现安全生成。


<details>
  <summary>Details</summary>
Motivation: 解决生成模型依赖大规模无标签数据引发的安全和版权问题，同时避免现有擦除方法对模型效用的过度损害。

Method: 基于生成输出的分布距离设计目标函数，利用反向传播进行端到端优化，并引入神经元掩码增强擦除鲁棒性。

Result: 在先进流匹配模型上验证，方法能有效擦除概念且不降低模型性能。

Conclusion: 为更安全、负责任的生成模型提供了可行路径。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [59] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 论文提出了一种利用大规模二进制占用数据（无语义标签）来增强3D语义占用预测的方法，通过分解预测过程为二进制和语义模块，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 3D语义占用预测需要昂贵的LiDAR标注数据，而二进制占用数据成本更低但未被充分利用。研究探索了如何利用二进制数据提升预测效果。

Method: 提出了一种基于二进制占用的框架，将预测过程分解为二进制占用模块和语义占用模块，充分利用二进制数据。

Result: 实验表明，该方法在预训练和自动标注任务中均优于现有方法，显著提升了3D语义占用预测性能。

Conclusion: 通过有效利用二进制占用数据，该方法为低成本提升3D语义占用预测提供了可行方案。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [60] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的模型InSyn，用于行人轨迹预测，通过显式捕捉多样交互模式和改进初始步预测误差。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖相对位置建模行人交互，但忽略了特定交互模式（如配对行走或冲突行为），导致预测精度受限。

Method: 提出InSyn模型，结合Transformer显式捕捉多样交互模式，并引入SSOS训练策略以减少初始步预测误差。

Result: 在ETH和UCY数据集上表现优于基线，尤其在高密度场景中，SSOS策略将初始步预测误差降低约6.58%。

Conclusion: InSyn模型和SSOS策略有效提升了行人轨迹预测的准确性，特别是在复杂交互场景中。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [61] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: 论文提出MADI框架，通过Masking-Augmented gaussian Diffusion（MAgD）和推理时扩展机制，显著提升扩散模型的可编辑性和可控性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成中表现出色，但在结构化、可控的生成和编辑方面仍面临挑战。

Method: 引入MAgD训练策略，结合去噪得分匹配和掩码重建；提出基于Pause Tokens的推理时扩展机制。

Result: MADI显著提升了扩散模型的编辑能力和可控性。

Conclusion: MADI为扩散模型在通用、上下文生成架构中的应用铺平了道路。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [62] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 本文介绍了一个用于驾驶员 drowsiness 检测的多模态公共数据集，包含面部、行为和生物特征信号，数据采集时间长且连续。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多为离散标签，缺乏连续状态变化记录。本研究旨在提供更全面的多模态数据，以更好地捕捉驾驶员 drowsiness 的生理和行为变化。

Method: 数据集整合了3D面部视频、IR摄像头、后视视频、生物特征信号（如心率、皮肤电活动等）以及方向盘握力传感器和模拟器数据。数据采集持续40分钟/人，共19名受试者。

Result: 数据集总时长1,400分钟，记录了驾驶员从警觉到 drowsiness 的连续状态变化，而非离散标签。

Conclusion: 该数据集为驾驶员 drowsiness 研究提供了更全面的多模态数据支持，未来可申请获取。

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [63] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一种基于扩散的框架，直接从CT/MRI体积生成平滑的主动脉表面，解决了现有方法依赖大标注数据集和手动干预的问题，适用于CFD分析。


<details>
  <summary>Details</summary>
Motivation: 准确的3D主动脉构建对临床诊断和CFD模拟至关重要，但现有方法依赖大标注数据集且难以生成几何一致的表面。

Method: AortaDiff采用体积引导的条件扩散模型生成主动脉中心线，并自动提取血管轮廓，最终拟合为平滑3D表面。

Result: 实验表明，AortaDiff在有限训练数据下仍能有效构建正常和病理主动脉网格，几何保真度高。

Conclusion: AortaDiff为心血管研究提供了端到端的实用解决方案，能生成高质量可视化结果。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [64] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: COREVQA是一个新的视觉蕴含基准测试，用于评估视觉语言模型在拥挤场景中的推理能力，结果显示当前模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少评估视觉语言模型在视觉蕴含任务（如基于图像接受或反驳假设）上的能力。

Method: 提出COREVQA基准，包含5608张图像和合成的真假陈述对，图像来自CrowdHuman数据集。

Result: 即使表现最好的模型准确率也低于80%，其他模型表现更差（39.98%-69.95%）。

Conclusion: 当前视觉语言模型在拥挤场景中的视觉蕴含推理能力存在显著不足。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [65] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: AI多模型深度学习系统在肩部X光片中检测骨折，准确率达95.5%，优于单一模型，适用于临床快速筛查。


<details>
  <summary>Details</summary>
Motivation: 肩部骨折在急诊和高流量临床环境中常被漏诊，AI工具可帮助早期检测并减少诊断延迟。

Method: 使用10,000张标注肩部X光片开发多模型深度学习系统，结合Faster R-CNN、EfficientDet和RF-DETR，并采用边界框和分类级集成技术如Soft-NMS、WBF和NMW融合。

Result: NMW集成方法达到95.5%准确率和0.9610 F1分数，优于所有单一模型，表现出高召回率和定位精度。

Conclusion: 基于集成的AI系统能可靠检测肩部骨折，适合实时诊断流程集成，但当前模型仅支持二元骨折检测，用于快速筛查而非详细分类。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [66] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 通过结合古老的CORONA卫星影像升级深度学习模型，显著提升了考古遗址自动识别的精度，并发现了四个新遗址。


<details>
  <summary>Details</summary>
Motivation: 利用CORONA影像弥补现代环境变迁导致的考古遗址消失问题，提升AI在考古领域的应用效果。

Method: 基于Bing的卷积网络模型，通过CORONA影像对阿布格莱布地区进行重新训练。

Result: 检测精度显著提升（IoU超过85%，整体准确率达90%），并发现四个新遗址。

Conclusion: AI结合CORONA影像是发现已消失考古遗址的有效方法，对考古研究具有重要意义。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [67] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: CaSTFormer是一种因果时空变换器，用于建模驾驶员行为与环境背景的因果关系，提升驾驶意图预测的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以准确建模复杂的时空依赖性和人类驾驶行为的不可预测性，因此需要一种新方法来提升预测的准确性和交互效率。

Method: CaSTFormer采用Reciprocal Shift Fusion（RSF）机制进行时间对齐，Causal Pattern Extraction（CPE）模块消除虚假相关性，以及Feature Synthesis Network（FSN）合成纯净表示。

Result: 在Brain4Cars数据集上，CaSTFormer实现了最先进的性能，有效捕捉了复杂的因果时空依赖性。

Conclusion: CaSTFormer显著提升了驾驶意图预测的准确性和透明度，为高级自动驾驶提供了可靠支持。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [68] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: 该论文提出了PhyWorldBench，一个评估视频生成模型对物理定律遵循程度的基准，涵盖从基础物理现象到复杂场景，并引入“反物理”类别。通过人类评估和MLLM方法，对12种先进模型进行了测试与分析。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型在物理现象模拟方面仍存在挑战，需要系统评估其物理一致性。

Method: 设计了PhyWorldBench基准，包含多级物理现象和“反物理”类别，结合人类评估和MLLM方法。

Result: 测试了12种模型，发现其在遵循物理定律方面存在关键挑战，并提出了改进建议。

Conclusion: PhyWorldBench为评估和提升视频生成模型的物理一致性提供了有效工具，并揭示了改进方向。

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [69] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 提出了一种用于摄影测量点云不确定性量化的框架，通过关联误差协方差矩阵解决多视图立体匹配阶段的未解决问题。


<details>
  <summary>Details</summary>
Motivation: 摄影测量点云的精度高度依赖场景，而多视图立体匹配阶段的不确定性估计尚未标准化，需要一种自监督且符合误差传播路径的方法。

Method: 采用自校准方法，利用可靠的多视图点回归视差不确定性，结合匹配成本值等线索，提供自监督的误差协方差矩阵。

Result: 在多种公开数据集上验证，该方法优于现有方法，实现了高边界率且未高估不确定性。

Conclusion: 提出的框架填补了摄影测量过程中不确定性量化的空白，为点云提供了鲁棒且可验证的精度凭证。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [70] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 提出了一种基于3D卷积自编码器的无监督方法，用于从Sentinel-2卫星图像序列中检测甜菜田的压力状态。


<details>
  <summary>Details</summary>
Motivation: 卫星图像时间序列（SITS）数据因其丰富的频谱和时间特性，在农业任务中表现优异。本研究旨在通过无监督方法解决甜菜田压力检测问题。

Method: 使用3D卷积自编码器从Sentinel-2图像序列中提取特征，并结合特定采集日期的时间编码以捕捉甜菜生长动态。

Result: 学习到的表征用于下游聚类任务，成功区分了压力田和健康田。该系统可直接应用于不同年份的数据。

Conclusion: 该方法为甜菜田压力检测提供了一种实用且易于使用的工具。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [71] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: SparseC-AFM是一种基于深度学习的模型，通过稀疏C-AFM扫描快速重建2D材料的导电性图，显著减少数据采集时间。


<details>
  <summary>Details</summary>
Motivation: 2D材料在纳米电子学中的应用增加，需要高效的电气表征技术，传统AFM方法速度慢。

Method: 提出SparseC-AFM模型，利用稀疏扫描数据快速重建导电性图，适用于多种扫描模式和实验条件。

Result: SparseC-AFM将采集时间减少11倍以上，且预测结果与高分辨率数据一致。

Conclusion: 该技术为AI辅助2D材料表征从实验室研究到工业应用的转化提供了重要进展。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [72] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 提出了一种新的二阶总广义变分（TGV）公式，用于处理嵌入在三维空间中的三角网格上的法向量，并将其与现有方法在网格去噪实验中进行了比较。


<details>
  <summary>Details</summary>
Motivation: 扩展离散TGV模型以处理流形值数据（如单位球上的法向量），并构建适用于流形设置的定制有限元空间。

Method: 构建了一种定制的切向Raviart-Thomas型有限元空间，将离散TGV模型扩展到流形设置。

Result: 新正则化器在网格去噪实验中与现有方法进行了比较。

Conclusion: 提出的方法为处理流形值数据提供了一种有效的TGV扩展，并在网格去噪中表现出潜力。

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [73] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: NABLA提出了一种新型的邻域自适应块级注意力机制，用于视频扩散变换器，显著降低了计算复杂度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决全注意力机制在视频生成任务中的二次计算复杂度问题，特别是针对高分辨率和长时视频序列。

Method: 采用块级注意力机制，结合自适应稀疏驱动阈值，动态适应视频扩散变换器的稀疏模式。

Result: 实验表明，NABLA在训练和推理速度上提升了2.7倍，同时几乎不影响生成质量和量化指标。

Conclusion: NABLA是一种高效且无需定制底层操作设计的注意力机制，适用于视频生成任务。

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [74] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 提出了一种基于LoRA增强的合成重放框架，通过任务特定的低秩适配器改进Stable Diffusion模型，以解决合成样本与真实任务数据不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有合成重放方法生成的样本可能因未能捕捉真实任务的细微语义而误导微调，导致知识保留不足。

Method: 采用LoRA增强的Stable Diffusion模型，结合两阶段置信度样本选择：先筛选真实任务数据，再生成并筛选合成样本。

Result: 在MTIL基准测试中表现优于现有合成重放技术，平衡了可塑性、稳定性和零样本能力。

Conclusion: 通过LoRA适配生成器，显著提升了视觉语言模型的持续学习鲁棒性。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [75] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 提出了一种名为NoiseSDF2NoiseSDF的新方法，通过噪声监督从噪声点云中学习干净的神经SDF，显著提高了表面重建质量。


<details>
  <summary>Details</summary>
Motivation: 低质量扫描设备捕获的点云通常包含大量噪声，导致表面重建不准确，需要一种方法来解决这一问题。

Method: 基于Noise2Noise范式，提出NoiseSDF2NoiseSDF方法，通过最小化噪声SDF表示之间的MSE损失，直接从噪声点云中学习干净的神经SDF。

Result: 在ShapeNet、ABC、Famous和Real等基准测试中，实验结果表明该方法显著提高了噪声输入下的表面重建质量。

Conclusion: NoiseSDF2NoiseSDF是一种有效的3D神经场去噪方法，能够从噪声点云中重建准确的隐式表面表示。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [76] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的框架（\ours），通过从非配对数据中学习空间变化的纹理先验，实现图像去模糊。


<details>
  <summary>Details</summary>
Motivation: 由于获取大量真实的模糊-清晰图像对困难且昂贵，从非配对数据中学习盲图像去模糊更具实用性和前景。现有方法依赖对抗学习，忽略了真实世界模糊模式的复杂性。

Method: 提出Texture Prior Encoder（TPE）和Texture Transfer Transformer层（TTformer），利用扩散模型生成纹理先验，并通过自适应滤波去除空间变化的模糊。

Result: 在广泛使用的基准测试中，\ours表现优于现有最优方法。

Conclusion: \ours为无监督去模糊提供了一种有前景的解决方案。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [77] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的爆发低分辨率图像超分辨率方法，通过随机采样器和知识蒸馏提高效率，显著减少运行时间并保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 爆发低分辨率图像虽能提升超分辨率效果，但现有方法生成的图像模糊且感知质量差，因此需要一种能生成清晰高保真超分辨率图像的方法。

Method: 使用扩散模型结合随机采样器（高阶ODE）和一步扩散（知识蒸馏）来提高效率。

Result: 实验表明，该方法将运行时间降至基线的1.6%，同时保持基于图像失真和感知质量的超分辨率效果。

Conclusion: 该方法在效率和图像质量之间取得了平衡，为爆发低分辨率图像的超分辨率提供了有效解决方案。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [78] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: 论文提出CoTasks框架，通过分解复杂视频问题为四个实体级基础任务，提升视频大语言模型的链式推理能力，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型缺乏细粒度对象级视频理解的链式推理能力，需要结构化标注支持逐步推理。

Method: 提出CoTasks框架，将复杂视频问题分解为帧定位、实体跟踪、时空关系提取四个任务，嵌入中间推理步骤。

Result: 在NeXT-QA基准测试中，LLaVA-video-7B和Qwen2.5-VL-3B性能显著提升，尤其在因果、时序和描述性子类别。

Conclusion: CoTasks作为结构化链式推理监督框架，有效提升视频组合推理能力。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [79] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: FoELS方法通过结合光流和纹理信息，有效分离动态和静态物体，适用于复杂场景和相机运动。


<details>
  <summary>Details</summary>
Motivation: 从移动相机视角分离动态和静态物体对3D重建、自主导航和场景理解至关重要，现有方法依赖光流但效果有限。

Method: FoELS通过计算光流的扩展焦点（FoE），结合纹理信息，生成初始运动似然，并与分割先验融合，估计最终运动概率。

Result: 在DAVIS 2016数据集和真实交通视频中表现优异，达到先进水平。

Conclusion: FoELS能有效处理复杂场景、相机旋转和平行运动，性能优越。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [80] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon提出了一种高效的混合3D头像生成方法，通过空射线省略（ERO）和空区间省略（EIO）策略减少计算成本，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF和SMPL的混合模型因变形方案计算成本高导致推理速度慢，EPSilon旨在通过优化采样策略解决这一问题。

Method: EPSilon采用ERO和EIO两种方法，分别通过剔除空射线和缩小采样区间来减少无效采样点。

Result: EPSilon仅需3.9%的采样点，推理速度提升约20倍，训练收敛速度提升4倍，同时保持生成质量。

Conclusion: EPSilon通过高效的采样策略显著提升了混合模型的性能，为3D头像生成提供了实用的解决方案。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [81] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 本文提出了一个大规模RGB-Event行人重识别数据集EvReID，并提出了TriPro-ReID框架，结合行人属性和对比学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件相机行人重识别方法因数据规模小或模拟数据导致的性能评估和泛化能力不足问题。

Method: 构建EvReID数据集，并提出TriPro-ReID框架，融合RGB和事件流特征，利用行人属性进行对比学习。

Result: 在EvReID和MARS数据集上验证了TriPro-ReID的有效性。

Conclusion: EvReID数据集和TriPro-ReID框架为未来研究提供了数据和基准支持。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [82] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: 提出了一种基于金字塔小波-傅里叶迭代管道的高效图像修复方法PW-FNet，结合多尺度分解和傅里叶变换，显著提升了修复质量和效率。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气条件会降低图像质量，影响下游任务性能。现有基于Transformer的方法虽然有效，但复杂度高，难以实时处理。

Method: PW-FNet采用金字塔小波多输入多输出结构实现多尺度分解，并在块内用傅里叶变换替代自注意力机制，降低计算复杂度。

Result: 在多种图像修复任务中，PW-FNet在修复质量和效率上均优于现有方法，参数和计算成本显著降低。

Conclusion: PW-FNet通过结合小波和傅里叶变换，为图像修复提供了一种高效且高性能的解决方案。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [83] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: 提出MaskHOI框架，通过MAE预训练和区域特定掩码分配，提升3D手-物交互任务中的姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 解决RGB图像几何模糊性和交互中严重遮挡问题。

Method: 采用MAE驱动的预训练框架，引入区域特定掩码分配和骨架驱动的手部掩码指导，结合掩码SDF多模态学习机制。

Result: 显著优于现有方法。

Conclusion: MaskHOI通过几何感知和遮挡鲁棒性学习，有效提升3D手-物交互姿态估计性能。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [84] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一个用于异构传感器配置的V2X协同感知框架，通过分层融合机制和自适应学习策略，显著提升了感知性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构传感器配置下特征融合和感知可靠性的挑战。

Method: 引入分层融合机制（通道和空间注意力）和自适应空间分辨率调整模块，结合动态调整的协同学习策略。

Result: 在TUMTraf-V2X数据集上，HeCoFuse在多种传感器配置下表现优异，3D mAP最高达43.38%，优于基线方法。

Conclusion: HeCoFuse在异构传感器配置下表现出色，成为当前V2X协同感知的先进方法。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [85] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于高斯核的运动测量方法，用于高精度结构健康监测，解决了现有视觉方法在亚像素级测量中精度不足或需手动调参的问题。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测对高精度运动测量的需求日益增长，而现有视觉方法在亚像素级测量中表现不佳。

Method: 开发了一种基于高斯核的运动测量方法，通过跟踪高斯核位置提取帧间运动，并引入运动一致性和超分辨率约束以提高精度和鲁棒性。

Result: 数值和实验验证表明，该方法无需针对不同样本定制参数即可实现高精度测量。

Conclusion: 该方法为结构健康监测提供了一种高精度、无需手动调参的视觉运动测量解决方案。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [86] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 本文提出了两种用于多目标跟踪（MOT）算法性能评估的准度量，分别扩展了GOSPA和T-GOSPA度量，用于衡量对象集和轨迹集的差异。


<details>
  <summary>Details</summary>
Motivation: 现有的GOSPA和T-GOSPA度量在评估MOT算法时缺乏灵活性，无法对不同错误类型（如漏检和误检）施加不同惩罚，且定位误差成本必须对称。本文旨在解决这些问题。

Method: 提出两种准度量：一种扩展GOSPA度量，衡量对象集差异；另一种扩展T-GOSPA度量，衡量轨迹集差异。新度量允许对漏检和误检施加不同成本，且定位误差成本无需对称。

Result: 通过仿真实验，使用T-GOSPA准度量评估了几种贝叶斯MOT算法的性能，验证了新度量的实用性。

Conclusion: 新提出的准度量在MOT评估中更具灵活性，适用于特定应用场景，能够更准确地反映算法性能。

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [87] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 提出了一种无需训练的方法PoemTale Diffusion，通过多阶段提示优化和自注意力机制改进诗歌文本到图像的生成，并引入了P4I数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在复杂、抽象的诗歌语言表达上表现不佳，导致信息丢失。

Method: 采用多阶段提示优化循环和自注意力机制改进模型，生成多张一致性图像以传达诗歌含义。

Result: 通过人类和定量评估验证了方法的有效性，生成图像能更好地捕捉诗歌信息。

Conclusion: PoemTale Diffusion为诗歌到图像生成提供了新视角，并推动了相关研究。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [88] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 提出了一种针对博物馆环境的增强现实流程，通过单张图像识别艺术品并生成精确的3D模型。


<details>
  <summary>Details</summary>
Motivation: 为博物馆提供一种能够增强游客互动体验的数字化工具，解决艺术品复杂轮廓和纹理的3D重建难题。

Method: 结合GLPN和Depth-Anything两种预训练深度估计模型，生成优化的深度图并转换为高质量点云和网格。

Result: 实验结果表明，该方法在重建精度和视觉真实感上有显著提升。

Conclusion: 该系统为博物馆提供了一种高效的增强现实工具，能够显著提升游客的互动体验。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


### [89] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: 本文分析了StyleGAN生成器的内部机制，探讨了其关键架构和技术，揭示了权重修剪的潜力，并研究了潜在向量对生成图像的影响，同时指出了技术滥用的伦理问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成图像的普及，理解StyleGAN的工作原理及其潜在风险变得尤为重要。

Method: 通过PyTorch框架训练StyleGAN模型，详细分析其架构（如均衡学习率）和权重修剪效果，并研究潜在向量的作用。

Result: 研究发现许多权重可修剪而不显著影响输出，潜在向量的全局和局部调整分别影响颜色和具体面部特征。

Conclusion: StyleGAN的精细控制能力具有学术价值，但也可能被恶意利用，引发严重的伦理和安全问题。

Abstract: In today's digital age, concerns about the dangers of AI-generated images are
increasingly common. One powerful tool in this domain is StyleGAN (style-based
generative adversarial networks), a generative adversarial network capable of
producing highly realistic synthetic faces. To gain a deeper understanding of
how such a model operates, this work focuses on analyzing the inner workings of
StyleGAN's generator component. Key architectural elements and techniques, such
as the Equalized Learning Rate, are explored in detail to shed light on the
model's behavior. A StyleGAN model is trained using the PyTorch framework,
enabling direct inspection of its learned weights. Through pruning, it is
revealed that a significant number of these weights can be removed without
drastically affecting the output, leading to reduced computational
requirements. Moreover, the role of the latent vector -- which heavily
influences the appearance of the generated faces -- is closely examined. Global
alterations to this vector primarily affect aspects like color tones, while
targeted changes to individual dimensions allow for precise manipulation of
specific facial features. This ability to finetune visual traits is not only of
academic interest but also highlights a serious ethical concern: the potential
misuse of such technology. Malicious actors could exploit this capability to
fabricate convincing fake identities, posing significant risks in the context
of digital deception and cybercrime.

</details>


### [90] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: Diffusion-FSCIL利用冻结的文本到图像扩散模型解决小样本类增量学习问题，通过多尺度特征提取和潜在重放提升性能。


<details>
  <summary>Details</summary>
Motivation: 小样本类增量学习（FSCIL）面临训练数据极少和灾难性遗忘的挑战，需平衡新知识学习和旧知识保留。

Method: 采用冻结的扩散模型作为主干，提取多尺度互补特征作为潜在重放，辅以特征蒸馏减少生成偏差。

Result: 在CUB-200、miniImageNet和CIFAR-100上表现优于现有方法，有效保留旧类性能并适应新类。

Conclusion: Diffusion-FSCIL通过冻结主干和最小化训练组件，实现了高效且性能优越的小样本类增量学习。

Abstract: Few-shot class-incremental learning (FSCIL) is challenging due to extremely
limited training data; while aiming to reduce catastrophic forgetting and learn
new information. We propose Diffusion-FSCIL, a novel approach that employs a
text-to-image diffusion model as a frozen backbone. Our conjecture is that
FSCIL can be tackled using a large generative model's capabilities benefiting
from 1) generation ability via large-scale pre-training; 2) multi-scale
representation; 3) representational flexibility through the text encoder. To
maximize the representation capability, we propose to extract multiple
complementary diffusion features to play roles as latent replay with slight
support from feature distillation for preventing generative biases. Our
framework realizes efficiency through 1) using a frozen backbone; 2) minimal
trainable components; 3) batch processing of multiple feature extractions.
Extensive experiments on CUB-200, \emph{mini}ImageNet, and CIFAR-100 show that
Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on
previously learned classes and adapting effectively to new ones.

</details>


### [91] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: EVS是一种无需训练的封装视频合成器，结合T2I和T2V模型，提升生成视频的视觉保真度和运动平滑性。


<details>
  <summary>Details</summary>
Motivation: 现有T2V模型在生成高质量视频时面临成像质量和运动表现不一致的挑战，如闪烁和伪影。

Method: 利用预训练的T2I扩散模型优化低质量视频帧，同时结合T2V模型确保运动一致性。

Result: 实验显示EVS显著提升了视频质量和推理速度（1.6x-4.5x加速）。

Conclusion: EVS通过结合T2I和T2V模型的优势，有效解决了视频合成的关键问题。

Abstract: In recent years, large text-to-video (T2V) synthesis models have garnered
considerable attention for their abilities to generate videos from textual
descriptions. However, achieving both high imaging quality and effective motion
representation remains a significant challenge for these T2V models. Existing
approaches often adapt pre-trained text-to-image (T2I) models to refine video
frames, leading to issues such as flickering and artifacts due to
inconsistencies across frames. In this paper, we introduce EVS, a training-free
Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both
visual fidelity and motion smoothness of generated videos. Our approach
utilizes a well-trained diffusion-based T2I model to refine low-quality video
frames by treating them as out-of-distribution samples, effectively optimizing
them with noising and denoising steps. Meanwhile, we employ T2V backbones to
ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior
into the T2I generation process, EVS successfully leverages the strengths of
both types of models, resulting in videos of improved imaging and motion
quality. Experimental results validate the effectiveness of our approach
compared to previous approaches. Our composition process also leads to a
significant improvement of 1.6x-4.5x speedup in inference time. Source codes:
https://github.com/Tonniia/EVS.

</details>


### [92] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的光谱扩散先验（SDP）和光谱先验注入模块（SPIM），显著提升了高光谱图像（HSI）重建的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以准确捕捉高光谱图像的高频细节，因此需要一种更有效的方法来提升重建质量。

Method: 通过扩散模型隐式学习光谱扩散先验（SDP），并设计光谱先验注入模块（SPIM）动态引导模型恢复细节。

Result: 在MST和BISRNet两种代表性HSI方法上，性能提升约0.5 dB。

Conclusion: 提出的SDP和SPIM有效提升了HSI重建的细节恢复能力，性能优于现有方法。

Abstract: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.

</details>


### [93] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: ClearVQA 是一个新的基准测试，旨在解决视觉问答（VQA）中用户提问的模糊性问题，通过交互式澄清而非仅重述问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要通过重述问题解决模糊性，忽略了用户与视觉语言模型（VLMs）的交互性。ClearVQA 填补了交互式澄清的评估空白。

Method: 引入 ClearVQA 基准测试，针对 VQA 中三类常见模糊性，并覆盖多种 VQA 场景。

Result: ClearVQA 为评估 VLMs 通过交互解决模糊性的能力提供了工具。

Conclusion: ClearVQA 解决了交互式澄清的评估和模型偏好问题，推动了 VQA 中模糊性处理的研究。

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [94] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 该论文提出了一种基于排列熵（PE）的轻量级图像分类方法，结合HOG和LBP特征，通过SVM分类器在多个基准数据集上实现了与深度学习模型竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索一种计算高效且可解释的图像分类方法，避免依赖参数庞大的深度学习模型。

Method: 方法包括将PE扩展到二维图像，结合HOG和LBP提取特征，训练SVM分类器。

Result: 在多个数据集（如Fashion-MNIST、CIFAR-10）上表现出色，证明了该方法的有效性。

Conclusion: 结论表明，基于熵的特征结合传统描述符为图像分类提供了一种轻量级且可解释的解决方案。

Abstract: Feature engineering continues to play a critical role in image
classification, particularly when interpretability and computational efficiency
are prioritized over deep learning models with millions of parameters. In this
study, we revisit classical machine learning based image classification through
a novel approach centered on Permutation Entropy (PE), a robust and
computationally lightweight measure traditionally used in time series analysis
but rarely applied to image data. We extend PE to two-dimensional images and
propose a multiscale, multi-orientation entropy-based feature extraction
approach that characterizes spatial order and complexity along rows, columns,
diagonals, anti-diagonals, and local patches of the image. To enhance the
discriminatory power of the entropy features, we integrate two classic image
descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and
edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an
image. The resulting hand-crafted feature set, comprising of 780 dimensions, is
used to train Support Vector Machine (SVM) classifiers optimized through grid
search. The proposed approach is evaluated on multiple benchmark datasets,
including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers
competitive classification performance without relying on deep architectures.
Our results demonstrate that the fusion of PE with HOG and LBP provides a
compact, interpretable, and effective alternative to computationally expensive
and limited interpretable deep learning models. This shows a potential of
entropy-based descriptors in image classification and contributes a lightweight
and generalizable solution to interpretable machine learning in image
classification and computer vision.

</details>


### [95] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 提出了一种自动化流水线，用于生成高质量图像编辑三元组（原始图像、指令、编辑图像），解决了数据标注难题，并发布了开源数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 生成式模型需要大量高质量的三元组数据，但手动标注成本高且难以满足像素级精度要求。

Method: 利用公共生成模型和任务调优的验证器自动生成和评分三元组，通过反转和组合扩展数据集。

Result: 发布了包含358k高质量三元组的NHR-Edit数据集，并在实验中验证其优于其他公开数据集。

Conclusion: 自动化方法显著降低了数据标注成本，推动了生成式模型的研究和应用。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


### [96] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 论文提出了一种显式可微分聚类模块，用于半监督学习和无监督域适应，通过利用监督数据计算聚类中心，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 半监督学习和无监督域适应通过利用标记和未标记数据提升模型性能，但现有方法通常隐式地利用聚类假设。本文旨在显式地引入可微分聚类模块，以更有效地利用监督数据。

Method: 提出了一种显式可微分聚类模块，扩展了监督数据以计算聚类中心，并通过端到端训练策略实现。

Result: 实验表明该方法在半监督学习和无监督域适应任务中表现优异，尤其在低监督条件下，既可作为独立模型，也可作为现有方法的正则化工具。

Conclusion: 显式引入可微分聚类模块是一种简单有效的策略，能够显著提升半监督学习和无监督域适应的性能。

Abstract: Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)
enhance the model performance by exploiting information from labeled and
unlabeled data. The clustering assumption has proven advantageous for learning
with limited supervision and states that data points belonging to the same
cluster in a high-dimensional space should be assigned to the same category.
Recent works have utilized different training mechanisms to implicitly enforce
this assumption for the SSL and UDA. In this work, we take a different approach
by explicitly involving a differentiable clustering module which is extended to
leverage the supervised data to compute its centroids. We demonstrate the
effectiveness of our straightforward end-to-end training strategy for SSL and
UDA over extensive experiments and highlight its benefits, especially in low
supervision regimes, both as a standalone model and as a regularizer for
existing approaches.

</details>


### [97] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: 提出了一种名为LoFNO的新型3D架构，用于提高血流动力学的时空分辨率，并直接从临床影像数据预测壁面剪切应力（WSS）。


<details>
  <summary>Details</summary>
Motivation: 磁共振血流成像的低时空分辨率和信噪比限制了其诊断价值，因此需要一种更高效的方法。

Method: LoFNO结合拉普拉斯特征向量作为几何先验，增强对不规则几何结构的感知，并采用EDSR层进行鲁棒的上采样。

Result: LoFNO在去噪和时空上采样方面表现优异，预测速度和WSS的效果优于插值和其他深度学习方法。

Conclusion: LoFNO为脑血管诊断提供了更精确的工具。

Abstract: Hemodynamic analysis is essential for predicting aneurysm rupture and guiding
treatment. While magnetic resonance flow imaging enables time-resolved
volumetric blood velocity measurements, its low spatiotemporal resolution and
signal-to-noise ratio limit its diagnostic utility. To address this, we propose
the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that
enhances both spatial and temporal resolution with the ability to predict wall
shear stress (WSS) directly from clinical imaging data. LoFNO integrates
Laplacian eigenvectors as geometric priors for improved structural awareness on
irregular, unseen geometries and employs an Enhanced Deep Super-Resolution
Network (EDSR) layer for robust upsampling. By combining geometric priors with
neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow
data, achieving superior velocity and WSS predictions compared to interpolation
and alternative deep learning methods, enabling more precise cerebrovascular
diagnostics.

</details>


### [98] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: DynFaceRestore提出了一种动态选择扩散起始时间步和局部调整引导强度的新方法，以解决盲脸修复中保真度与质量的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在盲脸修复中常因固定扩散采样时间步和全局引导尺度导致保真度与质量失衡。

Method: 通过将退化输入映射到高斯模糊图像，动态选择起始时间步，并应用闭式引导和动态引导缩放调整器。

Result: DynFaceRestore在定量和定性评估中均达到最先进性能。

Conclusion: 该方法有效平衡了保真度与质量，展示了盲脸修复的鲁棒性和有效性。

Abstract: Blind Face Restoration aims to recover high-fidelity, detail-rich facial
images from unknown degraded inputs, presenting significant challenges in
preserving both identity and detail. Pre-trained diffusion models have been
increasingly used as image priors to generate fine details. Still, existing
methods often use fixed diffusion sampling timesteps and a global guidance
scale, assuming uniform degradation. This limitation and potentially imperfect
degradation kernel estimation frequently lead to under- or over-diffusion,
resulting in an imbalance between fidelity and quality. We propose
DynFaceRestore, a novel blind face restoration approach that learns to map any
blindly degraded input to Gaussian blurry images. By leveraging these blurry
images and their respective Gaussian kernels, we dynamically select the
starting timesteps for each blurry image and apply closed-form guidance during
the diffusion sampling process to maintain fidelity. Additionally, we introduce
a dynamic guidance scaling adjuster that modulates the guidance strength across
local regions, enhancing detail generation in complex areas while preserving
structural fidelity in contours. This strategy effectively balances the
trade-off between fidelity and quality. DynFaceRestore achieves
state-of-the-art performance in both quantitative and qualitative evaluations,
demonstrating robustness and effectiveness in blind face restoration.

</details>


### [99] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: 论文提出了一种名为CF-SSC的新型时序3D语义场景补全框架，通过预测伪未来帧扩展感知范围，解决了现有单目方法在遮挡和视野外场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D语义场景补全方法在真实交通场景中因遮挡和视野限制表现不佳，需要一种能扩展感知范围的方法。

Method: 结合位姿和深度建立3D对应关系，通过几何一致性融合过去、当前和预测的未来帧，显式建模时空关系。

Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试中达到最先进性能，显著提升了遮挡推理和场景补全准确性。

Conclusion: CF-SSC框架通过时空建模和未来帧预测，有效提升了3D语义场景补全的性能，适用于自动驾驶场景。

Abstract: In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a
critical perception task for autonomous driving due to its ability to infer
complete 3D scene layouts and semantics from single 2D images. However, in
real-world traffic scenarios, a significant portion of the scene remains
occluded or outside the camera's field of view -- a fundamental challenge that
existing monocular SSC methods fail to address adequately. To overcome these
limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC
framework that leverages pseudo-future frame prediction to expand the model's
effective perceptual range. Our approach combines poses and depths to establish
accurate 3D correspondences, enabling geometrically-consistent fusion of past,
present, and predicted future frames in 3D space. Unlike conventional methods
that rely on simple feature stacking, our 3D-aware architecture achieves more
robust scene completion by explicitly modeling spatial-temporal relationships.
Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks
demonstrate state-of-the-art performance, validating the effectiveness of our
approach, highlighting our method's ability to improve occlusion reasoning and
3D scene completion accuracy.

</details>


### [100] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: GRAM-MAMBA框架通过线性复杂度的Mamba模型和优化的GRAM矩阵策略，解决了多模态融合中的效率、模态对齐和缺失数据问题，实验验证了其高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合系统在资源受限环境中部署困难，模态对齐不充分且对缺失数据鲁棒性差，亟需高效、鲁棒的解决方案。

Method: 结合Mamba模型处理时间序列数据，优化GRAM矩阵实现模态对齐，引入低秩自适应层补偿缺失模态。

Result: 在SPAWC2021和USC-HAD数据集上表现优异，误差更低、性能提升显著，且仅需微调少量参数。

Conclusion: GRAM-MAMBA为资源受限环境中的多模态感知提供了高效、鲁棒的解决方案。

Abstract: Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely
deployed in smart homes, intelligent transport, industrial automation, and
healthcare. However, existing systems often face challenges: high model
complexity hinders deployment in resource-constrained environments,
unidirectional modal alignment neglects inter-modal relationships, and
robustness suffers when sensor data is missing. These issues impede efficient
and robust multimodal perception in real-world IoT settings. To overcome these
limitations, we propose GRAM-MAMBA. This framework utilizes the
linear-complexity Mamba model for efficient sensor time-series processing,
combined with an optimized GRAM matrix strategy for pairwise alignment among
modalities, addressing the shortcomings of traditional single-modality
alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive
low-rank layer compensation strategy to handle missing modalities
post-training. This strategy freezes the pre-trained model core and irrelevant
adaptive layers, fine-tuning only those related to available modalities and the
fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On
the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower
error than baselines; adapting to missing modalities yields a 24.5% performance
boost by training less than 0.2% of parameters. On the USC-HAD human activity
recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),
outperforming prior work; the update strategy increases F1 by 23% while
training less than 0.3% of parameters. These results highlight GRAM-MAMBA's
potential for achieving efficient and robust multimodal perception in
resource-constrained environments.

</details>


### [101] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2是一个统一的多模态遥感基础模型，通过单一Transformer主干处理多模态数据，采用自适应SSL策略和MoE模块，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需为每种数据模态训练单独的主干网络，导致冗余和低效，且SSL方法未充分考虑遥感图像特性。

Method: 使用单一Transformer主干，结合自适应patch合并模块、可学习模态提示token和MoE模块。

Result: 在7个任务的16个数据集上评估，平均性能提升1.8分。

Conclusion: SkySense V2通过统一架构和针对性SSL策略，有效解决了多模态遥感任务中的挑战。

Abstract: The multi-modal remote sensing foundation model (MM-RSFM) has significantly
advanced various Earth observation tasks, such as urban planning, environmental
monitoring, and natural disaster management. However, most existing approaches
generally require the training of separate backbone networks for each data
modality, leading to redundancy and inefficient parameter utilization.
Moreover, prevalent pre-training methods typically apply self-supervised
learning (SSL) techniques from natural images without adequately accommodating
the characteristics of remote sensing (RS) images, such as the complicated
semantic distribution within a single RS image. In this work, we present
SkySense V2, a unified MM-RSFM that employs a single transformer backbone to
handle multiple modalities. This backbone is pre-trained with a novel SSL
strategy tailored to the distinct traits of RS data. In particular, SkySense V2
incorporates an innovative adaptive patch merging module and learnable modality
prompt tokens to address challenges related to varying resolutions and limited
feature diversity across modalities. In additional, we incorporate the mixture
of experts (MoE) module to further enhance the performance of the foundation
model. SkySense V2 demonstrates impressive generalization abilities through an
extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense
by an average of 1.8 points.

</details>


### [102] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的开放视频问答框架，通过多模型协作提升推理深度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频-语言模型在上下文理解、时间建模和复杂查询泛化方面表现不足。

Method: 引入提示与响应集成机制，协调多个异构视频-语言模型，结合外部大语言模型评估和整合结果。

Result: 在CVRR-ES数据集上显著优于基线模型，展示出更强的泛化和鲁棒性。

Conclusion: 提供了一种轻量级、可扩展的多模态推理策略，无需重新训练模型，为未来视频-语言模型发展奠定基础。

Abstract: We propose a novel framework for open-ended video question answering that
enhances reasoning depth and robustness in complex real-world scenarios, as
benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models
(Video-LMMs) often exhibit limited contextual understanding, weak temporal
modeling, and poor generalization to ambiguous or compositional queries. To
address these challenges, we introduce a prompting-and-response integration
mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)
via structured chains of thought, each tailored to distinct reasoning pathways.
An external Large Language Model (LLM) serves as an evaluator and integrator,
selecting and fusing the most reliable responses. Extensive experiments
demonstrate that our method significantly outperforms existing baselines across
all evaluation metrics, showcasing superior generalization and robustness. Our
approach offers a lightweight, extensible strategy for advancing multimodal
reasoning without requiring model retraining, setting a strong foundation for
future Video-LMM development.

</details>


### [103] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 论文探讨了在突尼斯城市景观中，使用Quanvolution预处理增强Attention U-Net模型在建筑分割中的能力，结果表明该方法在保持精度的同时减少了网络参数。


<details>
  <summary>Details</summary>
Motivation: 城市建筑分割在规划、灾害响应等领域至关重要，但高分辨率卫星图像的处理存在挑战。

Method: 采用Quanvolution预处理提取SAR图像特征，结合Attention U-Net模型进行建筑分割。

Result: 方法在测试精度上与标准模型相当，同时显著减少了网络参数，提高了计算效率。

Conclusion: 量子辅助深度学习框架在大规模城市建筑分割中具有潜力。

Abstract: Building segmentation in urban areas is essential in fields such as urban
planning, disaster response, and population mapping. Yet accurately segmenting
buildings in dense urban regions presents challenges due to the large size and
high resolution of satellite images. This study investigates the use of a
Quanvolutional pre-processing to enhance the capability of the Attention U-Net
model in the building segmentation. Specifically, this paper focuses on the
urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)
imagery. In this work, Quanvolution was used to extract more informative
feature maps that capture essential structural details in radar imagery,
proving beneficial for accurate building segmentation. Preliminary results
indicate that proposed methodology achieves comparable test accuracy to the
standard Attention U-Net model while significantly reducing network parameters.
This result aligns with findings from previous works, confirming that
Quanvolution not only maintains model accuracy but also increases computational
efficiency. These promising outcomes highlight the potential of
quantum-assisted Deep Learning frameworks for large-scale building segmentation
in urban environments.

</details>


### [104] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: Depth3DLane提出了一种双路径框架，结合自监督单目深度估计，无需昂贵传感器或额外深度数据，实现了准确的3D车道检测。


<details>
  <summary>Details</summary>
Motivation: 单目3D车道检测因缺乏显式空间信息而具有挑战性，现有方法依赖昂贵传感器或地面真实深度数据，且需已知相机参数，限制了应用场景。

Method: 采用双路径框架：鸟瞰路径提取空间信息，前视路径提取语义信息，结合3D车道锚点采样特征，并预测每帧相机参数以增强稳定性。

Result: 在OpenLane基准数据集上表现优异，且无需地面真实相机参数即可应用。

Conclusion: Depth3DLane解决了现有方法的局限性，适用于相机标定不可行的场景。

Abstract: Monocular 3D lane detection is essential for autonomous driving, but
challenging due to the inherent lack of explicit spatial information.
Multi-modal approaches rely on expensive depth sensors, while methods
incorporating fully-supervised depth networks rely on ground-truth depth data
that is impractical to collect at scale. Additionally, existing methods assume
that camera parameters are available, limiting their applicability in scenarios
like crowdsourced high-definition (HD) lane mapping. To address these
limitations, we propose Depth3DLane, a novel dual-pathway framework that
integrates self-supervised monocular depth estimation to provide explicit
structural information, without the need for expensive sensors or additional
ground-truth depth data. Leveraging a self-supervised depth network to obtain a
point cloud representation of the scene, our bird's-eye view pathway extracts
explicit spatial information, while our front view pathway simultaneously
extracts rich semantic information. Depth3DLane then uses 3D lane anchors to
sample features from both pathways and infer accurate 3D lane geometry.
Furthermore, we extend the framework to predict camera parameters on a
per-frame basis and introduce a theoretically motivated fitting procedure to
enhance stability on a per-segment basis. Extensive experiments demonstrate
that Depth3DLane achieves competitive performance on the OpenLane benchmark
dataset. Furthermore, experimental results show that using learned parameters
instead of ground-truth parameters allows Depth3DLane to be applied in
scenarios where camera calibration is infeasible, unlike previous methods.

</details>


### [105] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: PositionIC框架通过双向生成范式实现多主题图像定制中的精确空间控制，解决了现有方法在实体级空间控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有主题驱动图像定制方法在保真度上取得进展，但缺乏细粒度实体级空间控制，限制了实际应用。

Method: 提出PositionIC框架，构建可扩展的合成管道，采用双向生成范式消除主题漂移，并设计轻量级位置调制层解耦空间嵌入。

Result: 实验表明，PositionIC能实现精确空间控制，同时保持图像定制任务的高一致性。

Conclusion: PositionIC为开放世界多实体场景下的可控高保真图像定制提供了新思路，并将开源以促进研究。

Abstract: Recent subject-driven image customization has achieved significant
advancements in fidelity, yet fine-grained entity-level spatial control remains
elusive, hindering the broader real-world application. This limitation is
mainly attributed to scalable datasets that bind identity with precise
positional cues are absent. To this end, we introduce PositionIC, a unified
framework that enforces position and identity consistency for multi-subject
customization. We construct a scalable synthesis pipeline that employs a
bidirectional generation paradigm to eliminate subject drift and maintain
semantic coherence. On top of these data, we design a lightweight positional
modulation layer that decouples spatial embeddings among subjects, enabling
independent, accurate placement while preserving visual fidelity. Extensive
experiments demonstrate that our approach can achieve precise spatial control
while maintaining high consistency in image customization task. PositionIC
paves the way for controllable, high-fidelity image customization in
open-world, multi-entity scenarios and will be released to foster further
research.

</details>


### [106] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型（VLMs）在处理内部参数知识与外部信息冲突时的机制，通过引入多模态反事实查询数据集，定位了控制冲突的关键头部，并通过修改这些头部来引导模型行为。


<details>
  <summary>Details</summary>
Motivation: 解决VLMs在处理知识冲突时产生的幻觉和不可靠响应问题，探索其机制。

Method: 引入多模态反事实查询数据集，通过logit检查定位关键头部，并修改这些头部以引导模型行为。

Result: 定位到控制冲突的小部分头部，修改后可引导模型偏向内部知识或视觉输入，且注意力机制优于梯度归因。

Conclusion: 研究揭示了VLMs处理知识冲突的机制，为模型优化提供了新方向。

Abstract: Vision-language models (VLMs) increasingly leverage diverse knowledge sources
to address complex tasks, often encountering conflicts between their internal
parametric knowledge and external information. Knowledge conflicts can result
in hallucinations and unreliable responses, but the mechanisms governing such
interactions remain unknown. To address this gap, we analyze the mechanisms
that VLMs use to resolve cross-modal conflicts by introducing a dataset of
multimodal counterfactual queries that deliberately contradict internal
commonsense knowledge. We localize with logit inspection a small set of heads
that control the conflict. Moreover, by modifying these heads, we can steer the
model towards its internal knowledge or the visual inputs. Finally, we show
that attention from such heads pinpoints localized image regions driving visual
overrides, outperforming gradient-based attribution in precision.

</details>


### [107] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: 提出了一种通过融合实时视觉数据和海图信息来增强海洋视觉的新方法，利用基于Transformer的神经网络实现目标检测与匹配。


<details>
  <summary>Details</summary>
Motivation: 解决动态和挑战性海洋环境中目标定位和关联的准确性问题。

Method: 采用基于Transformer的端到端神经网络，预测浮标查询的边界框和置信度分数，直接匹配图像检测与世界空间海图标记。

Result: 实验结果表明，该方法在真实海洋场景中显著提高了目标定位和关联的准确性。

Conclusion: 该方法优于基线方法，适用于动态和挑战性环境。

Abstract: This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.

</details>


### [108] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: PCR-GS是一种无需COLMAP的3D高斯泼溅技术，通过相机姿态共正则化提升复杂场景下的3D建模和相机姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有3D-GS技术在复杂相机轨迹下表现不佳，导致相机姿态估计和联合优化问题。

Method: 提出特征重投影正则化和基于小波的高频正则化，分别从语义对齐和高频细节优化相机姿态。

Result: 实验表明PCR-GS在剧烈变化的相机轨迹下实现了优越的无姿态3D-GS场景建模。

Conclusion: PCR-GS通过双重视角正则化显著提升了复杂场景下的3D建模和相机姿态估计性能。

Abstract: COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing
attention due to its remarkable performance in reconstructing high-quality 3D
scenes from unposed images or videos. However, it often struggles to handle
scenes with complex camera trajectories as featured by drastic rotation and
translation across adjacent camera views, leading to degraded estimation of
camera poses and further local minima in joint optimization of camera poses and
3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that
achieves superior 3D scene modeling and camera pose estimation via camera pose
co-regularization. PCR-GS achieves regularization from two perspectives. The
first is feature reprojection regularization which extracts view-robust DINO
features from adjacent camera views and aligns their semantic information for
camera pose regularization. The second is wavelet-based frequency
regularization which exploits discrepancy in high-frequency details to further
optimize the rotation matrix in camera poses. Extensive experiments over
multiple real-world scenes show that the proposed PCR-GS achieves superior
pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.

</details>


### [109] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 论文提出了一种利用DepthAnything生成的深度先验增强LiDAR点云特征的方法，通过双路径RoI特征提取和双向门控融合模块，显著提升了3D目标检测的精度。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云特征表达能力有限，尤其是反射率属性的区分能力较弱，而DepthAnything提供的密集深度先验可以弥补这一不足。

Method: 融合DepthAnything的深度先验与LiDAR原始属性，提出点级特征提取模块和双路径RoI特征提取框架，结合双向门控RoI特征融合模块。

Result: 在KITTI基准测试中，检测精度显著提升。

Conclusion: 将视觉基础模型的先验融入LiDAR 3D目标检测具有重要价值。

Abstract: Recent advances in foundation models have opened up new possibilities for
enhancing 3D perception. In particular, DepthAnything offers dense and reliable
geometric priors from monocular RGB images, which can complement sparse LiDAR
data in autonomous driving scenarios. However, such priors remain underutilized
in LiDAR-based 3D object detection. In this paper, we address the limited
expressiveness of raw LiDAR point features, especially the weak discriminative
capability of the reflectance attribute, by introducing depth priors predicted
by DepthAnything. These priors are fused with the original LiDAR attributes to
enrich each point's representation. To leverage the enhanced point features, we
propose a point-wise feature extraction module. Then, a Dual-Path RoI feature
extraction framework is employed, comprising a voxel-based branch for global
semantic context and a point-based branch for fine-grained structural details.
To effectively integrate the complementary RoI features, we introduce a
bidirectional gated RoI feature fusion module that balances global and local
cues. Extensive experiments on the KITTI benchmark show that our method
consistently improves detection accuracy, demonstrating the value of
incorporating visual foundation model priors into LiDAR-based 3D object
detection.

</details>


### [110] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF是一种通用的神经渲染方法，能够在任意视角和时间下渲染新视图，即使输入视图较少。它结合多视角立体、神经辐射场和解耦策略，实现少样本泛化能力，并能构建任意时间的神经辐射场。


<details>
  <summary>Details</summary>
Motivation: 解决现有NeRF技术在时间维度上建模的不足，满足元宇宙等应用对动态3D场景的需求。

Method: 结合多视角立体、神经辐射场和解耦策略，构建隐式内容辐射场，支持少样本泛化和任意时间建模。

Result: TimeNeRF在少样本设置下无需逐场景优化即可渲染新视图，并能平滑过渡不同时间的光照变化。

Conclusion: TimeNeRF为动态3D场景建模提供了高效且通用的解决方案，尤其在时间维度上表现出色。

Abstract: We present TimeNeRF, a generalizable neural rendering approach for rendering
novel views at arbitrary viewpoints and at arbitrary times, even with few input
views. For real-world applications, it is expensive to collect multiple views
and inefficient to re-optimize for unseen scenes. Moreover, as the digital
realm, particularly the metaverse, strives for increasingly immersive
experiences, the ability to model 3D environments that naturally transition
between day and night becomes paramount. While current techniques based on
Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing
novel views, the exploration of NeRF's potential for temporal 3D scene modeling
remains limited, with no dedicated datasets available for this purpose. To this
end, our approach harnesses the strengths of multi-view stereo, neural radiance
fields, and disentanglement strategies across diverse datasets. This equips our
model with the capability for generalizability in a few-shot setting, allows us
to construct an implicit content radiance field for scene representation, and
further enables the building of neural radiance fields at any arbitrary time.
Finally, we synthesize novel views of that time via volume rendering.
Experiments show that TimeNeRF can render novel views in a few-shot setting
without per-scene optimization. Most notably, it excels in creating realistic
novel views that transition smoothly across different times, adeptly capturing
intricate natural scene changes from dawn to dusk.

</details>


### [111] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一种端到端视频扩散框架，用于显式分离静态外观和动态运动，通过全局静态标记和帧特定动态标记实现，并在解码器中引入关键归纳偏置。


<details>
  <summary>Details</summary>
Motivation: 现有基于VAE和GAN的方法存在信息泄漏和模糊重建问题，DiViD旨在解决这些挑战。

Method: DiViD使用序列编码器提取全局静态标记和帧特定动态标记，解码器采用共享噪声计划、时变KL瓶颈和交叉注意力机制。

Result: DiViD在真实基准测试中表现优于现有方法，实现了最高的交换联合准确率，并减少了交叉泄漏。

Conclusion: DiViD通过显式静态-动态分解，显著提升了视频中静态和动态内容的分离效果。

Abstract: Unsupervised disentanglement of static appearance and dynamic motion in video
remains a fundamental challenge, often hindered by information leakage and
blurry reconstructions in existing VAE- and GAN-based approaches. We introduce
DiViD, the first end-to-end video diffusion framework for explicit
static-dynamic factorization. DiViD's sequence encoder extracts a global static
token from the first frame and per-frame dynamic tokens, explicitly removing
static content from the motion code. Its conditional DDPM decoder incorporates
three key inductive biases: a shared-noise schedule for temporal consistency, a
time-varying KL-based bottleneck that tightens at early timesteps (compressing
static information) and relaxes later (enriching dynamics), and cross-attention
that routes the global static token to all frames while keeping dynamic tokens
frame-specific. An orthogonality regularizer further prevents residual
static-dynamic leakage. We evaluate DiViD on real-world benchmarks using
swap-based accuracy and cross-leakage metrics. DiViD outperforms
state-of-the-art sequential disentanglement methods: it achieves the highest
swap-based joint accuracy, preserves static fidelity while improving dynamic
transfer, and reduces average cross-leakage.

</details>


### [112] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 研究发现视觉模型的感知能力与其短期预测性能强相关，提出了一种通用预测框架，通过潜在扩散模型预测未来特征，并在多个任务中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索视觉模型的感知能力与预测性能之间的关系，以提升通用系统的预测能力。

Method: 提出通用预测框架，利用潜在扩散模型在冻结视觉骨干网络上预测未来特征，并通过轻量级任务特定解码器实现。

Result: 在九个模型和四个任务中验证了框架的有效性，表明感知能力与预测性能强相关。

Conclusion: 结合表征学习和生成模型对视频理解具有重要意义。

Abstract: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.

</details>


### [113] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 本文提出了一种评估视觉隐私保护方法的框架，并发布了HR-VISPR数据集，用于训练可解释的隐私度量。


<details>
  <summary>Details</summary>
Motivation: AI驱动的监控技术引发了对敏感个人数据处理的担忧，需要客观评估隐私保护方法。

Method: 提出了一个综合框架，从隐私性、实用性和实用性三个维度评估11种隐私保护方法，并引入HR-VISPR数据集。

Result: 框架能够区分隐私级别，并与人类视觉感知一致，同时揭示了隐私、实用性和实用性之间的权衡。

Conclusion: 该研究和数据集为隐私保护提供了结构化评估工具，适用于多种场景。

Abstract: Recent advances in AI-powered surveillance have intensified concerns over the
collection and processing of sensitive personal data. In response, research has
increasingly focused on privacy-by-design solutions, raising the need for
objective techniques to evaluate privacy protection. This paper presents a
comprehensive framework for evaluating visual privacy-protection methods across
three dimensions: privacy, utility, and practicality. In addition, it
introduces HR-VISPR, a publicly available human-centric dataset with biometric,
soft-biometric, and non-biometric labels to train an interpretable privacy
metric. We evaluate 11 privacy protection methods, ranging from conventional
techniques to advanced deep-learning methods, through the proposed framework.
The framework differentiates privacy levels in alignment with human visual
perception, while highlighting trade-offs between privacy, utility, and
practicality. This study, along with the HR-VISPR dataset, serves as an
insightful tool and offers a structured evaluation framework applicable across
diverse contexts.

</details>


### [114] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉自回归模型（VAR）的内容-风格分解方法CSD-VAR，通过尺度感知优化、SVD校正和增强键值记忆提升分解效果，并在新数据集CSD-100上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有内容-风格分解方法主要针对扩散模型，而VAR作为一种新兴生成框架，其尺度化生成过程可能更适合分解任务。

Method: 提出CSD-VAR方法，包括尺度感知交替优化、SVD校正和增强键值记忆三项创新。

Result: 实验表明CSD-VAR在内容保留和风格化保真度上优于现有方法。

Conclusion: CSD-VAR为内容-风格分解提供了高效解决方案，并展示了VAR在此任务中的潜力。

Abstract: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.

</details>


### [115] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene是一个端到端框架，通过文本或对话生成高质量、可编辑的3D场景，解决了现有方法在自动化、3D一致性和细粒度控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 自然语言生成3D场景在游戏、电影和设计中有广泛应用，但现有方法在自动化、一致性和控制性上存在挑战。

Method: DreamScene结合GPT-4代理推断语义和空间约束，构建混合图；通过图布局算法生成结构化布局；采用FPS生成几何；使用渐进相机采样确保一致性；支持细粒度编辑。

Result: 实验表明，DreamScene在质量、一致性和灵活性上优于现有方法。

Conclusion: DreamScene为开放域3D内容创作提供了实用解决方案。

Abstract: Generating 3D scenes from natural language holds great promise for
applications in gaming, film, and design. However, existing methods struggle
with automation, 3D consistency, and fine-grained control. We present
DreamScene, an end-to-end framework for high-quality and editable 3D scene
generation from text or dialogue. DreamScene begins with a scene planning
module, where a GPT-4 agent infers object semantics and spatial constraints to
construct a hybrid graph. A graph-based placement algorithm then produces a
structured, collision-free layout. Based on this layout, Formation Pattern
Sampling (FPS) generates object geometry using multi-timestep sampling and
reconstructive optimization, enabling fast and realistic synthesis. To ensure
global consistent, DreamScene employs a progressive camera sampling strategy
tailored to both indoor and outdoor settings. Finally, the system supports
fine-grained scene editing, including object movement, appearance changes, and
4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior
methods in quality, consistency, and flexibility, offering a practical solution
for open-domain 3D content creation. Code and demos are available at
https://dreamscene-project.github.io.

</details>


### [116] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的两步法，用于隧道裂缝的分类和分割，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 隧道裂缝是隧道安全状态的关键指标，需要高精度和高效率的分类与分割方法。

Method: 第一步使用DenseNet-169进行隧道图像分类，第二步基于DeepLabV3+进行裂缝分割，并通过视觉解释技术评估模型。

Result: 分类模型准确率92.23%，FPS 39.80；分割模型IoU 57.01%，F1分数67.44%，均优于其他模型。

Conclusion: 该方法结合视觉解释，为隧道健康状态的快速准确评估提供了基础。

Abstract: Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming
to classify and segment tunnel cracks with enhanced accuracy and efficiency,
this study proposes a two-step deep learning-based method. An automatic tunnel
image classification model is developed using the DenseNet-169 in the first
step. The proposed crack segmentation model in the second step is based on the
DeepLabV3+, whose internal logic is evaluated via a score-weighted visual
explanation technique. Proposed method combines tunnel image classification and
segmentation together, so that the selected images containing cracks from the
first step are segmented in the second step to improve the detection accuracy
and efficiency. The superior performances of the two-step method are validated
by experiments. The results show that the accuracy and frames per second (FPS)
of the tunnel crack classification model are 92.23% and 39.80, respectively,
which are higher than other convolutional neural networks (CNN) based and
Transformer based models. Also, the intersection over union (IoU) and F1 score
of the tunnel crack segmentation model are 57.01% and 67.44%, respectively,
outperforming other state-of-the-art models. Moreover, the provided visual
explanations in this study are conducive to understanding the "black box" of
deep learning-based models. The developed two-stage deep learning-based method
integrating visual explanations provides a basis for fast and accurate
quantitative assessment of tunnel health status.

</details>


### [117] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 该研究提出了一种基于多光谱成像和增强YOLOv5模型的深度学习框架，用于植物叶片异常分割，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要准确检测植物叶片的营养缺乏，以实现早期干预施肥、疾病和压力管理。

Method: 使用多光谱成像和带有基于Transformer注意力头的增强YOLOv5模型，处理九通道多光谱输入，利用自注意力机制捕捉细微症状。

Result: 模型在Dice分数和IoU上平均提升约12%，尤其在检测叶绿素缺失和色素积累等挑战性症状上表现优异。

Conclusion: 结合多光谱成像与光谱-空间特征学习，有望推动植物表型和精准农业的发展。

Abstract: Accurate detection of nutrient deficiency in plant leaves is essential for
precision agriculture, enabling early intervention in fertilization, disease,
and stress management. This study presents a deep learning framework for leaf
anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model
with a transformer-based attention head. The model is tailored for processing
nine-channel multispectral input and uses self-attention mechanisms to better
capture subtle, spatially-distributed symptoms. The plants in the experiments
were grown under controlled nutrient stress conditions for evaluation. We carry
out extensive experiments to benchmark the proposed model against the baseline
YOLOv5. Extensive experiments show that the proposed model significantly
outperforms the baseline YOLOv5, with an average Dice score and IoU
(Intersection over Union) improvement of about 12%. In particular, this model
is effective in detecting challenging symptoms like chlorosis and pigment
accumulation. These results highlight the promise of combining multi-spectral
imaging with spectral-spatial feature learning for advancing plant phenotyping
and precision agriculture.

</details>


### [118] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: 提出了一种基于量子辅助推理的超轻量级框架QuantEIT，用于EIT图像重建，显著降低模型复杂度并提升性能。


<details>
  <summary>Details</summary>
Motivation: EIT具有高时间分辨率和低成本，但逆问题病态性导致重建困难；现有深度学习方法参数多、效率低。

Method: QuantEIT结合2量子比特并行电路生成隐式非线性先验，通过单线性层重建电导率，无需训练数据。

Result: 在模拟和真实2D/3D肺部EIT数据中，QuantEIT优于传统方法，仅用0.2%参数实现更高精度和抗噪性。

Conclusion: QuantEIT首次将量子电路引入EIT重建，为高效、轻量化的医学成像提供新思路。

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside
imaging modality with high temporal resolution, making it suitable for bedside
monitoring. However, its inherently ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Deep learning (DL)-based
approaches have shown promise but often rely on complex network architectures
with a large number of parameters, limiting efficiency and scalability. Here,
we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework
for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network
(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive
latent representations that serve as implicit nonlinear priors, followed by a
single linear layer for conductivity reconstruction. This design drastically
reduces model complexity and parameter number. Uniquely, QuantEIT operates in
an unsupervised, training-data-free manner and represents the first integration
of quantum circuits into EIT image reconstruction. Extensive experiments on
simulated and real-world 2D and 3D EIT lung imaging data demonstrate that
QuantEIT outperforms conventional methods, achieving comparable or superior
reconstruction accuracy using only 0.2% of the parameters, with enhanced
robustness to noise.

</details>


### [119] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 论文提出了一种结合情感与视觉内容的方法，通过三个组件实现情感驱动的图像编辑：数据集MoodArchive、模型MoodifyCLIP和编辑工具Moodifier，显著提升了情感准确性和内容完整性。


<details>
  <summary>Details</summary>
Motivation: 情感驱动的图像编辑在创意产业中潜力巨大，但由于情感的抽象性和多样性，精确操控仍具挑战性。

Method: 1. 构建MoodArchive数据集（8M+图像，带层级情感标注）；2. 开发MoodifyCLIP模型，将情感映射为视觉属性；3. 提出Moodifier编辑模型，结合MLLMs实现精准情感转换。

Result: Moodifier在情感准确性和内容保留上优于现有方法，适用于多领域（如时尚、家居等）。

Conclusion: 通过将抽象情感与具体视觉变化关联，该方法为实际应用中的情感内容创作提供了新可能。

Abstract: Bridging emotions and visual content for emotion-driven image editing holds
great potential in creative industries, yet precise manipulation remains
challenging due to the abstract nature of emotions and their varied
manifestations across different contexts. We tackle this challenge with an
integrated approach consisting of three complementary components. First, we
introduce MoodArchive, an 8M+ image dataset with detailed hierarchical
emotional annotations generated by LLaVA and partially validated by human
evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned
on MoodArchive to translate abstract emotions into specific visual attributes.
Third, we propose Moodifier, a training-free editing model leveraging
MoodifyCLIP and multimodal large language models (MLLMs) to enable precise
emotional transformations while preserving content integrity. Our system works
across diverse domains such as character expressions, fashion design, jewelry,
and home d\'ecor, enabling creators to quickly visualize emotional variations
while preserving identity and structure. Extensive experimental evaluations
show that Moodifier outperforms existing methods in both emotional accuracy and
content preservation, providing contextually appropriate edits. By linking
abstract emotions to concrete visual changes, our solution unlocks new
possibilities for emotional content creation in real-world applications. We
will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier
code and demo publicly available upon acceptance.

</details>


### [120] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: 该论文评估了一种基于深度学习的自动化软件（Carebot AI Bones）在测量脊柱侧弯Cobb角方面的表现，结果显示其与放射科医生的测量结果具有较高的一致性。


<details>
  <summary>Details</summary>
Motivation: 脊柱侧弯的Cobb角测量对治疗决策至关重要，但传统手动测量耗时且存在观察者间差异。本研究旨在验证自动化软件的准确性和临床实用性。

Method: 研究采用回顾性多中心评估，对103张脊柱X光片进行测量，由两位放射科医生作为参考标准，通过Bland-Altman分析、MAE、RMSE、Pearson相关系数和Cohen kappa等方法评估AI与医生的一致性。

Result: AI与两位放射科医生的测量结果高度相关（Pearson r=0.906和0.880），MAE分别为3.89度和3.90度，Cohen kappa显示分类一致性为0.51和0.64。

Conclusion: 该自动化软件能够复现专家水平的Cobb角测量和分类，有望优化脊柱侧弯的临床工作流程。

Abstract: Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment
decisions depend on precise Cobb angle measurement. Manual assessment is time
consuming and subject to inter observer variation. We conducted a
retrospective, multi centre evaluation of a fully automated deep learning
software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on
103 standing anteroposterior whole spine radiographs collected from ten
hospitals. Two musculoskeletal radiologists independently measured each study
and served as reference readers. Agreement between the AI and each radiologist
was assessed with Bland Altman analysis, mean absolute error (MAE), root mean
squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four
grade severity classification. Against Radiologist 1 the AI achieved an MAE of
3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of
agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI
achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees
and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r
equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen
kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).
These results demonstrate that the proposed software reproduces expert level
Cobb angle measurements and categorical grading across multiple centres,
suggesting its utility for streamlining scoliosis reporting and triage in
clinical workflows.

</details>


### [121] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: Vision Mamba的MTR框架通过无训练的方式实现高效token压缩，显著降低计算量且性能损失小。


<details>
  <summary>Details</summary>
Motivation: 探索Vision Mamba的高效性以扩展应用，但现有ViT的token压缩技术直接应用于Mamba会导致性能下降。

Method: 提出Mamba结构感知的重要性评分，并基于此设计无需训练的MTR框架。

Result: 实验表明MTR在多种任务和骨干网络上显著减少计算量（如Vim-B上FLOPs降低40%），性能损失极小（ImageNet上仅下降1.6%）。

Conclusion: MTR是一种高效、即插即用的Vision Mamba token压缩方案。

Abstract: Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)
due to its ability to efficiently capture long-range dependencies with linear
computational complexity. While token reduction, an effective compression
technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision
Mamba's efficiency is essential for enabling broader applications. However, we
find that directly applying existing token reduction techniques for ViTs to
Vision Mamba leads to significant performance degradation. This is primarily
because Mamba is a sequence model without attention mechanisms, whereas most
token reduction techniques for ViTs rely on attention mechanisms for importance
measurement and overlook the order of compressed tokens. In this paper, we
investigate a Mamba structure-aware importance score to evaluate token
importance in a simple and effective manner. Building on this score, we further
propose MTR, a training-free \textbf{M}amba \textbf{T}oken \textbf{R}eduction
framework. Without the need for training or additional tuning parameters, our
method can be seamlessly integrated as a plug-and-play component across various
Mamba models. Extensive experiments demonstrate that our approach significantly
reduces computational workload while minimizing performance impact across
various tasks and multiple backbones. Notably, MTR reduces FLOPs by
approximately 40\% on the Vim-B backbone, with only a 1.6\% drop in ImageNet
performance without retraining.

</details>


### [122] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 论文探讨了在皮肤病分类中利用预训练基础模型进行类增量学习的方法，通过冻结主干网络并增量训练轻量级MLP，取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 探索预训练基础模型在皮肤病分类中实现类增量学习的潜力，解决传统方法中的遗忘问题。

Method: 冻结预训练基础模型的主干网络，增量训练轻量级MLP；同时测试了零训练场景下基于原型的分类方法。

Result: 提出的方法在类增量学习中表现优异，无需额外正则化或重放机制，且原型方法也取得了竞争性结果。

Conclusion: 冻结预训练基础模型在皮肤病分类的类增量学习中具有显著优势，适合实际医疗应用。

Abstract: Class-Incremental Learning (CIL) aims to learn new classes over time without
forgetting previously acquired knowledge. The emergence of foundation models
(FM) pretrained on large datasets presents new opportunities for CIL by
offering rich, transferable representations. However, their potential for
enabling incremental learning in dermatology remains largely unexplored. In
this paper, we systematically evaluate frozen FMs pretrained on large-scale
skin lesion datasets for CIL in dermatological disease classification. We
propose a simple yet effective approach where the backbone remains frozen, and
a lightweight MLP is trained incrementally for each task. This setup achieves
state-of-the-art performance without forgetting, outperforming regularization,
replay, and architecture based methods. To further explore the capabilities of
frozen FMs, we examine zero training scenarios using nearest mean classifiers
with prototypes derived from their embeddings. Through extensive ablation
studies, we demonstrate that this prototype based variant can also achieve
competitive results. Our findings highlight the strength of frozen FMs for
continual learning in dermatology and support their broader adoption in real
world medical applications. Our code and datasets are available here.

</details>


### [123] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: VLA-Mark是一种视觉对齐的水印框架，通过跨模态协调嵌入水印，保持语义保真度，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本水印方法破坏视觉-文本对齐，VLA-Mark旨在保护知识产权同时保持多模态一致性。

Method: 结合多尺度视觉-文本对齐指标，动态平衡水印强度与语义保留，无需模型重训练。

Result: 实验显示PPL降低7.4%，BLEU提高26.6%，检测AUC达98.8%，攻击抗性96.1%。

Conclusion: VLA-Mark为质量保持的多模态水印设定了新标准。

Abstract: Vision-language models demand watermarking solutions that protect
intellectual property without compromising multimodal coherence. Existing text
watermarking methods disrupt visual-textual alignment through biased token
selection and static strategies, leaving semantic-critical concepts vulnerable.
We propose VLA-Mark, a vision-aligned framework that embeds detectable
watermarks while preserving semantic fidelity through cross-modal coordination.
Our approach integrates multiscale visual-textual alignment metrics, combining
localized patch affinity, global semantic coherence, and contextual attention
patterns, to guide watermark injection without model retraining. An
entropy-sensitive mechanism dynamically balances watermark strength and
semantic preservation, prioritizing visual grounding during low-uncertainty
generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than
conventional methods, with near-perfect detection (98.8% AUC). The framework
demonstrates 96.1\% attack resilience against attacks such as paraphrasing and
synonym substitution, while maintaining text-visual consistency, establishing
new standards for quality-preserving multimodal watermarking

</details>


### [124] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文分析了四种人类匿名化技术对异常检测性能的影响，发现匿名化后检测仍可行，且性能与算法设计相关。


<details>
  <summary>Details</summary>
Motivation: 深度学习在监控视频异常检测中取得进展，但涉及敏感数据收集引发隐私问题，需研究匿名化技术对检测的影响。

Method: 在UCF-Crime数据集上应用模糊、掩码、加密和虚拟替换四种匿名化技术，评估四种异常检测方法（MGFN、UR-DMU、BN-WVAD、PEL4VAD）。

Result: 匿名化数据下异常检测仍有效，某些匿名化模式（如加密和掩码）甚至能提高部分模型的AUC性能。

Conclusion: 研究揭示了算法对匿名化的敏感性，并权衡了隐私保护与检测效用的关系，为隐私与检测需求的平衡提供了基准。

Abstract: Advancements in deep learning have improved anomaly detection in surveillance
videos, yet they raise urgent privacy concerns due to the collection of
sensitive human data. In this paper, we present a comprehensive analysis of
anomaly detection performance under four human anonymization techniques,
including blurring, masking, encryption, and avatar replacement, applied to the
UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,
BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method
responds to different obfuscation techniques. Experimental results demonstrate
that anomaly detection remains viable under anonymized data and is dependent on
the algorithmic design and the learning strategy. For instance, under certain
anonymization patterns, such as encryption and masking, some models
inadvertently achieve higher AUC performance compared to raw data, due to the
strong responsiveness of their algorithmic components to these noise patterns.
These results highlight the algorithm-specific sensitivities to anonymization
and emphasize the trade-off between preserving privacy and maintaining
detection utility. Furthermore, we compare these conventional anonymization
techniques with the emerging privacy-by-design solutions, highlighting an often
overlooked trade-off between robust privacy protection and utility flexibility.
Through comprehensive experiments and analyses, this study provides a
compelling benchmark and insights into balancing human privacy with the demands
of anomaly detection.

</details>


### [125] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: C-DOG是一种无需训练的框架，通过结合连接增量重叠图建模和极线几何，在多视图中鲁棒地关联对象检测，适用于噪声和视觉不可区分场景。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在对象视觉不可区分或噪声干扰时失效的问题，提出一种不依赖视觉特征的鲁棒关联方法。

Method: 结合连接增量重叠图建模与极线几何，通过增量邻居重叠聚类和IQR过滤，消除不一致观测。

Result: 在合成基准测试中，C-DOG优于几何基线，并在高密度、无视觉特征和有限相机重叠条件下保持鲁棒性。

Conclusion: C-DOG适用于现实场景中可扩展的3D重建，尤其在噪声和视觉不可区分条件下表现优异。

Abstract: Multi-view multi-object association is a fundamental step in 3D
reconstruction pipelines, enabling consistent grouping of object instances
across multiple camera views. Existing methods often rely on appearance
features or geometric constraints such as epipolar consistency. However, these
approaches can fail when objects are visually indistinguishable or observations
are corrupted by noise. We propose C-DOG, a training-free framework that serves
as an intermediate module bridging object detection (or pose estimation) and 3D
reconstruction, without relying on visual features. It combines connected
delta-overlap graph modeling with epipolar geometry to robustly associate
detections across views. Each 2D observation is represented as a graph node,
with edges weighted by epipolar consistency. A delta-neighbor-overlap
clustering step identifies strongly consistent groups while tolerating noise
and partial connectivity. To further improve robustness, we incorporate
Interquartile Range (IQR)-based filtering and a 3D back-projection error
criterion to eliminate inconsistent observations. Extensive experiments on
synthetic benchmarks demonstrate that C-DOG outperforms geometry-based
baselines and remains robust under challenging conditions, including high
object density, without visual features, and limited camera overlap, making it
well-suited for scalable 3D reconstruction in real-world scenarios.

</details>


### [126] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: Franca是一个完全开源（数据、代码、权重）的视觉基础模型，性能优于或匹敌现有专有模型（如DINOv2、CLIP等）。其透明训练流程和公开数据支持，解决了SSL聚类方法的局限性，并引入多头聚类投影器和位置解耦策略，提升了性能和语义编码。


<details>
  <summary>Details</summary>
Motivation: 解决现有专有视觉基础模型缺乏透明性和开源性的问题，同时改进SSL聚类方法的局限性，提供更高效、可复现的解决方案。

Method: 采用透明训练流程（基于Web-SSL和公开数据），引入多头聚类投影器（基于嵌套Matryoshka表示）和位置解耦策略，优化特征聚类和语义编码。

Result: 在多个下游任务中表现优异，性能优于或匹敌专有模型，同时提升了特征空间的清晰度和内存效率。

Conclusion: Franca为透明、高性能的视觉基础模型树立了新标准，推动了AI社区的可复现性和通用性发展。

Abstract: We present Franca (pronounced Fran-ka): free one; the first fully open-source
(data, code, weights) vision foundation model that matches and in many cases
surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,
CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training
pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and
a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in
SSL clustering methods. While modern models rely on assigning image features to
large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to
account for the inherent ambiguity in clustering semantics. To address this, we
introduce a parameter-efficient, multi-head clustering projector based on
nested Matryoshka representations. This design progressively refines features
into increasingly fine-grained clusters without increasing the model size,
enabling both performance and memory efficiency. Additionally, we propose a
novel positional disentanglement strategy that explicitly removes positional
biases from dense representations, thereby improving the encoding of semantic
content. This leads to consistent gains on several downstream benchmarks,
demonstrating the utility of cleaner feature spaces. Our contributions
establish a new standard for transparent, high-performance vision models and
open a path toward more reproducible and generalizable foundation models for
the broader AI community. The code and model checkpoints are available at
https://github.com/valeoai/Franca.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [127] [A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security](https://arxiv.org/abs/2507.13367)
*Mehrab Hosain,Rajiv Kapoor*

Main category: cs.CR

TL;DR: 提出了一种结合APVD和伪随机像素选择的新型隐写方法，解决了未使用块问题，提升了安全性、嵌入容量和图像质量。


<details>
  <summary>Details</summary>
Motivation: APVD方法存在未使用块问题，导致安全性、嵌入容量和视觉质量下降。

Method: 结合APVD与伪随机像素选择，优化像素嵌入策略。

Result: 新方法在安全性、数据隐藏容量和图像质量（PSNR、UIQ、SSIM）上优于现有技术。

Conclusion: 新方法适用于多种图像类型，确保安全传输且不损害图像质量。

Abstract: Steganography is the process of embedding secret information discreetly
within a carrier, ensuring secure exchange of confidential data. The Adaptive
Pixel Value Differencing (APVD) steganography method, while effective,
encounters certain challenges like the "unused blocks" issue. This problem can
cause a decrease in security, compromise the embedding capacity, and lead to
lower visual quality. This research presents a novel steganographic strategy
that integrates APVD with pseudorandom pixel selection to effectively mitigate
these issues. The results indicate that the new method outperforms existing
techniques in aspects of security, data hiding capacity, and the preservation
of image quality. Empirical results reveal that the combination of APVD with
pseudorandom pixel selection significantly enhances key image quality metrics
such as Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQ),
and Structural Similarity Index (SSIM), surpassing other contemporary methods
in performance. The newly proposed method is versatile, able to handle a
variety of cover and secret images in both color and grayscale, thereby
ensuring secure data transmission without compromising the aesthetic quality of
the image.

</details>


### [128] [PHASE: Passive Human Activity Simulation Evaluation](https://arxiv.org/abs/2507.13505)
*Steven Lamp,Jason D. Hiser,Anh Nguyen-Tuong,Jack W. Davidson*

Main category: cs.CR

TL;DR: PHASE是一种机器学习框架，通过分析Zeek连接日志，以超过90%的准确率区分人类与非人类活动，提升网络安全模拟环境中合成用户行为的真实性。


<details>
  <summary>Details</summary>
Motivation: 网络安全模拟环境需要真实的人类行为，但缺乏定量评估合成用户行为真实性的方法。

Method: PHASE框架被动分析Zeek连接日志，利用本地DNS记录分类流量，并结合SHAP分析揭示人类行为特征。

Result: PHASE准确率超过90%，并通过案例研究改进了合成用户行为的配置，显著提升了真实性。

Conclusion: PHASE为网络安全模拟环境提供了一种高效、被动的行为真实性评估方法，显著提升了合成用户行为的有效性。

Abstract: Cybersecurity simulation environments, such as cyber ranges, honeypots, and
sandboxes, require realistic human behavior to be effective, yet no
quantitative method exists to assess the behavioral fidelity of synthetic user
personas. This paper presents PHASE (Passive Human Activity Simulation
Evaluation), a machine learning framework that analyzes Zeek connection logs
and distinguishes human from non-human activity with over 90\% accuracy. PHASE
operates entirely passively, relying on standard network monitoring without any
user-side instrumentation or visible signs of surveillance. All network
activity used for machine learning is collected via a Zeek network appliance to
avoid introducing unnecessary network traffic or artifacts that could disrupt
the fidelity of the simulation environment. The paper also proposes a novel
labeling approach that utilizes local DNS records to classify network traffic,
thereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley
Additive exPlanations) analysis to uncover temporal and behavioral signatures
indicative of genuine human users. In a case study, we evaluate a synthetic
user persona and identify distinct non-human patterns that undermine behavioral
realism. Based on these insights, we develop a revised behavioral configuration
that significantly improves the human-likeness of synthetic activity yielding a
more realistic and effective synthetic user persona.

</details>


### [129] [FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning](https://arxiv.org/abs/2507.13591)
*Sahar Ghoflsaz Ghinani,Elaheh Sadredini*

Main category: cs.CR

TL;DR: FuSeFL是一种完全安全且可扩展的联邦学习方案，通过轻量级安全多方计算（MPC）实现跨机构设置中的高效训练，显著降低通信延迟和服务器内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法在隐私保护方面存在高计算、通信或内存开销，且忽视全局模型的保密性，限制了其实际应用。

Method: FuSeFL采用去中心化训练，利用轻量级MPC技术，服务器仅负责安全聚合，避免数据卸载。

Result: FuSeFL降低了95%的通信延迟和50%的服务器内存使用，同时提高了准确性。

Conclusion: FuSeFL在安全性和效率方面表现出色，适用于大规模跨机构联邦学习场景。

Abstract: Federated Learning (FL) enables collaborative model training without
centralizing client data, making it attractive for privacy-sensitive domains.
While existing approaches employ cryptographic techniques such as homomorphic
encryption, differential privacy, or secure multiparty computation to mitigate
inference attacks-including model inversion, membership inference, and gradient
leakage-they often suffer from high computational, communication, or memory
overheads. Moreover, many methods overlook the confidentiality of the global
model itself, which may be proprietary and sensitive. These challenges limit
the practicality of secure FL, especially in cross-silo deployments involving
large datasets and strict compliance requirements.
  We present FuSeFL, a fully secure and scalable FL scheme designed for
cross-silo settings. FuSeFL decentralizes training across client pairs using
lightweight secure multiparty computation (MPC), while confining the server's
role to secure aggregation. This design eliminates server bottlenecks, avoids
data offloading, and preserves full confidentiality of data, model, and updates
throughout training. FuSeFL defends against inference threats, achieves up to
95% lower communication latency and 50% lower server memory usage, and improves
accuracy over prior secure FL solutions, demonstrating strong security and
efficiency at scale.

</details>


### [130] [GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention](https://arxiv.org/abs/2507.13598)
*Amro Abdalla,Ismail Shaheen,Dan DeGenaro,Rupayan Mallick,Bogdan Raita,Sarah Adel Bargal*

Main category: cs.CR

TL;DR: GIFT是一种梯度感知免疫技术，用于防御扩散模型免受恶意微调攻击，同时保留其生成安全内容的能力。


<details>
  <summary>Details</summary>
Motivation: 现有安全机制（如安全检查器）容易被绕过，概念擦除方法在对抗性微调下失效，因此需要一种更鲁棒的防御方法。

Method: GIFT将免疫问题建模为双层优化问题：上层目标通过表示噪声和最大化降低模型对有害概念的表示能力，下层目标保持对安全数据的性能。

Result: 实验表明，GIFT显著削弱模型重新学习有害概念的能力，同时保持对安全内容的生成质量。

Conclusion: GIFT为创建抗对抗性微调攻击的安全生成模型提供了有前景的方向。

Abstract: We present GIFT: a {G}radient-aware {I}mmunization technique to defend
diffusion models against malicious {F}ine-{T}uning while preserving their
ability to generate safe content. Existing safety mechanisms like safety
checkers are easily bypassed, and concept erasure methods fail under
adversarial fine-tuning. GIFT addresses this by framing immunization as a
bi-level optimization problem: the upper-level objective degrades the model's
ability to represent harmful concepts using representation noising and
maximization, while the lower-level objective preserves performance on safe
data. GIFT achieves robust resistance to malicious fine-tuning while
maintaining safe generative quality. Experimental results show that our method
significantly impairs the model's ability to re-learn harmful concepts while
maintaining performance on safe content, offering a promising direction for
creating inherently safer generative models resistant to adversarial
fine-tuning attacks.

</details>


### [131] [Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques](https://arxiv.org/abs/2507.13629)
*Niveen O. Jaffal,Mohammed Alkhanafseh,David Mohaisen*

Main category: cs.CR

TL;DR: 大语言模型（LLMs）通过智能、自适应和自动化的方式革新了网络安全，覆盖威胁检测、漏洞评估和事件响应等领域。本文综述了LLMs在网络安全中的应用及其自身漏洞与缓解策略。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何超越传统方法，提升网络安全能力，并分析其潜在漏洞。

Method: 综述LLMs在关键网络安全领域的应用及其自身漏洞，提出缓解策略。

Result: LLMs在网络安全中展现出显著优势，但也存在需解决的漏洞。

Conclusion: LLMs为构建安全、可扩展的未来网络防御系统提供了实用见解和战略建议。

Abstract: Large Language Models (LLMs) are transforming cybersecurity by enabling
intelligent, adaptive, and automated approaches to threat detection,
vulnerability assessment, and incident response. With their advanced language
understanding and contextual reasoning, LLMs surpass traditional methods in
tackling challenges across domains such as IoT, blockchain, and hardware
security. This survey provides a comprehensive overview of LLM applications in
cybersecurity, focusing on two core areas: (1) the integration of LLMs into key
cybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along
with mitigation strategies. By synthesizing recent advancements and identifying
key limitations, this work offers practical insights and strategic
recommendations for leveraging LLMs to build secure, scalable, and future-ready
cyber defense systems.

</details>


### [132] [TopicAttack: An Indirect Prompt Injection Attack via Topic Transition](https://arxiv.org/abs/2507.13686)
*Yulin Chen,Haoran Li,Yuexin Li,Yue Liu,Yangqiu Song,Bryan Hooi*

Main category: cs.CR

TL;DR: 论文提出TopicAttack方法，通过生成平滑的对话过渡提示，提升间接提示注入攻击的成功率，实验显示其攻击成功率超过90%。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法因指令注入突兀而效果有限，需改进以提升攻击的隐蔽性和成功率。

Method: 提出TopicAttack，生成对话过渡提示逐步引导话题至恶意指令，使注入更平滑。

Result: TopicAttack在大多数情况下攻击成功率超过90%，且能抵御多种防御方法。

Conclusion: TopicAttack通过提高注入指令的注意力比例，显著提升了攻击效果，为LLM安全性研究提供了新视角。

Abstract: Large language models (LLMs) have shown remarkable performance across a range
of NLP tasks. However, their strong instruction-following capabilities and
inability to distinguish instructions from data content make them vulnerable to
indirect prompt injection attacks. In such attacks, instructions with malicious
purposes are injected into external data sources, such as web documents. When
LLMs retrieve this injected data through tools, such as a search engine and
execute the injected instructions, they provide misled responses. Recent attack
methods have demonstrated potential, but their abrupt instruction injection
often undermines their effectiveness. Motivated by the limitations of existing
attack methods, we propose TopicAttack, which prompts the LLM to generate a
fabricated conversational transition prompt that gradually shifts the topic
toward the injected instruction, making the injection smoother and enhancing
the plausibility and success of the attack. Through comprehensive experiments,
TopicAttack achieves state-of-the-art performance, with an attack success rate
(ASR) over 90\% in most cases, even when various defense methods are applied.
We further analyze its effectiveness by examining attention scores. We find
that a higher injected-to-original attention ratio leads to a greater success
probability, and our method achieves a much higher ratio than the baseline
methods.

</details>


### [133] [Quantum Blockchain Survey: Foundations, Trends, and Gaps](https://arxiv.org/abs/2507.13720)
*Saurav Ghosh*

Main category: cs.CR

TL;DR: 该论文综述了量子计算对区块链的威胁及应对方案，包括后量子区块链和量子区块链，比较了它们的技术、安全性和可扩展性，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 量子计算威胁传统区块链的加密基础，需要研究量子时代的区块链安全解决方案。

Method: 综述了后量子区块链（使用抗量子算法）和量子区块链（利用量子特性）的技术发展，分析其密码学基础、架构设计和实现挑战。

Result: 提供了技术方案的比较，强调了安全性、可扩展性和部署中的权衡，并指出了硬件、共识和网络设计中的开放问题。

Conclusion: 该研究为量子时代推进安全的区块链系统提供了结构化和全面的参考。

Abstract: Quantum computing poses fundamental risks to classical blockchain systems by
undermining widely used cryptographic primitives. In response, two major
research directions have emerged: post-quantum blockchains, which integrate
quantum-resistant algorithms, and quantum blockchains, which leverage quantum
properties such as entanglement and quantum key distribution. This survey
reviews key developments in both areas, analyzing their cryptographic
foundations, architectural designs, and implementation challenges. This work
provides a comparative overview of technical proposals, highlight trade-offs in
security, scalability, and deployment, and identify open research problems
across hardware, consensus, and network design. The goal is to offer a
structured and comprehensive reference for advancing secure blockchain systems
in the quantum era.

</details>


### [134] [Developers Insight On Manifest v3 Privacy and Security Webextensions](https://arxiv.org/abs/2507.13926)
*Libor Polčák,Giorgio Maone,Michael McMahon,Martin Bednář*

Main category: cs.CR

TL;DR: 本文研究了Chrome的Manifest v3对webextensions的影响，发现其挑战与机遇并存，部分项目需牺牲功能或拒绝更新。


<details>
  <summary>Details</summary>
Motivation: 探讨Manifest v3对webextensions功能的影响，以了解其实际效果和开发者反馈。

Method: 采用深入的定性研究方法，分析Manifest v3的挑战与机遇。

Result: 部分项目可无功能损失迁移，但多数项目面临功能限制或需寻找替代方案，关键API缺失。

Conclusion: Manifest v3对不同类型webextensions影响不一，需进一步改进API以满足开发者需求。

Abstract: Webextensions can improve web browser privacy, security, and user experience.
The APIs offered by the browser to webextensions affect possible functionality.
Currently, Chrome transitions to a modified set of APIs called Manifest v3.
This paper studies the challenges and opportunities of Manifest v3 with an
in-depth structured qualitative research. Even though some projects observed
positive effects, a majority expresses concerns over limited benefits to users,
removal of crucial APIs, or the need to find workarounds. Our findings indicate
that the transition affects different types of webextensions differently; some
can migrate without losing functionality, while other projects remove
functionality or decline to update. The respondents identified several critical
missing APIs, including reliable APIs to inject content scripts, APIs for
storing confidential content, and others.

</details>


### [135] [Chain Table: Protecting Table-Level Data Integrity by Digital Ledger Technology](https://arxiv.org/abs/2507.13932)
*Feng Yu,Ryan Laird*

Main category: cs.CR

TL;DR: 提出了一种名为“链表”的数据库内设计，用于保护数据完整性，无需依赖区块链系统。


<details>
  <summary>Details</summary>
Motivation: 区块链技术虽然能保护数据完整性，但实现复杂且技术门槛高，因此需要一种更简便的解决方案。

Method: 设计了“链表”结构，并提出了一套数据写入原则，以实现表级数据完整性（TDI）。

Result: 链表及其数据写入原则能够灵活保证数据完整性，且技术门槛低、存储开销小。

Conclusion: 链表是一种高效且易于实现的数据完整性保护方案，适用于无需区块链系统的场景。

Abstract: The rise of blockchain and Digital Ledger Technology (DLT) has gained wide
traction. Instead of relying on a traditional centralized data authority, a
blockchain system consists of digitally entangled block data shared across a
distributed network. The specially designed chain data structure and its
consensus mechanism protect blockchain data from being tampered by unauthorized
adversaries. However, implementing a full-fledged blockchain system to protect
a database can be technically cumbersome. In this work, we introduce an
in-database design, named chain table, to protect data integrity without the
need for a blockchain system. It features a succinct design without significant
technology barriers or storage overhead. To realize rigorous data security, we
also propose a set of data writing principles for the chain table. We prove
that the chain table, together with the data writing principles, will guarantee
flexible data integrity, named table-level data integrity (TDI).

</details>


### [136] [The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems](https://arxiv.org/abs/2507.14007)
*Serhan W. Bahar*

Main category: cs.CR

TL;DR: 论文提出了CryptoNeo威胁建模框架（CNTMF），用于应对区块链、加密货币和Web3技术融合带来的风险，如预言机操纵和跨链攻击。


<details>
  <summary>Details</summary>
Motivation: 传统金融系统与去中心化技术的快速融合带来了新的安全风险，需要一种针对性的威胁建模框架。

Method: CNTMF扩展了STRIDE、OWASP Top 10等方法，引入了混合层分析、CRYPTOQ助记符和AI增强反馈循环等组件。

Result: 基于2025年的真实数据，CNTMF帮助减少了约24.7亿美元的损失，覆盖344起安全事件。

Conclusion: CNTMF通过资产映射、风险分析和迭代反馈，有效应对了包括国家支持攻击在内的新兴威胁。

Abstract: The rapid integration of blockchain, cryptocurrency, and Web3 technologies
into digital banks and fintech operations has created an integrated environment
blending traditional financial systems with decentralised elements. This paper
introduces the CryptoNeo Threat Modelling Framework (CNTMF), a proposed
framework designed to address the risks in these ecosystems, such as oracle
manipulation and cross-chain exploits. CNTMF represents a proposed extension of
established methodologies like STRIDE, OWASP Top 10, NIST frameworks, LINDDUN,
and PASTA, while incorporating tailored components including Hybrid Layer
Analysis, the CRYPTOQ mnemonic for cryptocurrency-specific risks, and an
AI-Augmented Feedback Loop. Drawing on real-world data from 2025 incidents,
CNTMF supports data-driven mitigation to reduce losses, which totalled
approximately $2.47 billion in the first half of 2025 across 344 security
events (CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025). Its
phases guide asset mapping, risk profiling, prioritisation, mitigation, and
iterative feedback. This supports security against evolving risks like
state-sponsored attacks.

</details>


### [137] [An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting](https://arxiv.org/abs/2507.14109)
*Xinyu Cao,Bimal Adhikari,Shangqing Zhao,Jingxian Wu,Yanjun Pan*

Main category: cs.CR

TL;DR: 论文研究了基于深度学习的射频指纹识别系统的安全风险，发现其在领域偏移下存在一致的误分类行为，可能被利用为后门攻击。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注系统在无线环境中的鲁棒性，而忽略了深度学习方法的潜在安全漏洞。

Method: 通过对抗性驱动的实验分析，系统研究了深度学习模型的误分类行为及其成因。

Result: 实验表明，模型在领域偏移下会误分类设备，且训练原始信号会导致指纹与环境特征纠缠，增加攻击面。

Conclusion: 仅通过后处理安全方法无法完全缓解这些风险，需重新设计模型训练方法。

Abstract: Radio frequency (RF) fingerprinting, which extracts unique hardware
imperfections of radio devices, has emerged as a promising physical-layer
device identification mechanism in zero trust architectures and beyond 5G
networks. In particular, deep learning (DL) methods have demonstrated
state-of-the-art performance in this domain. However, existing approaches have
primarily focused on enhancing system robustness against temporal and spatial
variations in wireless environments, while the security vulnerabilities of
these DL-based approaches have often been overlooked. In this work, we
systematically investigate the security risks of DL-based RF fingerprinting
systems through an adversarial-driven experimental analysis. We observe a
consistent misclassification behavior for DL models under domain shifts, where
a device is frequently misclassified as another specific one. Our analysis
based on extensive real-world experiments demonstrates that this behavior can
be exploited as an effective backdoor to enable external attackers to intrude
into the system. Furthermore, we show that training DL models on raw received
signals causes the models to entangle RF fingerprints with environmental and
signal-pattern features, creating additional attack vectors that cannot be
mitigated solely through post-processing security methods such as confidence
thresholds.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [138] [Physical models realizing the transformer architecture of large language models](https://arxiv.org/abs/2507.13354)
*Zeqian Chen*

Main category: cs.LG

TL;DR: 论文从物理角度分析Transformer架构，提出基于开放量子系统的物理模型。


<details>
  <summary>Details</summary>
Motivation: 现有理论对Transformer的工作原理缺乏物理层面的理解。

Method: 从现代芯片的物理视角，在Fock空间构建基于Transformer的开放量子系统模型。

Result: 提出了支持Transformer架构的物理模型。

Conclusion: 物理模型为Transformer架构提供了理论基础。

Abstract: The introduction of the transformer architecture in 2017 (cf.\cite{VSP2017})
marked the most striking advancement in natural language processing. The
transformer is a model architecture relying entirely on an attention mechanism
to draw global dependencies between input and output. However, we believe there
is a gap in our theoretical understanding of what the transformer is, and why
it works physically. In this paper, from a physical perspective on modern
chips, we construct physical models in the Fock space over the Hilbert space of
tokens realizing large language models based on a transformer architecture as
open quantum systems. Our physical models underlie the transformer architecture
for large language models.

</details>


### [139] [Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models](https://arxiv.org/abs/2507.13383)
*Charvi Rastogi,Tian Huey Teh,Pushkar Mishra,Roma Patel,Ding Wang,Mark Díaz,Alicia Parrish,Aida Mostafazadeh Davani,Zoe Ashwood,Michela Paganini,Vinodkumar Prabhakaran,Verena Rieser,Lora Aroyo*

Main category: cs.LG

TL;DR: 论文提出了一种多元对齐方法，通过引入DIVE数据集和实证研究，改进文本到图像（T2I）模型对多样化人类价值观的理解和响应。


<details>
  <summary>Details</summary>
Motivation: 当前T2I模型未能充分反映多样化的人类经验，导致系统与人类价值观不一致。研究旨在通过多元对齐解决这一问题。

Method: 1. 创建DIVE数据集，通过多样化人口背景的评估者提供反馈；2. 实证验证人口特征作为多样化观点的代理；3. 探讨对齐T2I模型的策略。

Result: DIVE数据集成功捕捉了多样化安全观点，实证显示人口特征显著影响危害感知，与传统评估不同。

Conclusion: 研究为构建更公平和对齐的T2I系统提供了基础工具，包括高效数据收集和模型可操控性策略。

Abstract: Current text-to-image (T2I) models often fail to account for diverse human
experiences, leading to misaligned systems. We advocate for pluralistic
alignment, where an AI understands and is steerable towards diverse, and often
conflicting, human values. Our work provides three core contributions to
achieve this in T2I models. First, we introduce a novel dataset for Diverse
Intersectional Visual Evaluation (DIVE) -- the first multimodal dataset for
pluralistic alignment. It enable deep alignment to diverse safety perspectives
through a large pool of demographically intersectional human raters who
provided extensive feedback across 1000 prompts, with high replication,
capturing nuanced safety perceptions. Second, we empirically confirm
demographics as a crucial proxy for diverse viewpoints in this domain,
revealing significant, context-dependent differences in harm perception that
diverge from conventional evaluations. Finally, we discuss implications for
building aligned T2I models, including efficient data collection strategies,
LLM judgment capabilities, and model steerability towards diverse perspectives.
This research offers foundational tools for more equitable and aligned T2I
systems. Content Warning: The paper includes sensitive content that may be
harmful.

</details>


### [140] [Improving KAN with CDF normalization to quantiles](https://arxiv.org/abs/2507.13393)
*Jakub Strawa,Jarek Duda*

Main category: cs.LG

TL;DR: 论文探讨了在机器学习中使用CDF归一化的优势，通过Kolmogorov-Arnold Networks (KANs)展示了其优于传统归一化方法的效果。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习中常用的归一化方法（如均值标准差或固定范围缩放）在金融领域的copula理论中较少使用，而CDF归一化能减少过拟合并简化表示。

Method: 通过将数据转换为CDF(x)实现归一化，应用于KANs中，并与Legendre-KAN进行比较。

Result: CDF归一化显著提升了KANs的预测性能。

Conclusion: CDF归一化在机器学习中具有潜力，尤其在KANs中表现优异，能提供更灵活的分布建模和传播方向调整。

Abstract: Data normalization is crucial in machine learning, usually performed by
subtracting the mean and dividing by standard deviation, or by rescaling to a
fixed range. In copula theory, popular in finance, there is used normalization
to approximately quantiles by transforming x to CDF(x) with estimated CDF
(cumulative distribution function) to nearly uniform distribution in [0,1],
allowing for simpler representations which are less likely to overfit. It seems
nearly unknown in machine learning, therefore, we would like to present some
its advantages on example of recently popular Kolmogorov-Arnold Networks
(KANs), improving predictions from Legendre-KAN by just switching rescaling to
CDF normalization. Additionally, in HCR interpretation, weights of such neurons
are mixed moments providing local joint distribution models, allow to propagate
also probability distributions, and change propagation direction.

</details>


### [141] [Selective Embedding for Deep Learning](https://arxiv.org/abs/2507.13399)
*Mert Sehri,Zehui Hua,Francisco de Assis Boldt,Patrick Dumond*

Main category: cs.LG

TL;DR: 提出了一种名为选择性嵌入的新数据加载策略，通过交替多源数据的短片段来提升深度学习模型的泛化能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在非平稳条件和跨域数据中性能下降，传统数据加载策略泛化能力有限或计算成本高。

Method: 选择性嵌入策略，交替加载多源数据的短片段于单一输入通道，模拟人类信息处理方式。

Result: 在六个时域数据集上验证，该方法显著提高分类准确性并减少训练时间。

Conclusion: 选择性嵌入为多源数据复杂系统提供了一种可扩展且资源高效的解决方案。

Abstract: Deep learning has revolutionized many industries by enabling models to
automatically learn complex patterns from raw data, reducing dependence on
manual feature engineering. However, deep learning algorithms are sensitive to
input data, and performance often deteriorates under nonstationary conditions
and across dissimilar domains, especially when using time-domain data.
Conventional single-channel or parallel multi-source data loading strategies
either limit generalization or increase computational costs. This study
introduces selective embedding, a novel data loading strategy, which alternates
short segments of data from multiple sources within a single input channel.
Drawing inspiration from cognitive psychology, selective embedding mimics
human-like information processing to reduce model overfitting, enhance
generalization, and improve computational efficiency. Validation is conducted
using six time-domain datasets, demonstrating that the proposed method
consistently achieves high classification accuracy across various deep learning
architectures while significantly reducing training times. The approach proves
particularly effective for complex systems with multiple data sources, offering
a scalable and resource-efficient solution for real-world applications in
healthcare, heavy machinery, marine, railway, and agriculture, where robustness
and adaptability are critical.

</details>


### [142] [LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data](https://arxiv.org/abs/2507.13413)
*Aleksey Lapin,Igor Hromov,Stanislav Chumakov,Mile Mitrovic,Dmitry Simakov,Nikolay O. Nikitin,Andrey V. Savchenko*

Main category: cs.LG

TL;DR: LightAutoDS-Tab是一个结合LLM代码生成和多个AutoML工具的多代理系统，用于处理表格数据任务，提高了灵活性和鲁棒性，并在Kaggle任务中表现优于现有开源方案。


<details>
  <summary>Details</summary>
Motivation: 当前AutoML在处理复杂任务时依赖特定工具，效率受限。

Method: 结合LLM代码生成和多个AutoML工具，设计多代理系统。

Result: 在多个Kaggle数据科学任务中表现优于现有开源方案。

Conclusion: LightAutoDS-Tab提高了AutoML的灵活性和鲁棒性，代码已开源。

Abstract: AutoML has advanced in handling complex tasks using the integration of LLMs,
yet its efficiency remains limited by dependence on specific underlying tools.
In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for
tasks with tabular data, which combines an LLM-based code generation with
several AutoML tools. Our approach improves the flexibility and robustness of
pipeline design, outperforming state-of-the-art open-source solutions on
several data science tasks from Kaggle. The code of LightAutoDS-Tab is
available in the open repository https://github.com/sb-ai-lab/LADS

</details>


### [143] [Gauge Flow Models](https://arxiv.org/abs/2507.13414)
*Alexander Strunk,Roland Assam*

Main category: cs.LG

TL;DR: Gauge Flow Models是一种新型生成流模型，通过引入可学习的Gauge Field，在Flow ODE中实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统Flow Models性能有限，需要更高效的生成模型。

Method: 在Flow ODE中引入可学习的Gauge Field，构建数学框架。

Result: 在Gaussian Mixture Models上表现优于传统Flow Models。

Conclusion: Gauge Flow Models具有潜力在更广泛生成任务中提升性能。

Abstract: This paper introduces Gauge Flow Models, a novel class of Generative Flow
Models. These models incorporate a learnable Gauge Field within the Flow
Ordinary Differential Equation (ODE). A comprehensive mathematical framework
for these models, detailing their construction and properties, is provided.
Experiments using Flow Matching on Gaussian Mixture Models demonstrate that
Gauge Flow Models yields significantly better performance than traditional Flow
Models of comparable or even larger size. Additionally, unpublished research
indicates a potential for enhanced performance across a broader range of
generative tasks.

</details>


### [144] [Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling](https://arxiv.org/abs/2507.13416)
*Jiaxiang Yi,Bernardo P. Ferreira,Miguel A. Bessa*

Main category: cs.LG

TL;DR: 该论文提出了一种层次化的数据驱动学习方法，能够处理历史依赖的多保真度数据，并量化认知不确定性，同时将其与数据噪声（随机不确定性）分离。


<details>
  <summary>Details</summary>
Motivation: 动机在于扩展数据驱动学习的适用范围，使其能够适应从简单的单保真度确定性神经网络到复杂的多保真度贝叶斯循环神经网络的多种学习场景。

Method: 方法包括构建层次化的多保真度方差估计贝叶斯循环神经网络，能够适应不同学习需求，同时分离认知不确定性和数据噪声。

Result: 结果表明，该方法能够准确预测响应并量化模型误差，同时发现噪声分布（如果存在）。

Conclusion: 结论指出，该方法为科学和工程领域中的不确定性设计和分析提供了新的可能性。

Abstract: Data-driven learning is generalized to consider history-dependent
multi-fidelity data, while quantifying epistemic uncertainty and disentangling
it from data noise (aleatoric uncertainty). This generalization is hierarchical
and adapts to different learning scenarios: from training the simplest
single-fidelity deterministic neural networks up to the proposed multi-fidelity
variance estimation Bayesian recurrent neural networks. The versatility and
generality of the proposed methodology are demonstrated by applying it to
different data-driven constitutive modeling scenarios that include multiple
fidelities with and without aleatoric uncertainty (noise). The method
accurately predicts the response and quantifies model error while also
discovering the noise distribution (when present). This opens opportunities for
future real-world applications in diverse scientific and engineering domains;
especially, the most challenging cases involving design and analysis under
uncertainty.

</details>


### [145] [Soft-ECM: An extension of Evidential C-Means for complex data](https://arxiv.org/abs/2507.13417)
*Armel Soubeiga,Thomas Guyet,Violaine Antoine*

Main category: cs.LG

TL;DR: 本文提出了一种基于信念函数的聚类算法Soft-ECM，用于处理复杂数据（如混合数据和时间序列），仅需半度量即可实现模糊聚类。


<details>
  <summary>Details</summary>
Motivation: 现有基于信念函数的聚类算法无法处理复杂数据（如混合数据或非表格数据），限制了其应用范围。

Method: 通过重新定义Evidential C-Means (ECM)问题，提出Soft-ECM算法，利用半度量定位模糊簇的中心。

Result: 实验表明，Soft-ECM在数值数据上与传统模糊聚类效果相当，并能有效处理混合数据和时间序列。

Conclusion: Soft-ECM扩展了信念函数聚类的应用范围，为复杂数据提供了一种有效的解决方案。

Abstract: Clustering based on belief functions has been gaining increasing attention in
the machine learning community due to its ability to effectively represent
uncertainty and/or imprecision. However, none of the existing algorithms can be
applied to complex data, such as mixed data (numerical and categorical) or
non-tabular data like time series. Indeed, these types of data are, in general,
not represented in a Euclidean space and the aforementioned algorithms make use
of the properties of such spaces, in particular for the construction of
barycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem
for clustering complex data. We propose a new algorithm, Soft-ECM, which
consistently positions the centroids of imprecise clusters requiring only a
semi-metric. Our experiments show that Soft-ECM present results comparable to
conventional fuzzy clustering approaches on numerical data, and we demonstrate
its ability to handle mixed data and its benefits when combining fuzzy
clustering with semi-metrics such as DTW for time series data.

</details>


### [146] [Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity](https://arxiv.org/abs/2507.13423)
*Edward Henderson,Dewi Gould,Richard Everson,George De Ath,Nick Pepper*

Main category: cs.LG

TL;DR: 该论文提出了一种基于图神经网络（GNN）的可解释框架，用于实时评估空管任务需求，优于传统启发式方法。


<details>
  <summary>Details</summary>
Motivation: 现有复杂性指标难以捕捉空管任务需求的细微操作驱动因素，需要更可靠的评估工具。

Method: 采用基于注意力的GNN模型，通过静态交通场景中的交互预测即将发布的指令数量，并通过系统消融飞机测量其对预测的影响。

Result: 该框架显著优于启发式方法，能更可靠地评估场景复杂性，并能将任务需求归因于特定飞机。

Conclusion: 该工具为分析复杂性驱动因素提供了新方法，适用于空管培训和空域重新设计。

Abstract: Real-time assessment of near-term Air Traffic Controller (ATCO) task demand
is a critical challenge in an increasingly crowded airspace, as existing
complexity metrics often fail to capture nuanced operational drivers beyond
simple aircraft counts. This work introduces an interpretable Graph Neural
Network (GNN) framework to address this gap. Our attention-based model predicts
the number of upcoming clearances, the instructions issued to aircraft by
ATCOs, from interactions within static traffic scenarios. Crucially, we derive
an interpretable, per-aircraft task demand score by systematically ablating
aircraft and measuring the impact on the model's predictions. Our framework
significantly outperforms an ATCO-inspired heuristic and is a more reliable
estimator of scenario complexity than established baselines. The resulting tool
can attribute task demand to specific aircraft, offering a new way to analyse
and understand the drivers of complexity for applications in controller
training and airspace redesign.

</details>


### [147] [Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning](https://arxiv.org/abs/2507.13482)
*Seyyed Saeid Cheshmi,Buyao Lyu,Thomas Lisko,Rajesh Rajamani,Robert A. McGovern,Yogatheesan Varatharajah*

Main category: cs.LG

TL;DR: 提出了一种跨模态自监督预训练方法，用于从无标签的IMU-视频数据中学习表示，提高了在分布外IMU数据集上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有HAR方法依赖特定应用标签、泛化能力不足的问题，特别是在不同环境或人群中的数据。

Method: 采用跨模态自监督预训练方法，利用大规模无标签IMU-视频数据学习表示。

Result: 在零样本和少样本评估中，该方法优于当前最先进的IMU-视频预训练和仅IMU预训练方法。

Conclusion: 跨模态预训练是学习通用数据表示的有效工具，尤其在动态数据模态（如IMU信号）中。

Abstract: Human Activity Recognition (HAR) based on wearable inertial sensors plays a
critical role in remote health monitoring. In patients with movement disorders,
the ability to detect abnormal patient movements in their home environments can
enable continuous optimization of treatments and help alert caretakers as
needed. Machine learning approaches have been proposed for HAR tasks using
Inertial Measurement Unit (IMU) data; however, most rely on
application-specific labels and lack generalizability to data collected in
different environments or populations. To address this limitation, we propose a
new cross-modal self-supervised pretraining approach to learn representations
from large-sale unlabeled IMU-video data and demonstrate improved
generalizability in HAR tasks on out of distribution (OOD) IMU datasets,
including a dataset collected from patients with Parkinson's disease.
Specifically, our results indicate that the proposed cross-modal pretraining
approach outperforms the current state-of-the-art IMU-video pretraining
approach and IMU-only pretraining under zero-shot and few-shot evaluations.
Broadly, our study provides evidence that in highly dynamic data modalities,
such as IMU signals, cross-modal pretraining may be a useful tool to learn
generalizable data representations. Our software is available at
https://github.com/scheshmi/IMU-Video-OOD-HAR.

</details>


### [148] [Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents](https://arxiv.org/abs/2507.13491)
*Thomas Banker,Ali Mesbah*

Main category: cs.LG

TL;DR: 论文提出基于模型的智能体作为模型无关强化学习的替代方案，以提高样本效率、安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 模型无关强化学习（RL）在复杂系统中表现优异，但存在样本效率低、学习不安全及可解释性差的问题。

Method: 引入基于模型的智能体，利用系统动力学、成本和约束的可适应模型进行安全策略学习，并结合模型无关RL弥补模型不匹配的缺陷。

Result: 基于模型的智能体（如模型预测控制）能编码先验知识，提升决策的安全性和可解释性。

Conclusion: 结合模型无关RL和基于模型的方法，有望实现样本高效、安全且可解释的决策智能体。

Abstract: Training sophisticated agents for optimal decision-making under uncertainty
has been key to the rapid development of modern autonomous systems across
fields. Notably, model-free reinforcement learning (RL) has enabled
decision-making agents to improve their performance directly through system
interactions, with minimal prior knowledge about the system. Yet, model-free RL
has generally relied on agents equipped with deep neural network function
approximators, appealing to the networks' expressivity to capture the agent's
policy and value function for complex systems. However, neural networks amplify
the issues of sample inefficiency, unsafe learning, and limited
interpretability in model-free RL. To this end, this work introduces
model-based agents as a compelling alternative for control policy
approximation, leveraging adaptable models of system dynamics, cost, and
constraints for safe policy learning. These models can encode prior system
knowledge to inform, constrain, and aid in explaining the agent's decisions,
while deficiencies due to model mismatch can be remedied with model-free RL. We
outline the benefits and challenges of learning model-based agents --
exemplified by model predictive control -- and detail the primary learning
approaches: Bayesian optimization, policy search RL, and offline strategies,
along with their respective strengths. While model-free RL has long been
established, its interplay with model-based agents remains largely unexplored,
motivating our perspective on their combined potentials for sample-efficient
learning of safe and interpretable decision-making agents.

</details>


### [149] [Fake or Real: The Impostor Hunt in Texts for Space Operations](https://arxiv.org/abs/2507.13508)
*Agata Kaczmarek,Dawid Płudowski,Piotr Wilczyński,Przemysław Biecek,Krzysztof Kotowski,Ramez Shendy,Jakub Nalepa,Artur Janicki,Evridiki Ntagiou*

Main category: cs.LG

TL;DR: Kaggle竞赛“Fake or Real”旨在解决AI安全威胁（数据投毒和过度依赖LLM），任务是区分正常和恶意修改的LLM输出。


<details>
  <summary>Details</summary>
Motivation: 基于欧洲航天局资助的项目，识别并解决AI安全中的两大威胁：数据投毒和过度依赖大型语言模型（LLM）。

Method: 参赛者需开发新技术或调整现有方法，以区分正常和恶意修改的LLM输出。

Result: 竞赛鼓励创新方法，填补了该领域的研究空白。

Conclusion: 该竞赛推动了AI安全领域的研究，特别是针对LLM的安全问题。

Abstract: The "Fake or Real" competition hosted on Kaggle
(\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})
is the second part of a series of follow-up competitions and hackathons related
to the "Assurance for Space Domain AI Applications" project funded by the
European Space Agency
(\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).
The competition idea is based on two real-life AI security threats identified
within the project -- data poisoning and overreliance in Large Language Models.
The task is to distinguish between the proper output from LLM and the output
generated under malicious modification of the LLM. As this problem was not
extensively researched, participants are required to develop new techniques to
address this issue or adjust already existing ones to this problem's statement.

</details>


### [150] [Provable Low-Frequency Bias of In-Context Learning of Representations](https://arxiv.org/abs/2507.13540)
*Yongyi Yang,Hidenori Tanaka,Wei Hu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的双收敛框架，解释了大型语言模型（LLMs）如何通过上下文学习（ICL）从输入序列中学习新行为，而无需参数更新。


<details>
  <summary>Details</summary>
Motivation: 研究ICL的机制，解释LLMs如何通过内部化提示的数据生成过程（DGP）结构来超越预训练阶段的学习效果。

Method: 引入双收敛框架，分析隐藏表示在上下文和层间的收敛过程，证明其对平滑（低频）表示的隐式偏好。

Result: 理论解释了ICL的多个经验观察，如表示几何的全局结构性和局部扭曲性，以及能量衰减不消失的现象。

Conclusion: ICL对高频噪声具有内在鲁棒性，为研究其机制提供了理论基础，并有望扩展到更一般的数据分布和设置。

Abstract: In-context learning (ICL) enables large language models (LLMs) to acquire new
behaviors from the input sequence alone without any parameter updates. Recent
studies have shown that ICL can surpass the original meaning learned in
pretraining stage through internalizing the structure the data-generating
process (DGP) of the prompt into the hidden representations. However, the
mechanisms by which LLMs achieve this ability is left open. In this paper, we
present the first rigorous explanation of such phenomena by introducing a
unified framework of double convergence, where hidden representations converge
both over context and across layers. This double convergence process leads to
an implicit bias towards smooth (low-frequency) representations, which we prove
analytically and verify empirically. Our theory explains several open empirical
observations, including why learned representations exhibit globally structured
but locally distorted geometry, and why their total energy decays without
vanishing. Moreover, our theory predicts that ICL has an intrinsic robustness
towards high-frequency noise, which we empirically confirm. These results
provide new insights into the underlying mechanisms of ICL, and a theoretical
foundation to study it that hopefully extends to more general data
distributions and settings.

</details>


### [151] [Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography](https://arxiv.org/abs/2507.13542)
*Beka Begiashvili,Carlos J. Fernandez-Candel,Matías Pérez Paredes*

Main category: cs.LG

TL;DR: 论文提出了一种新型AI衍生的超声心动图参数Acoustic Index，用于量化心脏功能障碍，结合了EDMD和混合神经网络，临床验证显示其AUC为0.89，具有高敏感性和特异性。


<details>
  <summary>Details</summary>
Motivation: 传统超声心动图参数（如EF和GLS）在早期检测心脏功能障碍时存在局限性，需要一种可重复、易解释且操作者无关的新参数。

Method: 结合EDMD和混合神经网络，从超声心动图序列中提取时空动态，通过注意力机制加权并与临床数据融合，生成0到1的连续评分。

Result: 在736名患者的队列中，Acoustic Index的AUC为0.89，敏感性和特异性均超过0.8，表现出稳健的性能。

Conclusion: Acoustic Index是一种物理信息驱动的可解释AI生物标志物，有望用于早期检测和监测，未来需进一步验证和优化。

Abstract: Traditional echocardiographic parameters such as ejection fraction (EF) and
global longitudinal strain (GLS) have limitations in the early detection of
cardiac dysfunction. EF often remains normal despite underlying pathology, and
GLS is influenced by load conditions and vendor variability. There is a growing
need for reproducible, interpretable, and operator-independent parameters that
capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic
parameter designed to quantify cardiac dysfunction from standard ultrasound
views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on
Koopman operator theory with a hybrid neural network that incorporates clinical
metadata. Spatiotemporal dynamics are extracted from echocardiographic
sequences to identify coherent motion patterns. These are weighted via
attention mechanisms and fused with clinical data using manifold learning,
resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac
pathologies and normal controls, the Acoustic Index achieved an area under the
curve (AUC) of 0.89 in an independent test set. Cross-validation across five
folds confirmed the robustness of the model, showing that both sensitivity and
specificity exceeded 0.8 when evaluated on independent data. Threshold-based
analysis demonstrated stable trade-offs between sensitivity and specificity,
with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker
for cardiac function. It shows promise as a scalable, vendor-independent tool
for early detection, triage, and longitudinal monitoring. Future directions
include external validation, longitudinal studies, and adaptation to
disease-specific classifiers.

</details>


### [152] [Time Series Forecastability Measures](https://arxiv.org/abs/2507.13556)
*Rui Wang,Steven Klee,Alexis Roos*

Main category: cs.LG

TL;DR: 提出两种度量指标（谱可预测性评分和最大李雅普诺夫指数）来量化时间序列的可预测性，帮助在模型开发前评估数据特性。


<details>
  <summary>Details</summary>
Motivation: 传统模型评估指标在模型开发后才使用，而这两种指标能在模型开发前评估数据的固有可预测性，帮助优化资源分配和策略制定。

Method: 使用谱可预测性评分评估时间序列的频率成分强度和规律性，用李雅普诺夫指数量化数据生成系统的混沌和稳定性。

Result: 在合成和真实世界数据（M5预测竞赛数据集）上验证了这两种指标能准确反映时间序列的固有可预测性，并与实际预测性能强相关。

Conclusion: 通过提前评估时间序列的可预测性，可以优化资源分配，为可预测性低的产品制定替代策略。

Abstract: This paper proposes using two metrics to quantify the forecastability of time
series prior to model development: the spectral predictability score and the
largest Lyapunov exponent. Unlike traditional model evaluation metrics, these
measures assess the inherent forecastability characteristics of the data before
any forecast attempts. The spectral predictability score evaluates the strength
and regularity of frequency components in the time series, whereas the Lyapunov
exponents quantify the chaos and stability of the system generating the data.
We evaluated the effectiveness of these metrics on both synthetic and
real-world time series from the M5 forecast competition dataset. Our results
demonstrate that these two metrics can correctly reflect the inherent
forecastability of a time series and have a strong correlation with the actual
forecast performance of various models. By understanding the inherent
forecastability of time series before model training, practitioners can focus
their planning efforts on products and supply chain levels that are more
forecastable, while setting appropriate expectations or seeking alternative
strategies for products with limited forecastability.

</details>


### [153] [Change of Thought: Adaptive Test-Time Computation](https://arxiv.org/abs/2507.13569)
*Mrinal Mathur,Mike Doan,Barak Pearlmutter,Sergey Plis*

Main category: cs.LG

TL;DR: SELF-Transformer通过内部迭代更新注意力权重，提升编码器Transformer的表达能力，无需依赖自回归，实现20%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在固定深度下表达能力受限，而自回归方法依赖外部化中间状态。SELF-Transformer旨在通过内部迭代提升表达能力，避免自回归的复杂性。

Method: 引入SELF-Transformer，通过迭代更新注意力权重至固定点，动态调整计算复杂度。

Result: 在编码器基准测试中，准确率提升高达20%，且不增加参数量。

Conclusion: SELF-Transformer通过内部迭代恢复了迭代推理的表达能力，同时保持了纯编码器架构的简洁性。

Abstract: Transformers evaluated in a single, fixed-depth pass are provably limited in
expressive power to the constant-depth circuit class TC0. Running a Transformer
autoregressively removes that ceiling -- first in next-token prediction and,
more recently, in chain-of-thought reasoning. Both regimes rely on feedback
loops that decode internal states into tokens only to re-encode them in
subsequent steps. While this "thinking aloud" mirrors human reasoning,
biological brains iterate without externalising intermediate states as
language. To boost the expressive power of encoder Transformers without
resorting to token-level autoregression, we introduce the SELF-Transformer: an
encoder layer that iteratively refines its own attention weights to a fixed
point. Instead of producing -- in one pass -- the alignment matrix that remixes
the input sequence, the SELF-Transformer iteratively updates that matrix
internally, scaling test-time computation with input difficulty. This
adaptivity yields up to 20\% accuracy gains on encoder-style benchmarks without
increasing parameter count, demonstrating that input-adaptive alignment at test
time offers substantial benefits for only a modest extra compute budget.
Self-Transformers thus recover much of the expressive power of iterative
reasoning while preserving the simplicity of pure encoder architectures.

</details>


### [154] [Apple Intelligence Foundation Language Models: Tech Report 2025](https://arxiv.org/abs/2507.13575)
*Hanzhi Zhou,Erik Hornberger,Pengsheng Guo,Xiyou Zhou,Saiwen Wang,Xin Wang,Yifei He,Xuankai Chang,Rene Rauch,Louis D'hauwe,John Peebles,Alec Doane,Kohen Chia,Jenna Thibodeau,Zi-Yi Dou,Yuanyang Zhang,Ruoming Pang,Reed Li,Zhifeng Chen,Jeremy Warner,Zhaoyang Xu,Sophy Lee,David Mizrahi,Ramsey Tantawi,Chris Chaney,Kelsey Peterson,Jun Qin,Alex Dombrowski,Mira Chiang,Aiswarya Raghavan,Gerard Casamayor,Qibin Chen,Aonan Zhang,Nathalie Tran,Jianyu Wang,Hang Su,Thomas Voice,Alessandro Pappalardo,Brycen Wershing,Prasanth Yadla,Rui Li,Priyal Chhatrapati,Ismael Fernandez,Yusuf Goren,Xin Zheng,Forrest Huang,Tao Lei,Eray Yildiz,Alper Kokmen,Gokul Santhanam,Areeba Kamal,Kaan Elgin,Dian Ang Yap,Jeremy Liu,Peter Gray,Howard Xing,Kieran Liu,Matteo Ronchi,Moritz Schwarzer-Becker,Yun Zhu,Mandana Saebi,Jeremy Snow,David Griffiths,Guillaume Tartavel,Erin Feldman,Simon Lehnerer,Fernando Bermúdez-Medina,Hans Han,Joe Zhou,Xiaoyi Ren,Sujeeth Reddy,Zirui Wang,Tom Gunter,Albert Antony,Yuanzhi Li,John Dennison,Tony Sun,Yena Han,Yi Qin,Sam Davarnia,Jeffrey Bigham,Wayne Shan,Hannah Gillis Coleman,Guillaume Klein,Peng Liu,Muyang Yu,Jack Cackler,Yuan Gao,Crystal Xiao,Binazir Karimzadeh,Zhengdong Zhang,Felix Bai,Albin Madappally Jose,Feng Nan,Nazir Kamaldin,Dong Yin,Hans Hao,Yanchao Sun,Yi Hua,Charles Maalouf,Alex Guillen Garcia,Guoli Yin,Lezhi Li,Mohana Prasad Sathya Moorthy,Hongbin Gao,Jay Tang,Joanna Arreaza-Taylor,Faye Lao,Carina Peng,Josh Shaffer,Dan Masi,Sushma Rao,Tommi Vehvilainen,Senyu Tong,Dongcai Shen,Yang Zhao,Chris Bartels,Peter Fu,Qingqing Cao,Christopher Neubauer,Ethan Li,Mingfei Gao,Rebecca Callahan,Richard Wei,Patrick Dong,Alex Braunstein,Sachin Ravi,Adolfo Lopez Mendez,Kaiwei Huang,Kun Duan,Haoshuo Huang,Rui Qian,Stefano Ligas,Jordan Huffaker,Dongxu Li,Bailin Wang,Nanzhu Wang,Anuva Agarwal,Tait Madsen,Josh Newnham,Abhishek Sharma,Zhile Ren,Deepak Gopinath,Erik Daxberger,Saptarshi Guha,Oron Levy,Jing Lu,Nan Dun,Marc Kirchner,Yinfei Yang,Manjot Bilkhu,Dave Nelson,Anthony Spalvieri-Kruse,Juan Lao Tebar,Yang Xu,Phani Mutyala,Gabriel Jacoby-Cooper,Yingbo Wang,Karla Vega,Vishaal Mahtani,Darren Botten,Eric Wang,Hanli Li,Matthias Paulik,Haoran Yan,Navid Shiee,Yihao Qian,Bugu Wu,Qi Zhu,Ob Adaranijo,Bhuwan Dhingra,Zhe Gan,Nicholas Seidl,Grace Duanmu,Rong Situ,Yiping Ma,Yin Xia,David Riazati,Vasileios Saveris,Anh Nguyen,Michael,Lee,Patrick Sonnenberg,Chinguun Erdenebileg,Yanghao Li,Vivian Ma,James Chou,Isha Garg,Mark Lee,Keen You,Yuhong Li,Ransen Niu,Nandhitha Raghuram,Pulkit Agrawal,Henry Mason,Sumeet Singh,Keyu He,Hong-You Chen,Lucas Guibert,Shiyu Li,Varsha Paidi,Narendran Raghavan,Mingze Xu,Yuli Yang,Sergiu Sima,Irina Belousova,Sprite Chu,Afshin Dehghan,Philipp Dufter,David Haldimann,Zhen Yang,Margit Bowler,Chang Liu,Ying-Chang Cheng,Vivek Rathod,Syd Evans,Wilson Tsao,Dustin Withers,Haitian Sun,Biyao Wang,Peter Grasch,Walker Cheng,Yihao Feng,Vivek Kumar,Frank Chu,Victoria MönchJuan Haladjian,Doug Kang,Jiarui Lu,Ciro Sannino,Max Lam,Floris Weers,Bowen Pan,Kenneth Jung,Dhaval Doshi,Fangping Shi,Olli Saarikivi,Alp Aygar,Josh Elman,Cheng Leong,Eshan Verma,Matthew Lei,Jeff Nichols,Jiulong Shan,Donald Zhang,Lawrence Zhou,Stephen Murphy,Xianzhi Du,Chang Lan,Ankur Jain,Elmira Amirloo,Marcin Eichner,Naomy Sabo,Anupama Mann Anupama,David Qiu,Zhao Meng,Michael FitzMaurice,Peng Zhang,Simon Yeung,Chen Chen,Marco Zuliani,Andrew Hansen,Yang Lu,Brent Ramerth,Ziyi Zhong,Parsa Mazaheri,Matthew Hopkins,Mengyu Li,Simon Wang,David Chen,Farzin Rasteh,Chong Wang,Josh Gardner,Asaf Liberman,Haoxuan You,Andrew Walkingshaw,Xingyu Zhou,Jinhao Lei,Yan Meng,Quentin Keunebroek,Sam Wiseman,Anders Boesen Lindbo Larsen,Yi Zhang,Zaid Ahmed,Haiming Gang,Aaron Franklin,Kelvin Zou,Guillaume Seguin,Jonathan Janke,Rachel Burger,Co Giang,Cheng Shen,Jen Liu,Sanskruti Shah,Xiang Kong,Yiran Fei,TJ Collins,Chen Zhang,Zhiyun Lu,Michael Booker,Qin Ba,Yasutaka Tanaka,Andres Romero Mier Y Teran,Federico Scozzafava,Regan Poston,Jane Li,Eduardo Jimenez,Bas Straathof,Karanjeet Singh,Lindsay Hislop,Rajat Arora,Deepa Seshadri,Boyue Li,Colorado Reed,Zhen Li,TJ Lu,Yi Wang,Kaelen Haag,Nicholas Lusskin,Raunak Sinha,Rahul Nair,Eldon Schoop,Mary Beth Kery,Mehrdad Farajtbar,Brenda Yang,George Horrell,Shiwen Zhao,Dhruti Shah,Cha Chen,Bowen Zhang,Chang Gao,Devi Krishna,Jennifer Mallalieu,Javier Movellan,Di Feng,Emily Zhang,Sam Xu,Junting Pan,Dominik Moritz,Suma Jayaram,Kevin Smith,Dongseong Hwang,Daniel Parilla,Jiaming Hu,You-Cyuan Jhang,Emad Soroush,Fred Hohman,Nan Du,Emma Wang,Sam Dodge,Pragnya Sridhar,Joris Pelemans,Wei Fang,Nina Wenzel,Joseph Yitan Cheng,Hadas Kotek,Chung-Cheng Chiu,Meng Cao,Haijing Fu,Ruixuan Hou,Ke Ye,Diane Zhu,Nikhil Bhendawade,Joseph Astrauskas,Jian Liu,Sai Aitharaju,Wentao Wu,Artsiom Peshko,Hyunjik Kim,Nilesh Shahdadpuri,Andy De Wang,Qi Shan,Piotr Maj,Raul Rea Menacho,Justin Lazarow,Eric Liang Yang,Arsalan Farooq,Donghan Yu,David Güera,Minsik Cho,Kavya Nerella,Yongqiang Wang,Tao Jia,John Park,Jeff Lai,Haotian Zhang,Futang Peng,Daniele Molinari,Aparna Rajamani,Tyler Johnson,Lauren Gardiner,Chao Jia,Violet Yao,Wojciech Kryscinski,Xiujun Li,Shang-Chen Wu*

Main category: cs.LG

TL;DR: 苹果推出两款多语言、多模态基础语言模型，分别用于设备端和服务器端，支持多语言和图像理解，性能优于同类开源模型。


<details>
  <summary>Details</summary>
Motivation: 为苹果设备和服务提供智能功能，同时兼顾性能、成本与隐私保护。

Method: 设备端模型采用KV缓存共享和2位量化训练；服务器模型采用并行轨道混合专家（PT-MoE）架构。训练数据包括网络爬取、授权语料和合成数据，并通过监督微调和强化学习优化。

Result: 模型在公开基准测试和人工评估中表现优异，支持多语言和工具调用。

Conclusion: 苹果通过技术创新和负责任AI策略，实现了高性能、隐私保护的智能模型，并提供了开发者友好的框架。

Abstract: We introduce two multilingual, multimodal foundation language models that
power Apple Intelligence features across Apple devices and services: i a
3B-parameter on-device model optimized for Apple silicon through architectural
innovations such as KV-cache sharing and 2-bit quantization-aware training; and
ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts
PT-MoE transformer that combines track parallelism, mixture-of-experts sparse
computation, and interleaved global-local attention to deliver high quality
with competitive cost on Apple's Private Cloud Compute platform. Both models
are trained on large-scale multilingual and multimodal datasets sourced via
responsible web crawling, licensed corpora, and high-quality synthetic data,
then further refined with supervised fine-tuning and reinforcement learning on
a new asynchronous platform. The resulting models support several additional
languages while understanding images and executing tool calls. In public
benchmarks and human evaluations, both the server model and the on-device model
match or surpass comparably sized open baselines.
  A new Swift-centric Foundation Models framework exposes guided generation,
constrained tool calling, and LoRA adapter fine-tuning, allowing developers to
integrate these capabilities with a few lines of code. The latest advancements
in Apple Intelligence models are grounded in our Responsible AI approach with
safeguards like content filtering and locale-specific evaluation, as well as
our commitment to protecting our users' privacy with innovations like Private
Cloud Compute.

</details>


### [155] [Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries](https://arxiv.org/abs/2507.13579)
*Hyunji Nam,Yanming Wan,Mickel Liu,Jianxun Lian,Natasha Jaques*

Main category: cs.LG

TL;DR: PLUS框架通过生成用户偏好摘要，实现个性化LLM响应，优于传统RLHF和上下文学习方法。


<details>
  <summary>Details</summary>
Motivation: 传统RLHF无法区分用户差异，需开发能捕捉用户个性化偏好的方法。

Method: 提出PLUS框架，通过强化学习生成用户偏好摘要，并动态更新奖励模型。

Result: PLUS能有效捕捉用户偏好，适应新用户和多样话题，并可零样本迁移至GPT-4等模型。

Conclusion: PLUS提供透明、可解释的用户摘要，增强LLM对齐的用户控制。

Abstract: As everyday use cases of large language model (LLM) AI assistants have
expanded, it is becoming increasingly important to personalize responses to
align to different users' preferences and goals. While reinforcement learning
from human feedback (RLHF) is effective at improving LLMs to be generally more
helpful and fluent, it does not account for variability across users, as it
models the entire user population with a single reward model. We present a
novel framework, Preference Learning Using Summarization (PLUS), that learns
text-based summaries of each user's preferences, characteristics, and past
conversations. These summaries condition the reward model, enabling it to make
personalized predictions about the types of responses valued by each user. We
train the user-summarization model with reinforcement learning, and update the
reward model simultaneously, creating an online co-adaptation loop. We show
that in contrast with prior personalized RLHF techniques or with in-context
learning of user information, summaries produced by PLUS capture meaningful
aspects of a user's preferences. Across different pluralistic user datasets, we
show that our method is robust to new users and diverse conversation topics.
Additionally, we demonstrate that the textual summaries generated about users
can be transferred for zero-shot personalization of stronger, proprietary
models like GPT-4. The resulting user summaries are not only concise and
portable, they are easy for users to interpret and modify, allowing for more
transparency and user control in LLM alignment.

</details>


### [156] [Off-Policy Evaluation and Learning for Matching Markets](https://arxiv.org/abs/2507.13608)
*Yudai Hayashi,Shuhei Goda,Yuta Saito*

Main category: cs.LG

TL;DR: 论文提出两种新的离线策略评估（OPE）方法DiPS和DPR，专门针对匹配市场设计，解决了传统方法在双向交互和大规模数据下的不可靠问题。


<details>
  <summary>Details</summary>
Motivation: 匹配市场中的双向交互和大规模数据导致传统OPE方法不可靠，需要新的评估方法。

Method: 结合直接法（DM）、逆倾向得分（IPS）和双重稳健（DR）估计器，并引入中间标签（如初始参与信号）以优化偏差-方差控制。

Result: 理论分析和实验验证表明，DiPS和DPR在偏差和方差控制上优于传统方法，并能扩展到离线策略学习。

Conclusion: 提出的方法在匹配市场的离线评估和学习任务中表现优异，为推荐策略优化提供了有效工具。

Abstract: Matching users based on mutual preferences is a fundamental aspect of
services driven by reciprocal recommendations, such as job search and dating
applications. Although A/B tests remain the gold standard for evaluating new
policies in recommender systems for matching markets, it is costly and
impractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays
a crucial role by enabling the evaluation of recommendation policies using only
offline logged data naturally collected on the platform. However, unlike
conventional recommendation settings, the large scale and bidirectional nature
of user interactions in matching platforms introduce variance issues and
exacerbate reward sparsity, making standard OPE methods unreliable. To address
these challenges and facilitate effective offline evaluation, we propose novel
OPE estimators, \textit{DiPS} and \textit{DPR}, specifically designed for
matching markets. Our methods combine elements of the Direct Method (DM),
Inverse Propensity Score (IPS), and Doubly Robust (DR) estimators while
incorporating intermediate labels, such as initial engagement signals, to
achieve better bias-variance control in matching markets. Theoretically, we
derive the bias and variance of the proposed estimators and demonstrate their
advantages over conventional methods. Furthermore, we show that these
estimators can be seamlessly extended to offline policy learning methods for
improving recommendation policies for making more matches. We empirically
evaluate our methods through experiments on both synthetic data and A/B testing
logs from a real job-matching platform. The empirical results highlight the
superiority of our approach over existing methods in off-policy evaluation and
learning tasks for a variety of configurations.

</details>


### [157] [Tri-Learn Graph Fusion Network for Attributed Graph Clustering](https://arxiv.org/abs/2507.13620)
*Binxiong Li,Yuefei Wang,Xu Xiang,Xue Li,Binyu Zhao,Heyang Gao,Qinyu Zhao,Xi Yu*

Main category: cs.LG

TL;DR: 提出了一种结合GCN、AE和Graph Transformer的Tri-GFN框架，通过三学习机制和特征融合策略提升图聚类性能。


<details>
  <summary>Details</summary>
Motivation: 解决GCN在大规模复杂图数据中的过平滑和过压缩问题，以及Graph Transformer在异构图数据中的性能限制。

Method: 结合GCN、AE和Graph Transformer，通过三学习机制和特征融合策略优化全局与局部信息的一致性。

Result: 在ACM、Reuters和USPS数据集上分别提升0.87%、14.14%和7.58%的准确率。

Conclusion: Tri-GFN在异构图数据中表现优异，适用于新闻分类和主题检索等领域。

Abstract: In recent years, models based on Graph Convolutional Networks (GCN) have made
significant strides in the field of graph data analysis. However, challenges
such as over-smoothing and over-compression remain when handling large-scale
and complex graph datasets, leading to a decline in clustering quality.
Although the Graph Transformer architecture has mitigated some of these issues,
its performance is still limited when processing heterogeneous graph data. To
address these challenges, this study proposes a novel deep clustering framework
that comprising GCN, Autoencoder (AE), and Graph Transformer, termed the
Tri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the
differentiation and consistency of global and local information through a
unique tri-learning mechanism and feature fusion enhancement strategy. The
framework integrates GCN, AE, and Graph Transformer modules. These components
are meticulously fused by a triple-channel enhancement module, which maximizes
the use of both node attributes and topological structures, ensuring robust
clustering representation. The tri-learning mechanism allows mutual learning
among these modules, while the feature fusion strategy enables the model to
capture complex relationships, yielding highly discriminative representations
for graph clustering. It surpasses many state-of-the-art methods, achieving an
accuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the
Reuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding
performance on the Reuters dataset, Tri-GFN can be applied to automatic news
classification, topic retrieval, and related fields.

</details>


### [158] [FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning](https://arxiv.org/abs/2507.13624)
*Daniel Commey,Kamel Abbad,Garth V. Crosby,Lyes Khoukhi*

Main category: cs.LG

TL;DR: FedSkipTwin是一种基于服务器端数字孪生的客户端跳过算法，通过预测梯度更新的大小和不确定性来减少通信开销，在非IID数据下节省带宽并提升模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的通信开销是主要瓶颈，尤其是移动和物联网设备的带宽受限问题。

Method: 使用轻量级LSTM数字孪生预测客户端的梯度更新，仅在预测值超过阈值时请求通信，否则跳过轮次。

Result: 在UCI-HAR和MNIST数据集上，FedSkipTwin减少12-15.5%的通信量，同时模型精度提升0.5个百分点。

Conclusion: 预测引导的跳过策略是带宽受限边缘环境中资源感知联邦学习的实用有效方法。

Abstract: Communication overhead remains a primary bottleneck in federated learning
(FL), particularly for applications involving mobile and IoT devices with
constrained bandwidth. This work introduces FedSkipTwin, a novel
client-skipping algorithm driven by lightweight, server-side digital twins.
Each twin, implemented as a simple LSTM, observes a client's historical
sequence of gradient norms to forecast both the magnitude and the epistemic
uncertainty of its next update. The server leverages these predictions,
requesting communication only when either value exceeds a predefined threshold;
otherwise, it instructs the client to skip the round, thereby saving bandwidth.
Experiments are conducted on the UCI-HAR and MNIST datasets with 10 clients
under a non-IID data distribution. The results demonstrate that FedSkipTwin
reduces total communication by 12-15.5% across 20 rounds while simultaneously
improving final model accuracy by up to 0.5 percentage points compared to the
standard FedAvg algorithm. These findings establish that prediction-guided
skipping is a practical and effective strategy for resource-aware FL in
bandwidth-constrained edge environments.

</details>


### [159] [A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design](https://arxiv.org/abs/2507.13646)
*Nimisha Ghosh,Daniele Santoni,Debaleena Nawn,Eleonora Ottaviani,Giovanni Felici*

Main category: cs.LG

TL;DR: 综述了基于Transformer的模型在蛋白质序列分析与设计中的最新进展，包括应用、优缺点及未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer模型在生物信息学中的应用，特别是蛋白质序列分析与设计，以填补研究空白并指导未来工作。

Method: 回顾并分析了大量相关研究，涵盖基因本体、蛋白质功能与结构识别、蛋白质生成及结合等领域。

Result: 总结了现有研究的优缺点，为读者提供了全面的视角，并指出了未来发展的潜在方向。

Conclusion: 本文综述有助于研究者了解该领域的最新进展，并为未来研究提供方向。

Abstract: The impact of Transformer-based language models has been unprecedented in
Natural Language Processing (NLP). The success of such models has also led to
their adoption in other fields including bioinformatics. Taking this into
account, this paper discusses recent advances in Transformer-based models for
protein sequence analysis and design. In this review, we have discussed and
analysed a significant number of works pertaining to such applications. These
applications encompass gene ontology, functional and structural protein
identification, generation of de novo proteins and binding of proteins. We
attempt to shed light on the strength and weaknesses of the discussed works to
provide a comprehensive insight to readers. Finally, we highlight shortcomings
in existing research and explore potential avenues for future developments. We
believe that this review will help researchers working in this field to have an
overall idea of the state of the art in this field, and to orient their future
studies.

</details>


### [160] [Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction](https://arxiv.org/abs/2507.13685)
*Yue Yang,Zihan Su,Ying Zhang,Chang Chuan Goh,Yuxiang Lin,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: 论文提出GRU-KAN和LSTM-KAN模型，用于提前三个月以上预测贷款违约，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有贷款违约预测模型在早期预测中的准确性和时间依赖性不足的问题。

Method: 结合Kolmogorov-Arnold Networks (KAN)与GRU和LSTM网络，提出GRU-KAN和LSTM-KAN模型。

Result: 新模型在提前三个月和八个月的预测中分别达到92%和88%的准确率，优于基线模型。

Conclusion: GRU-KAN和LSTM-KAN模型在贷款违约早期预测中表现优异，具有实际应用价值。

Abstract: This study addresses a critical challenge in time series anomaly detection:
enhancing the predictive capability of loan default models more than three
months in advance to enable early identification of default events, helping
financial institutions implement preventive measures before risk events
materialize. Existing methods have significant drawbacks, such as their lack of
accuracy in early predictions and their dependence on training and testing
within the same year and specific time frames. These issues limit their
practical use, particularly with out-of-time data. To address these, the study
introduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge
Kolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long
Short-Term Memory (LSTM) networks. The proposed models were evaluated against
the baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms
of accuracy, precision, recall, F1 and AUC in different lengths of feature
window, sample sizes, and early prediction intervals. The results demonstrate
that the proposed model achieves a prediction accuracy of over 92% three months
in advance and over 88% eight months in advance, significantly outperforming
existing baselines.

</details>


### [161] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
*Martin Krutský,Gustav Šír,Vyacheslav Kungurtsev,Georgios Korpas*

Main category: cs.LG

TL;DR: PI-GNNs在组合优化问题中表现良好，但随着问题图密度增加，性能显著下降。研究发现训练动态中的相变现象，并提出基于模糊逻辑和二值化神经网络的改进方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 研究PI-GNNs在组合优化问题中的性能表现，尤其是图密度增加时的性能下降问题。

Method: 分析PI-GNNs的训练动态，提出基于模糊逻辑和二值化神经网络的改进策略。

Result: 改进方法显著提升了PI-GNNs在高密度图问题中的性能。

Conclusion: 通过理论分析和实验验证，改进方法有效解决了PI-GNNs在高密度图中的性能问题。

Abstract: Physics-inspired graph neural networks (PI-GNNs) have been utilized as an
efficient unsupervised framework for relaxing combinatorial optimization
problems encoded through a specific graph structure and loss, reflecting
dependencies between the problem's variables. While the framework has yielded
promising results in various combinatorial problems, we show that the
performance of PI-GNNs systematically plummets with an increasing density of
the combinatorial problem graphs. Our analysis reveals an interesting phase
transition in the PI-GNNs' training dynamics, associated with degenerate
solutions for the denser problems, highlighting a discrepancy between the
relaxed, real-valued model outputs and the binary-valued problem solutions. To
address the discrepancy, we propose principled alternatives to the naive
strategy used in PI-GNNs by building on insights from fuzzy logic and binarized
neural networks. Our experiments demonstrate that the portfolio of proposed
methods significantly improves the performance of PI-GNNs in increasingly dense
settings.

</details>


### [162] [Bayesian Optimization for Molecules Should Be Pareto-Aware](https://arxiv.org/abs/2507.13704)
*Anabel Yong,Austin Tripp,Layla Hosseini-Gerami,Brooks Paige*

Main category: cs.LG

TL;DR: 多目标贝叶斯优化（MOBO）在分子设计中优于标量化方法，尤其是在低数据情况下。


<details>
  <summary>Details</summary>
Motivation: 探讨MOBO在分子设计中的实际优势，尤其是与标量化方法相比。

Method: 使用基于Pareto的MOBO策略（EHVI）与固定权重的标量化方法（EI）进行对比实验。

Result: EHVI在Pareto前沿覆盖、收敛速度和化学多样性方面均优于EI。

Conclusion: Pareto感知的获取策略在分子优化中具有实际优势，特别是在有限预算和非平凡权衡的情况下。

Abstract: Multi-objective Bayesian optimization (MOBO) provides a principled framework
for navigating trade-offs in molecular design. However, its empirical
advantages over scalarized alternatives remain underexplored. We benchmark a
simple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --
against a simple fixed-weight scalarized baseline using Expected Improvement
(EI), under a tightly controlled setup with identical Gaussian Process
surrogates and molecular representations. Across three molecular optimization
tasks, EHVI consistently outperforms scalarized EI in terms of Pareto front
coverage, convergence speed, and chemical diversity. While scalarization
encompasses flexible variants -- including random or adaptive schemes -- our
results show that even strong deterministic instantiations can underperform in
low-data regimes. These findings offer concrete evidence for the practical
advantages of Pareto-aware acquisition in de novo molecular optimization,
especially when evaluation budgets are limited and trade-offs are nontrivial.

</details>


### [163] [Learning Deformable Body Interactions With Adaptive Spatial Tokenization](https://arxiv.org/abs/2507.13707)
*Hao Wang,Yu Liu,Daniel Biggs,Haoru Wang,Jiandong Yu,Ping Huang*

Main category: cs.LG

TL;DR: 提出了一种自适应空间标记化（AST）方法，通过网格划分和注意力机制，高效模拟可变形体交互，解决了现有方法在大规模网格中的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 学习基于图神经网络（GNN）的方法在模拟复杂物理系统时存在可扩展性问题，尤其是在处理大规模网格时动态创建全局边缘的计算成本过高。

Method: 将模拟空间划分为网格单元，将非结构化网格映射到结构化网格上，并通过交叉注意力模块将稀疏单元映射为紧凑的固定长度嵌入，利用自注意力模块预测潜在空间中的下一状态。

Result: 实验表明，该方法在大规模网格（超过10万个节点）上显著优于现有方法，且计算效率更高。

Conclusion: AST方法通过结合标记化和注意力机制，实现了高效且可扩展的可变形体交互模拟，并贡献了一个新的大规模数据集。

Abstract: Simulating interactions between deformable bodies is vital in fields like
material science, mechanical design, and robotics. While learning-based methods
with Graph Neural Networks (GNNs) are effective at solving complex physical
systems, they encounter scalability issues when modeling deformable body
interactions. To model interactions between objects, pairwise global edges have
to be created dynamically, which is computationally intensive and impractical
for large-scale meshes. To overcome these challenges, drawing on insights from
geometric representations, we propose an Adaptive Spatial Tokenization (AST)
method for efficient representation of physical states. By dividing the
simulation space into a grid of cells and mapping unstructured meshes onto this
structured grid, our approach naturally groups adjacent mesh nodes. We then
apply a cross-attention module to map the sparse cells into a compact,
fixed-length embedding, serving as tokens for the entire physical state.
Self-attention modules are employed to predict the next state over these tokens
in latent space. This framework leverages the efficiency of tokenization and
the expressive power of attention mechanisms to achieve accurate and scalable
simulation results. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches in modeling deformable
body interactions. Notably, it remains effective on large-scale simulations
with meshes exceeding 100,000 nodes, where existing methods are hindered by
computational limitations. Additionally, we contribute a novel large-scale
dataset encompassing a wide range of deformable body interactions to support
future research in this area.

</details>


### [164] [Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods](https://arxiv.org/abs/2507.13716)
*Danilo Avola,Andrea Bernardini,Giancarlo Crocetti,Andrea Ladogana,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 该研究系统比较了传统机器学习和深度学习模型在帕金森病（PD）分类中的表现，发现CNN-LSTM模型表现最佳，同时XGBoost等传统分类器也具竞争力。


<details>
  <summary>Details</summary>
Motivation: 早期诊断PD对临床干预至关重要，EEG是一种非侵入性检测手段，但开发可靠的自动化诊断模型仍具挑战。

Method: 采用统一的七步预处理流程，并应用一致的交叉验证和评估标准，比较传统ML和DL模型在PD分类中的表现。

Result: CNN-LSTM模型表现最佳，但XGBoost等传统分类器也展现出较强的预测能力。

Conclusion: 研究为未来EEG神经诊断领域提供了可靠的基线结果和参考框架，强调了科学严谨性和可重复性。

Abstract: Parkinson's Disease PD is a progressive neurodegenerative disorder that
affects motor and cognitive functions with early diagnosis being critical for
effective clinical intervention Electroencephalography EEG offers a noninvasive
and costeffective means of detecting PDrelated neural alterations yet the
development of reliable automated diagnostic models remains a challenge In this
study we conduct a systematic benchmark of traditional machine learning ML and
deep learning DL models for classifying PD using a publicly available oddball
task dataset Our aim is to lay the groundwork for developing an effective
learning system and to determine which approach produces the best results We
implement a unified sevenstep preprocessing pipeline and apply consistent
subjectwise crossvalidation and evaluation criteria to ensure comparability
across models Our results demonstrate that while baseline deep learning
architectures particularly CNNLSTM models achieve the best performance compared
to other deep learning architectures underlining the importance of capturing
longrange temporal dependencies several traditional classifiers such as XGBoost
also offer strong predictive accuracy and calibrated decision boundaries By
rigorously comparing these baselines our work provides a solid reference
framework for future studies aiming to develop and evaluate more complex or
specialized architectures Establishing a reliable set of baseline results is
essential to contextualize improvements introduced by novel methods ensuring
scientific rigor and reproducibility in the evolving field of EEGbased
neurodiagnostics

</details>


### [165] [Bi-GRU Based Deception Detection using EEG Signals](https://arxiv.org/abs/2507.13718)
*Danilo Avola,Muhammad Yasir Bilal,Emad Emam,Cristina Lakasz,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 本文提出了一种基于Bi-GRU的深度学习模型，利用EEG信号检测欺骗行为，测试准确率达97%。


<details>
  <summary>Details</summary>
Motivation: 欺骗检测在安全、心理学和法医学等领域具有重要意义，但传统方法存在局限性。

Method: 使用Bag-of-Lies数据集的EEG信号，训练Bi-GRU神经网络进行二分类。

Result: 模型测试准确率为97%，且精确率、召回率和F1分数均表现优异。

Conclusion: 双向时序建模在EEG欺骗检测中效果显著，具有实时应用潜力，未来可探索更先进的神经网络架构。

Abstract: Deception detection is a significant challenge in fields such as security,
psychology, and forensics. This study presents a deep learning approach for
classifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)
signals from the Bag-of-Lies dataset, a multimodal corpus designed for
naturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit
(Bi-GRU) neural network was trained to perform binary classification of EEG
samples. The model achieved a test accuracy of 97\%, along with high precision,
recall, and F1-scores across both classes. These results demonstrate the
effectiveness of using bidirectional temporal modeling for EEG-based deception
detection and suggest potential for real-time applications and future
exploration of advanced neural architectures.

</details>


### [166] [Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion](https://arxiv.org/abs/2507.13721)
*Zizhao Zhang,Tianxiang Zhao,Yu Sun,Liping Sun,Jichuan Kang*

Main category: cs.LG

TL;DR: 本文提出了一种混合特征融合框架，用于构建自主货船故障模式的图结构数据集，显著提升了文献检索效率和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 解决自主货船组件故障引发的级联反应及应急决策中的不确定性。

Method: 采用改进的布谷鸟搜索算法（HN-CSA）提升检索效率，构建分层特征融合框架，结合Word2Vec、BERT-KPCA和Sentence-BERT处理特征。

Result: 数据集覆盖12个系统、1,262种故障模式和6,150条传播路径，GATE-GNN模型分类准确率为0.735，预测F1分数达0.93。

Conclusion: 为自主货船的故障分析、风险评估和智能决策系统提供了可靠支持。

Abstract: To address the challenges posed by cascading reactions caused by component
failures in autonomous cargo ships (ACS) and the uncertainties in emergency
decision-making, this paper proposes a novel hybrid feature fusion framework
for constructing a graph-structured dataset of failure modes. By employing an
improved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency
is significantly enhanced, achieving improvements of 7.1% and 3.4% compared to
the NSGA-II and CSA search algorithms, respectively. A hierarchical feature
fusion framework is constructed, using Word2Vec encoding to encode
subsystem/component features, BERT-KPCA to process failure modes/reasons, and
Sentence-BERT to quantify the semantic association between failure impact and
emergency decision-making. The dataset covers 12 systems, 1,262 failure modes,
and 6,150 propagation paths. Validation results show that the GATE-GNN model
achieves a classification accuracy of 0.735, comparable to existing benchmarks.
Additionally, a silhouette coefficient of 0.641 indicates that the features are
highly distinguishable. In the label prediction results, the Shore-based
Meteorological Service System achieved an F1 score of 0.93, demonstrating high
prediction accuracy. This paper not only provides a solid foundation for
failure analysis in autonomous cargo ships but also offers reliable support for
fault diagnosis, risk assessment, and intelligent decision-making systems. The
link to the dataset is
https://github.com/wojiufukele/Graph-Structured-about-CSA.

</details>


### [167] [Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics](https://arxiv.org/abs/2507.13727)
*René Heinrich,Lukas Rauch,Bernhard Sick,Christoph Scholz*

Main category: cs.LG

TL;DR: 研究探讨了对抗训练在音频分类中如何提升模型对数据分布偏移和对抗攻击的鲁棒性，发现输出空间攻击策略能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 对抗训练对音频分类中数据分布偏移和对抗攻击的鲁棒性影响尚未充分研究，本文旨在填补这一空白。

Method: 采用两种对抗训练策略（输出空间攻击和嵌入空间攻击），在两种模型架构（ConvNeXt和AudioProtoPNet）上进行实验，使用鸟类声音分类基准评估。

Result: 输出空间攻击策略显著提升模型在干净测试数据上的性能（平均10.5%），同时增强对抗鲁棒性。

Conclusion: 对抗训练在音频分类中具有潜力，可同时应对数据分布偏移和对抗攻击。

Abstract: Adversarial training is a promising strategy for enhancing model robustness
against adversarial attacks. However, its impact on generalization under
substantial data distribution shifts in audio classification remains largely
unexplored. To address this gap, this work investigates how different
adversarial training strategies improve generalization performance and
adversarial robustness in audio classification. The study focuses on two model
architectures: a conventional convolutional neural network (ConvNeXt) and an
inherently interpretable prototype-based model (AudioProtoPNet). The approach
is evaluated using a challenging bird sound classification benchmark. This
benchmark is characterized by pronounced distribution shifts between training
and test data due to varying environmental conditions and recording methods, a
common real-world challenge. The investigation explores two adversarial
training strategies: one based on output-space attacks that maximize the
classification loss function, and another based on embedding-space attacks
designed to maximize embedding dissimilarity. These attack types are also used
for robustness evaluation. Additionally, for AudioProtoPNet, the study assesses
the stability of its learned prototypes under targeted embedding-space attacks.
Results show that adversarial training, particularly using output-space
attacks, improves clean test data performance by an average of 10.5% relative
and simultaneously strengthens the adversarial robustness of the models. These
findings, although derived from the bird sound domain, suggest that adversarial
training holds potential to enhance robustness against both strong distribution
shifts and adversarial attacks in challenging audio classification settings.

</details>


### [168] [An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC](https://arxiv.org/abs/2507.13736)
*Matthias Jobst,Tim Langer,Chen Liu,Mehmet Alici,Hector A. Gonzalez,Christian Mayr*

Main category: cs.LG

TL;DR: 提出了一个多层的DNN调度框架，扩展了OctopuScheduler，支持从PyTorch模型到SpiNNaker2芯片的端到端推理。


<details>
  <summary>Details</summary>
Motivation: 为了在神经形态平台SpiNNaker2上实现大规模复杂DNN（如Transformer）的边缘计算。

Method: 结合前端量化与降阶步骤，提出一个端到端的调度框架。

Result: 实现了在SpiNNaker2芯片上高效运行复杂DNN的能力。

Conclusion: 该框架为神经形态硬件上的大规模DNN推理提供了可行的解决方案。

Abstract: This work presents a multi-layer DNN scheduling framework as an extension of
OctopuScheduler, providing an end-to-end flow from PyTorch models to inference
on a single SpiNNaker2 chip. Together with a front-end comprised of
quantization and lowering steps, the proposed framework enables the edge-based
execution of large and complex DNNs up to transformer scale using the
neuromorphic platform SpiNNaker2.

</details>


### [169] [SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification](https://arxiv.org/abs/2507.13741)
*Shangyou Wang,Zezhong Ding,Xike Xie*

Main category: cs.LG

TL;DR: SamGoG框架通过基于采样的图-图学习方法，有效解决图分类任务中的类别和大小不平衡问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实中的图数据常存在类别和大小不平衡问题，影响模型性能，现有方法通常只解决一种不平衡或计算成本高。

Method: 提出SamGoG框架，通过重要性采样构建多个图-图结构，结合可学习相似性和自适应节点度提升边同质性。

Result: 在基准数据集上，SamGoG实现了15.66%的准确率提升和6.7倍的训练加速。

Conclusion: SamGoG是一种高效且通用的框架，可显著提升图分类任务的性能。

Abstract: Graph Neural Networks (GNNs) have shown remarkable success in graph
classification tasks by capturing both structural and feature-based
representations. However, real-world graphs often exhibit two critical forms of
imbalance: class imbalance and graph size imbalance. These imbalances can bias
the learning process and degrade model performance. Existing methods typically
address only one type of imbalance or incur high computational costs. In this
work, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning
framework that effectively mitigates both class and graph size imbalance.
SamGoG constructs multiple GoGs through an efficient importance-based sampling
mechanism and trains on them sequentially. This sampling mechanism incorporates
the learnable pairwise similarity and adaptive GoG node degree to enhance edge
homophily, thus improving downstream model quality. SamGoG can seamlessly
integrate with various downstream GNNs, enabling their efficient adaptation for
graph classification tasks. Extensive experiments on benchmark datasets
demonstrate that SamGoG achieves state-of-the-art performance with up to a
15.66% accuracy improvement with 6.7$\times$ training acceleration.

</details>


### [170] [Search-Optimized Quantization in Biomedical Ontology Alignment](https://arxiv.org/abs/2507.13742)
*Oussama Bouaggad,Natalia Grabar*

Main category: cs.LG

TL;DR: 论文提出了一种基于监督学习的变压器模型优化方法，用于生物医学本体对齐，通过动态量化和优化工具显著提升了推理速度和内存效率。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型规模和计算需求的增加，在资源受限环境中部署模型面临挑战，如能耗、内存使用和延迟问题。

Method: 采用基于余弦语义相似度的监督学习方法，结合Microsoft Olive、ONNX Runtime、Intel Neural Compressor和IPEX进行动态量化优化。

Result: 在DEFT 2020评估任务中达到新SOTA，推理速度提升20倍，内存使用减少约70%，性能指标保持不变。

Conclusion: 该方法有效解决了资源受限环境中的模型部署问题，为高效优化技术提供了新方向。

Abstract: In the fast-moving world of AI, as organizations and researchers develop more
advanced models, they face challenges due to their sheer size and computational
demands. Deploying such models on edge devices or in resource-constrained
environments adds further challenges related to energy consumption, memory
usage and latency. To address these challenges, emerging trends are shaping the
future of efficient model optimization techniques. From this premise, by
employing supervised state-of-the-art transformer-based models, this research
introduces a systematic method for ontology alignment, grounded in cosine-based
semantic similarity between a biomedical layman vocabulary and the Unified
Medical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to
search for target optimizations among different Execution Providers (EPs) using
the ONNX Runtime backend, followed by an assembled process of dynamic
quantization employing Intel Neural Compressor and IPEX (Intel Extension for
PyTorch). Through our optimization process, we conduct extensive assessments on
the two tasks from the DEFT 2020 Evaluation Campaign, achieving a new
state-of-the-art in both. We retain performance metrics intact, while attaining
an average inference speed-up of 20x and reducing memory usage by approximately
70%.

</details>


### [171] [MolPIF: A Parameter Interpolation Flow Model for Molecule Generation](https://arxiv.org/abs/2507.13762)
*Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Mingyue Zheng,Qian Shi*

Main category: cs.LG

TL;DR: 提出了一种新的参数插值流模型（PIF），用于分子生成，并在药物设计中展示了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的贝叶斯流网络（BFNs）在灵活性和适应性上存在局限，需要更高效的参数空间模型。

Method: 提出PIF模型，基于参数插值流，提供详细的理论基础和训练推理流程，并开发MolPIF用于药物设计。

Result: MolPIF在多种指标上优于基线模型。

Conclusion: 验证了参数空间生成模型的有效性，为模型设计提供了新视角。

Abstract: Advances in deep learning for molecular generation show promise in
accelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown
impressive performance across diverse chemical tasks, with their success often
ascribed to the paradigm of modeling in a low-variance parameter space.
However, the Bayesian inference-based strategy imposes limitations on designing
more flexible distribution transformation pathways, making it challenging to
adapt to diverse data distributions and varied task requirements. Furthermore,
the potential for simpler, more efficient parameter-space-based models is
unexplored. To address this, we propose a novel Parameter Interpolation Flow
model (named PIF) with detailed theoretical foundation, training, and inference
procedures. We then develop MolPIF for structure-based drug design,
demonstrating its superior performance across diverse metrics compared to
baselines. This work validates the effectiveness of parameter-space-based
generative modeling paradigm for molecules and offers new perspectives for
model design.

</details>


### [172] [Dual-Center Graph Clustering with Neighbor Distribution](https://arxiv.org/abs/2507.13765)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Li Jin,Liqiang Nie*

Main category: cs.LG

TL;DR: 提出了一种基于邻居分布特性的双中心图聚类方法（DCGC），通过邻居分布作为监督信号和双中心优化，提升了聚类效果。


<details>
  <summary>Details</summary>
Motivation: 传统目标导向聚类方法依赖伪标签和单中心优化，导致监督信号不可靠且指导不完整。

Method: 利用邻居分布作为监督信号挖掘对比学习中的难负样本，并引入邻居分布中心与特征中心共同构建双目标分布进行优化。

Result: 实验证明该方法在性能和效果上优于现有方法。

Conclusion: DCGC通过可靠的邻居分布监督和双中心优化，显著提升了图聚类的效果。

Abstract: Graph clustering is crucial for unraveling intricate data structures, yet it
presents significant challenges due to its unsupervised nature. Recently,
goal-directed clustering techniques have yielded impressive results, with
contrastive learning methods leveraging pseudo-label garnering considerable
attention. Nonetheless, pseudo-label as a supervision signal is unreliable and
existing goal-directed approaches utilize only features to construct a
single-target distribution for single-center optimization, which lead to
incomplete and less dependable guidance. In our work, we propose a novel
Dual-Center Graph Clustering (DCGC) approach based on neighbor distribution
properties, which includes representation learning with neighbor distribution
and dual-center optimization. Specifically, we utilize neighbor distribution as
a supervision signal to mine hard negative samples in contrastive learning,
which is reliable and enhances the effectiveness of representation learning.
Furthermore, neighbor distribution center is introduced alongside feature
center to jointly construct a dual-target distribution for dual-center
optimization. Extensive experiments and analysis demonstrate superior
performance and effectiveness of our proposed method.

</details>


### [173] [On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach](https://arxiv.org/abs/2507.13805)
*Tim Rensmeyer,Denis Kramer,Oliver Niggemann*

Main category: cs.LG

TL;DR: 论文提出了一种基于贝叶斯神经网络的方法，用于微调预训练的基础模型，并通过实时学习工作流程自动检测和采样稀有事件。


<details>
  <summary>Details</summary>
Motivation: 由于从头计算原子间力的计算复杂性，机器学习力场的研究变得活跃，但生成足够多样化的训练数据集仍具有挑战性，尤其是在稀有事件或大配置空间系统中。

Method: 采用贝叶斯神经网络方法微调预训练的基础模型，结合实时学习工作流程，通过模型不确定性自动更新训练数据。

Result: 该方法能够在保持预设精度的同时自动微调模型，并能高效检测和采样稀有事件（如过渡态）。

Conclusion: 提出的方法解决了基础模型微调中的不确定性量化问题，为稀有事件建模提供了实用解决方案。

Abstract: Due to the computational complexity of evaluating interatomic forces from
first principles, the creation of interatomic machine learning force fields has
become a highly active field of research. However, the generation of training
datasets of sufficient size and sample diversity itself comes with a
computational burden that can make this approach impractical for modeling rare
events or systems with a large configuration space. Fine-tuning foundation
models that have been pre-trained on large-scale material or molecular
databases offers a promising opportunity to reduce the amount of training data
necessary to reach a desired level of accuracy. However, even if this approach
requires less training data overall, creating a suitable training dataset can
still be a very challenging problem, especially for systems with rare events
and for end-users who don't have an extensive background in machine learning.
In on-the-fly learning, the creation of a training dataset can be largely
automated by using model uncertainty during the simulation to decide if the
model is accurate enough or if a structure should be recalculated with
classical methods and used to update the model. A key challenge for applying
this form of active learning to the fine-tuning of foundation models is how to
assess the uncertainty of those models during the fine-tuning process, even
though most foundation models lack any form of uncertainty quantification. In
this paper, we overcome this challenge by introducing a fine-tuning approach
based on Bayesian neural network methods and a subsequent on-the-fly workflow
that automatically fine-tunes the model while maintaining a pre-specified
accuracy and can detect rare events such as transition states and sample them
at an increased rate relative to their occurrence.

</details>


### [174] [Scalable Submodular Policy Optimization via Pruned Submodularity Graph](https://arxiv.org/abs/2507.13834)
*Aditi Anand,Suman Banerjee,Dildar Ali*

Main category: cs.LG

TL;DR: 论文研究了强化学习中奖励函数为次模函数的问题，提出了一种基于修剪次模性图的方法，以在可行计算时间内提供近似最优解。实验表明该方法优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中奖励函数通常为加性，但现实中许多问题（如路径规划、覆盖控制）的奖励函数表现为递减回报，可用次模函数建模。本文旨在解决此类问题。

Method: 提出了一种基于修剪次模性图的方法，该方法在计算时间和空间复杂度上可行，并提供性能保证。

Result: 实验结果表明，所提方法获得的策略比基线方法产生更高的奖励。

Conclusion: 该方法为次模奖励函数的强化学习问题提供了有效的近似解决方案，优于现有方法。

Abstract: In Reinforcement Learning (abbreviated as RL), an agent interacts with the
environment via a set of possible actions, and a reward is generated from some
unknown distribution. The task here is to find an optimal set of actions such
that the reward after a certain time step gets maximized. In a traditional
setup, the reward function in an RL Problem is considered additive. However, in
reality, there exist many problems, including path planning, coverage control,
etc., the reward function follows the diminishing return, which can be modeled
as a submodular function. In this paper, we study a variant of the RL Problem
where the reward function is submodular, and our objective is to find an
optimal policy such that this reward function gets maximized. We have proposed
a pruned submodularity graph-based approach that provides a provably
approximate solution in a feasible computation time. The proposed approach has
been analyzed to understand its time and space requirements as well as a
performance guarantee. We have experimented with a benchmark agent-environment
setup, which has been used for similar previous studies, and the results are
reported. From the results, we observe that the policy obtained by our proposed
approach leads to more reward than the baseline methods.

</details>


### [175] [Self-supervised learning on gene expression data](https://arxiv.org/abs/2507.13912)
*Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar*

Main category: cs.LG

TL;DR: 研究探讨了自监督学习方法在基因表达数据表型预测中的应用，证明其优于传统监督学习，并减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 基因表达数据标注成本高，传统监督学习依赖大量标注数据，自监督学习能直接从无标签数据中提取信息。

Method: 选取三种自监督学习方法，评估其在基因表达数据中的表现，并用于下游预测任务。

Result: 自监督学习方法能有效捕捉复杂信息，提高预测准确性，优于传统监督模型。

Conclusion: 自监督学习在基因表达数据分析中具有潜力，未来研究可进一步优化其应用。

Abstract: Predicting phenotypes from gene expression data is a crucial task in
biomedical research, enabling insights into disease mechanisms, drug responses,
and personalized medicine. Traditional machine learning and deep learning rely
on supervised learning, which requires large quantities of labeled data that
are costly and time-consuming to obtain in the case of gene expression data.
Self-supervised learning has recently emerged as a promising approach to
overcome these limitations by extracting information directly from the
structure of unlabeled data. In this study, we investigate the application of
state-of-the-art self-supervised learning methods to bulk gene expression data
for phenotype prediction. We selected three self-supervised methods, based on
different approaches, to assess their ability to exploit the inherent structure
of the data and to generate qualitative representations which can be used for
downstream predictive tasks. By using several publicly available gene
expression datasets, we demonstrate how the selected methods can effectively
capture complex information and improve phenotype prediction accuracy. The
results obtained show that self-supervised learning methods can outperform
traditional supervised models besides offering significant advantage by
reducing the dependency on annotated data. We provide a comprehensive analysis
of the performance of each method by highlighting their strengths and
limitations. We also provide recommendations for using these methods depending
on the case under study. Finally, we outline future research directions to
enhance the application of self-supervised learning in the field of gene
expression data analysis. This study is the first work that deals with bulk
RNA-Seq data and self-supervised learning.

</details>


### [176] [Reframing attention as a reinforcement learning problem for causal discovery](https://arxiv.org/abs/2507.13920)
*Turan Orujlu,Christian Gumbsch,Martin V. Butz,Charley M Wu*

Main category: cs.LG

TL;DR: 提出了一种新的因果过程框架，用于表示动态因果结构，并通过强化学习实现因果推理。


<details>
  <summary>Details</summary>
Motivation: 现有因果模型多假设静态因果图，忽视了因果交互的动态性，因此需要一种新理论来填补这一空白。

Method: 引入Causal Process框架及其实现模型Causal Process Model，将Transformer的注意力机制与强化学习结合，推断可解释的因果过程。

Result: 在强化学习环境中，该方法在因果表示学习和智能体性能上优于现有方法，并能恢复动态因果过程图。

Conclusion: Causal Process框架为动态因果推理提供了有效工具，结合强化学习实现了可解释的因果表示。

Abstract: Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.

</details>


### [177] [MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space](https://arxiv.org/abs/2507.13950)
*Jingbo Liang,Bruna Jacobson*

Main category: cs.LG

TL;DR: MoDyGAN结合分子动力学模拟和生成对抗网络，通过将蛋白质3D结构转换为2D矩阵，高效探索蛋白质构象空间。


<details>
  <summary>Details</summary>
Motivation: 传统基于物理的动态模拟计算成本高，限制了蛋白质构象空间的探索。

Method: 提出MoDyGAN管道，利用GAN生成蛋白质构象，并通过双判别器和集成学习优化结果。

Result: 在三种刚性蛋白质上验证了生成新构象的可行性，并在十丙氨酸案例中展示了与SMD模拟的一致性。

Conclusion: 将蛋白质表示为图像数据为生物分子模拟提供了新思路，框架可扩展至其他复杂3D结构。

Abstract: Extensively exploring protein conformational landscapes remains a major
challenge in computational biology due to the high computational cost involved
in dynamic physics-based simulations. In this work, we propose a novel
pipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and
generative adversarial networks (GANs) to explore protein conformational
spaces. MoDyGAN contains a generator that maps Gaussian distributions into
MD-derived protein trajectories, and a refinement module that combines ensemble
learning with a dual-discriminator to further improve the plausibility of
generated conformations. Central to our approach is an innovative
representation technique that reversibly transforms 3D protein structures into
2D matrices, enabling the use of advanced image-based GAN architectures. We use
three rigid proteins to demonstrate that MoDyGAN can generate plausible new
conformations. We also use deca-alanine as a case study to show that
interpolations within the latent space closely align with trajectories obtained
from steered molecular dynamics (SMD) simulations. Our results suggest that
representing proteins as image-like data unlocks new possibilities for applying
advanced deep learning techniques to biomolecular simulation, leading to an
efficient sampling of conformational states. Additionally, the proposed
framework holds strong potential for extension to other complex 3D structures.

</details>


### [178] [Robust Anomaly Detection with Graph Neural Networks using Controllability](https://arxiv.org/abs/2507.13954)
*Yifan Wei,Anwar Said,Waseem Abbas,Xenofon Koutsoukos*

Main category: cs.LG

TL;DR: 论文提出两种新方法，通过将平均可控性整合到图机器学习模型中，显著提高了异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 复杂领域中的异常检测面临标记数据不足和样本不平衡的挑战，图机器学习模型结合属性和关系数据成为潜在解决方案。

Method: 提出两种方法：1) 将平均可控性作为边权重；2) 将其编码为独热边属性向量。

Result: 在真实和合成网络上的实验表明，新方法优于六种基线模型，验证了可控性度量对性能提升的关键作用。

Conclusion: 整合平均可控性为解决稀疏和不平衡数据集中的异常检测问题提供了新思路。

Abstract: Anomaly detection in complex domains poses significant challenges due to the
need for extensive labeled data and the inherently imbalanced nature of
anomalous versus benign samples. Graph-based machine learning models have
emerged as a promising solution that combines attribute and relational data to
uncover intricate patterns. However, the scarcity of anomalous data exacerbates
the challenge, which requires innovative strategies to enhance model learning
with limited information. In this paper, we hypothesize that the incorporation
of the influence of the nodes, quantified through average controllability, can
significantly improve the performance of anomaly detection. We propose two
novel approaches to integrate average controllability into graph-based
frameworks: (1) using average controllability as an edge weight and (2)
encoding it as a one-hot edge attribute vector. Through rigorous evaluation on
real-world and synthetic networks with six state-of-the-art baselines, our
proposed methods demonstrate improved performance in identifying anomalies,
highlighting the critical role of controllability measures in enhancing the
performance of graph machine learning models. This work underscores the
potential of integrating average controllability as additional metrics to
address the challenges of anomaly detection in sparse and imbalanced datasets.

</details>


### [179] [Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs](https://arxiv.org/abs/2507.13959)
*Eli Verwimp,Gustav Ryberg Smidt,Hendrik Hameeuw,Katrien De Graef*

Main category: cs.LG

TL;DR: 本文研究了机器学习在楔形文字分类中的应用，探讨了数据集差异对模型性能的影响，并提出了未来数据采集标准的建议。


<details>
  <summary>Details</summary>
Motivation: 楔形文字因来源、用途、书写者和数字化方式的不同而存在很大变异性，导致模型在不同数据集上表现不佳，本文旨在研究这种差异的影响。

Method: 使用ResNet50模型，在来自三个美索不达米亚城市（尼普尔、杜尔-阿比舒和西帕尔）的手写古巴比伦文本上进行训练和测试。

Result: 模型在至少20个实例的楔形文字上取得了top-1准确率87.1%和top-5准确率96.5%。

Conclusion: 研究为未来楔形文字分类任务提供了基础，并建议改进数据采集标准以提高模型泛化能力。

Abstract: The work in this paper describes the training and evaluation of machine
learning (ML) techniques for the classification of cuneiform signs. There is a
lot of variability in cuneiform signs, depending on where they come from, for
what and by whom they were written, but also how they were digitized. This
variability makes it unlikely that an ML model trained on one dataset will
perform successfully on another dataset. This contribution studies how such
differences impact that performance. Based on our results and insights, we aim
to influence future data acquisition standards and provide a solid foundation
for future cuneiform sign classification tasks. The ML model has been trained
and tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary
texts inscribed on clay tablets originating from three Mesopotamian cities
(Nippur, D\=ur-Abie\v{s}uh and Sippar). The presented and analysed model is
ResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for
signs with at least 20 instances. As these automatic classification results are
the first on Old Babylonian texts, there are currently no comparable results.

</details>


### [180] [Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks](https://arxiv.org/abs/2507.13992)
*Jagruti Patel,Thomas A. W. Bolton,Mikkel Schöttner,Anjali Tarun,Sebastien Tourbier,Yasser Alemàn-Gòmez,Jonas Richiardi,Patric Hagmann*

Main category: cs.LG

TL;DR: 论文提出了一种基于图卷积自编码器的结构连接组（SC）跨站点协调方法，解决了现有方法依赖元数据或忽视图拓扑的问题。


<details>
  <summary>Details</summary>
Motivation: 神经影像学中小样本量限制了可靠生物标志物的开发，而多站点研究中的扫描仪异质性又引入了偏差。现有协调方法依赖元数据或忽视SC的图结构，亟需改进。

Method: 提出了一种无需元数据或旅行被试的站点条件深度协调框架，测试了三种深度架构（全连接自编码器、卷积自编码器、图卷积自编码器）与线性回归基线的性能。

Result: 非图模型在边权重预测和边存在检测上表现优异，而图自编码器在保留拓扑结构和个体特征上更优。线性回归基线性能最高但依赖元数据，实用性受限。

Conclusion: 图卷积方法在结构感知和跨域泛化方面表现突出，适合大规模多站点SC研究的协调任务。

Abstract: Small sample sizes in neuroimaging in general, and in structural connectome
(SC) studies in particular limit the development of reliable biomarkers for
neurological and psychiatric disorders - such as Alzheimer's disease and
schizophrenia - by reducing statistical power, reliability, and
generalizability. Large-scale multi-site studies have exist, but they have
acquisition-related biases due to scanner heterogeneity, compromising imaging
consistency and downstream analyses. While existing SC harmonization methods -
such as linear regression (LR), ComBat, and deep learning techniques - mitigate
these biases, they often rely on detailed metadata, traveling subjects (TS), or
overlook the graph-topology of SCs. To address these limitations, we propose a
site-conditioned deep harmonization framework that harmonizes SCs across
diverse acquisition sites without requiring metadata or TS that we test in a
simulated scenario based on the Human Connectome Dataset. Within this
framework, we benchmark three deep architectures - a fully connected
autoencoder (AE), a convolutional AE, and a graph convolutional AE - against a
top-performing LR baseline. While non-graph models excel in edge-weight
prediction and edge existence detection, the graph AE demonstrates superior
preservation of topological structure and subject-level individuality, as
reflected by graph metrics and fingerprinting accuracy, respectively. Although
the LR baseline achieves the highest numerical performance by explicitly
modeling acquisition parameters, it lacks applicability to real-world
multi-site use cases as detailed acquisition metadata is often unavailable. Our
results highlight the critical role of model architecture in SC harmonization
performance and demonstrate that graph-based approaches are particularly
well-suited for structure-aware, domain-generalizable SC harmonization in
large-scale multi-site SC studies.

</details>


### [181] [ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies](https://arxiv.org/abs/2507.13998)
*Itay Katav,Aryeh Kontorovich*

Main category: cs.LG

TL;DR: 论文提出了一种动态加权机制ParallelTime Weighter，结合局部窗口注意力和Mamba，优化了时间序列预测中长短期依赖的权重分配，并通过ParallelTime架构实现了高效性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时间序列预测中对长短期依赖赋予相同权重并不理想，需要更灵活的权重分配机制。

Method: 提出ParallelTime Weighter动态计算长短期依赖的权重，并设计ParallelTime架构结合该机制。

Result: ParallelTime在多个基准测试中表现优异，计算效率高，参数少，且适应更长的预测范围。

Conclusion: ParallelTime为时间序列预测中的并行Attention-Mamba架构提供了有前景的发展方向。

Abstract: Modern multivariate time series forecasting primarily relies on two
architectures: the Transformer with attention mechanism and Mamba. In natural
language processing, an approach has been used that combines local window
attention for capturing short-term dependencies and Mamba for capturing
long-term dependencies, with their outputs averaged to assign equal weight to
both. We find that for time-series forecasting tasks, assigning equal weight to
long-term and short-term dependencies is not optimal. To mitigate this, we
propose a dynamic weighting mechanism, ParallelTime Weighter, which calculates
interdependent weights for long-term and short-term dependencies for each token
based on the input and the model's knowledge. Furthermore, we introduce the
ParallelTime architecture, which incorporates the ParallelTime Weighter
mechanism to deliver state-of-the-art performance across diverse benchmarks.
Our architecture demonstrates robustness, achieves lower FLOPs, requires fewer
parameters, scales effectively to longer prediction horizons, and significantly
outperforms existing methods. These advances highlight a promising path for
future developments of parallel Attention-Mamba in time series forecasting. The
implementation is readily available at:
\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub

</details>


### [182] [On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes](https://arxiv.org/abs/2507.14005)
*Mathieu Godbout,Audrey Durand*

Main category: cs.LG

TL;DR: 论文探讨了动态规划（DP）方法在马尔可夫决策过程（MDPs）中寻找静态CVaR最优策略时的失败原因，并提出了风险分配一致性的约束条件。


<details>
  <summary>Details</summary>
Motivation: 研究动态规划方法在CVaR优化中的失败原因，并揭示其根本问题。

Method: 通过将问题从策略优化转向策略评估，提出风险分配一致性约束条件，并量化评估误差。

Result: 发现评估误差源于约束条件的不满足，并证明双CVaR分解方法在寻找全局最优策略时的局限性。

Conclusion: 双CVaR分解方法在特定MDP中无法找到对所有初始风险水平均最优的策略。

Abstract: Recent work has shown that dynamic programming (DP) methods for finding
static CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when
based on the dual formulation, yet the root cause for the failure has remained
unclear. We expand on these findings by shifting focus from policy optimization
to the seemingly simpler task of policy evaluation. We show that evaluating the
static CVaR of a given policy can be framed as two distinct minimization
problems. For their solutions to match, a set of ``risk-assignment consistency
constraints'' must be satisfied, and we demonstrate that the intersection of
the constraints being empty is the source of previously observed evaluation
errors. Quantifying the evaluation error as the CVaR evaluation gap, we then
demonstrate that the issues observed when optimizing over the dual-based CVaR
DP are explained by the returned policy having a non-zero CVaR evaluation gap.
We then leverage our proposed risk-assignment perspective to prove that the
search for a single, uniformly optimal policy via on the dual CVaR
decomposition is fundamentally limited, identifying an MDP where no single
policy can be optimal across all initial risk levels.

</details>


### [183] [Byzantine-resilient federated online learning for Gaussian process regression](https://arxiv.org/abs/2507.14021)
*Xu Zhang,Zhenyuan Yuan,Minghui Zhu*

Main category: cs.LG

TL;DR: 提出了一种拜占庭容错的联邦高斯过程回归算法，用于在部分代理存在拜占庭行为时提升学习性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何在代理存在拜占庭行为（任意或敌对行为）的情况下，通过联邦学习提升高斯过程回归的性能。

Method: 开发了一种拜占庭容错的联邦GPR算法，通过云和代理协作学习潜在函数，并使用拜占庭容错的产品专家聚合规则计算全局模型。

Result: 实验表明，代理融合GPR的学习精度优于本地GPR，验证了算法的有效性。

Conclusion: 提出的算法在拜占庭代理存在时仍能有效提升学习性能，适用于实际应用场景。

Abstract: In this paper, we study Byzantine-resilient federated online learning for
Gaussian process regression (GPR). We develop a Byzantine-resilient federated
GPR algorithm that allows a cloud and a group of agents to collaboratively
learn a latent function and improve the learning performances where some agents
exhibit Byzantine failures, i.e., arbitrary and potentially adversarial
behavior. Each agent-based local GPR sends potentially compromised local
predictions to the cloud, and the cloud-based aggregated GPR computes a global
model by a Byzantine-resilient product of experts aggregation rule. Then the
cloud broadcasts the current global model to all the agents. Agent-based fused
GPR refines local predictions by fusing the received global model with that of
the agent-based local GPR. Moreover, we quantify the learning accuracy
improvements of the agent-based fused GPR over the agent-based local GPR.
Experiments on a toy example and two medium-scale real-world datasets are
conducted to demonstrate the performances of the proposed algorithm.

</details>


### [184] [DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis](https://arxiv.org/abs/2507.14038)
*Aileen Luo,Tao Zhou,Ming Du,Martin V. Holt,Andrej Singer,Mathew J. Cherukara*

Main category: cs.LG

TL;DR: DONUT是一种物理感知神经网络，用于快速自动分析纳米束衍射数据，无需标记数据集或预训练，效率比传统方法高200倍。


<details>
  <summary>Details</summary>
Motivation: 实时分析纳米束衍射数据存在瓶颈，传统方法受限于计算需求和伪影问题。

Method: DONUT结合可微分几何衍射模型，实时预测晶体晶格应变和取向。

Result: 实验证明DONUT能高效提取数据特征，速度比传统方法快200倍。

Conclusion: DONUT为X射线科学中的实时数据分析提供了高效解决方案。

Abstract: Coherent X-ray scattering techniques are critical for investigating the
fundamental structural properties of materials at the nanoscale. While
advancements have made these experiments more accessible, real-time analysis
remains a significant bottleneck, often hindered by artifacts and computational
demands. In scanning X-ray nanodiffraction microscopy, which is widely used to
spatially resolve structural heterogeneities, this challenge is compounded by
the convolution of the divergent beam with the sample's local structure. To
address this, we introduce DONUT (Diffraction with Optics for Nanobeam by
Unsupervised Training), a physics-aware neural network designed for the rapid
and automated analysis of nanobeam diffraction data. By incorporating a
differentiable geometric diffraction model directly into its architecture,
DONUT learns to predict crystal lattice strain and orientation in real-time.
Crucially, this is achieved without reliance on labeled datasets or
pre-training, overcoming a fundamental limitation for supervised machine
learning in X-ray science. We demonstrate experimentally that DONUT accurately
extracts all features within the data over 200 times more efficiently than
conventional fitting methods.

</details>


### [185] [Noradrenergic-inspired gain modulation attenuates the stability gap in joint training](https://arxiv.org/abs/2507.14056)
*Alejandro Rodriguez-Garcia,Anindya Ghosh,Srikanth Ramaswamy*

Main category: cs.LG

TL;DR: 论文研究了持续学习中的稳定性间隙问题，提出了一种基于不确定性调制的增益动态机制，有效减少了性能下降。


<details>
  <summary>Details</summary>
Motivation: 持续学习中存在稳定性间隙问题，即在掌握新任务时已掌握任务的性能会短暂下降，这与持续学习的目标相矛盾。论文旨在通过生物启发的机制解决这一问题。

Method: 受生物大脑中蓝斑核介导的去甲肾上腺素爆发的启发，提出了不确定性调制的增益动态机制，模拟双时间尺度优化器，动态平衡知识整合与干扰最小化。

Result: 在MNIST和CIFAR基准测试中，该机制有效减少了稳定性间隙，提升了持续学习任务的性能。

Conclusion: 不确定性调制的增益动态机制不仅减少了稳定性间隙，还为理解如何通过增益调制模拟生物机制提供了新视角。

Abstract: Recent studies in continual learning have identified a transient drop in
performance on mastered tasks when assimilating new ones, known as the
stability gap. Such dynamics contradict the objectives of continual learning,
revealing a lack of robustness in mitigating forgetting, and notably,
persisting even under an ideal joint-loss regime. Examining this gap within
this idealized joint training context is critical to isolate it from other
sources of forgetting. We argue that it reflects an imbalance between rapid
adaptation and robust retention at task boundaries, underscoring the need to
investigate mechanisms that reconcile plasticity and stability within continual
learning frameworks. Biological brains navigate a similar dilemma by operating
concurrently on multiple timescales, leveraging neuromodulatory signals to
modulate synaptic plasticity. However, artificial networks lack native
multitimescale dynamics, and although optimizers like momentum-SGD and Adam
introduce implicit timescale regularization, they still exhibit stability gaps.
Inspired by locus coeruleus mediated noradrenergic bursts, which transiently
enhance neuronal gain under uncertainty to facilitate sensory assimilation, we
propose uncertainty-modulated gain dynamics - an adaptive mechanism that
approximates a two-timescale optimizer and dynamically balances integration of
knowledge with minimal interference on previously consolidated information. We
evaluate our mechanism on domain-incremental and class-incremental variants of
the MNIST and CIFAR benchmarks under joint training, demonstrating that
uncertainty-modulated gain dynamics effectively attenuate the stability gap.
Finally, our analysis elucidates how gain modulation replicates noradrenergic
functions in cortical circuits, offering mechanistic insights into reducing
stability gaps and enhance performance in continual learning tasks.

</details>


### [186] [Preference-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2507.14066)
*Ni Mu,Yao Luan,Qing-Shan Jia*

Main category: cs.LG

TL;DR: 论文提出了一种基于偏好的多目标强化学习方法（Pb-MORL），通过整合偏好来优化多目标任务的决策，避免了复杂奖励函数的设计。


<details>
  <summary>Details</summary>
Motivation: 传统多目标强化学习依赖预定义的奖励函数，难以平衡冲突目标且可能导致简化问题。偏好更灵活直观，能避免复杂奖励设计。

Method: Pb-MORL将偏好整合到MORL框架中，构建与偏好对齐的多目标奖励模型，并证明优化该模型等价于训练帕累托最优策略。

Result: 在多个基准任务和实际场景（如能源管理和自动驾驶）中，Pb-MORL表现优异，甚至优于使用真实奖励函数的方法。

Conclusion: Pb-MORL展示了在复杂现实系统中应用的潜力，为多目标决策提供了更灵活的解决方案。

Abstract: Multi-objective reinforcement learning (MORL) is a structured approach for
optimizing tasks with multiple objectives. However, it often relies on
pre-defined reward functions, which can be hard to design for balancing
conflicting goals and may lead to oversimplification. Preferences can serve as
more flexible and intuitive decision-making guidance, eliminating the need for
complicated reward design. This paper introduces preference-based MORL
(Pb-MORL), which formalizes the integration of preferences into the MORL
framework. We theoretically prove that preferences can derive policies across
the entire Pareto frontier. To guide policy optimization using preferences, our
method constructs a multi-objective reward model that aligns with the given
preferences. We further provide theoretical proof to show that optimizing this
reward model is equivalent to training the Pareto optimal policy. Extensive
experiments in benchmark multi-objective tasks, a multi-energy management task,
and an autonomous driving task on a multi-line highway show that our method
performs competitively, surpassing the oracle method, which uses the ground
truth reward function. This highlights its potential for practical applications
in complex real-world systems.

</details>


### [187] [DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration](https://arxiv.org/abs/2507.14088)
*Xiyun Li,Yining Ding,Yuhua Jiang,Yunlong Zhao,Runpeng Xie,Shuang Xu,Yuanhua Ni,Yiqin Yang,Bo Xu*

Main category: cs.LG

TL;DR: 提出了一种基于双过程多尺度心智理论（DPMT）的框架，用于提升人-AI协作中AI对人类复杂心理特征的建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）代理难以准确建模人类在动态场景中的复杂心理特征（如领域意图），尤其是在缺乏直接沟通的情况下。

Method: 受认知科学双过程理论启发，提出DPMT框架，包含多尺度心智理论（ToM）模块，通过心理特征推理实现稳健的人类伙伴建模。

Result: 实验表明DPMT显著提升了人-AI协作效果，消融研究进一步验证了多尺度ToM在慢系统中的贡献。

Conclusion: DPMT框架有效解决了人-AI协作中AI对人类心理特征建模的挑战，为动态场景下的协作提供了新思路。

Abstract: Real-time human-artificial intelligence (AI) collaboration is crucial yet
challenging, especially when AI agents must adapt to diverse and unseen human
behaviors in dynamic scenarios. Existing large language model (LLM) agents
often fail to accurately model the complex human mental characteristics such as
domain intentions, especially in the absence of direct communication. To
address this limitation, we propose a novel dual process multi-scale theory of
mind (DPMT) framework, drawing inspiration from cognitive science dual process
theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)
module to facilitate robust human partner modeling through mental
characteristic reasoning. Experimental results demonstrate that DPMT
significantly enhances human-AI collaboration, and ablation studies further
validate the contributions of our multi-scale ToM in the slow system.

</details>


### [188] [Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective](https://arxiv.org/abs/2507.14121)
*Pankaj Yadav,Vivek Vijay*

Main category: cs.LG

TL;DR: Kolmogorov Arnold Networks (KANs) show promise for imbalanced classification but face computational and compatibility issues with standard techniques.


<details>
  <summary>Details</summary>
Motivation: To evaluate KANs' effectiveness in class-imbalanced classification compared to MLPs.

Method: Empirical evaluation on ten benchmark datasets, comparing KANs and MLPs with/without imbalance strategies.

Result: KANs perform well on raw imbalanced data but degrade with standard imbalance techniques; MLPs with imbalance techniques match KANs at lower cost.

Conclusion: KANs are specialized for raw imbalanced data but need architectural and efficiency improvements for practical use.

Abstract: Kolmogorov Arnold Networks (KANs) are recent architectural advancement in
neural computation that offer a mathematically grounded alternative to standard
neural networks. This study presents an empirical evaluation of KANs in context
of class imbalanced classification, using ten benchmark datasets. We observe
that KANs can inherently perform well on raw imbalanced data more effectively
than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,
conventional imbalance strategies fundamentally conflict with KANs mathematical
structure as resampling and focal loss implementations significantly degrade
KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from
prohibitive computational costs without proportional performance gains.
Statistical validation confirms that MLPs with imbalance techniques achieve
equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.
These findings reveal that KANs represent a specialized solution for raw
imbalanced data where resources permit. But their severe performance-resource
tradeoffs and incompatibility with standard resampling techniques currently
limits practical deployment. We identify critical research priorities as
developing KAN specific architectural modifications for imbalance learning,
optimizing computational efficiency, and theoretical reconciling their conflict
with data augmentation. This work establishes foundational insights for next
generation KAN architectures in imbalanced classification scenarios.

</details>


### [189] [Toward Temporal Causal Representation Learning with Tensor Decomposition](https://arxiv.org/abs/2507.14126)
*Jianhong Chen,Meng Zhao,Mostafa Reisi Gahrooei,Xubo Yue*

Main category: cs.LG

TL;DR: 提出了一种结合时间因果表示学习与不规则张量分解的框架CaRTeD，用于高维不规则数据，并在理论和实验上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现实应用中数据多为高维不规则张量，现有方法难以有效提取因果表示，需结合张量分解技术。

Method: 提出CaRTeD框架，整合时间因果表示学习与不规则张量分解，提供灵活的规范化设计。

Result: 理论证明算法收敛，实验在合成和真实数据（如MIMIC-III）上表现优于现有方法。

Conclusion: CaRTeD填补了不规则张量分解理论空白，提升了因果表示的可解释性和性能。

Abstract: Temporal causal representation learning is a powerful tool for uncovering
complex patterns in observational studies, which are often represented as
low-dimensional time series. However, in many real-world applications, data are
high-dimensional with varying input lengths and naturally take the form of
irregular tensors. To analyze such data, irregular tensor decomposition is
critical for extracting meaningful clusters that capture essential information.
In this paper, we focus on modeling causal representation learning based on the
transformed information. First, we present a novel causal formulation for a set
of latent clusters. We then propose CaRTeD, a joint learning framework that
integrates temporal causal representation learning with irregular tensor
decomposition. Notably, our framework provides a blueprint for downstream tasks
using the learned tensor factors, such as modeling latent structures and
extracting causal information, and offers a more flexible regularization design
to enhance tensor decomposition. Theoretically, we show that our algorithm
converges to a stationary point. More importantly, our results fill the gap in
theoretical guarantees for the convergence of state-of-the-art irregular tensor
decomposition. Experimental results on synthetic and real-world electronic
health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both
phenotyping and network recovery perspectives, demonstrate that our proposed
method outperforms state-of-the-art techniques and enhances the explainability
of causal representations.

</details>


### [190] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: VIDAR是一个两阶段框架，通过扩散模型预训练和掩码逆向动力学模型解决双手机器人操作中的数据稀缺和异构性问题，仅需少量演示即可泛化到新任务和背景。


<details>
  <summary>Details</summary>
Motivation: 双手机器人操作中数据稀缺和异构性限制了其扩展，需要一种更高效的方法。

Method: 利用扩散模型预训练750K多视角视频，结合掩码逆向动力学模型提取动作相关信息。

Result: 仅需20分钟人类演示（1%数据量），VIDAR在新平台和任务中表现优异，超越现有方法。

Conclusion: 视频基础模型与掩码动作预测结合，为机器人操作提供了可扩展和泛化的解决方案。

Abstract: Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>
